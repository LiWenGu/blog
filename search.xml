<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[五、Curator操作]]></title>
    <url>%2F2017%2F08%2F28%2Fzookeeper%2F5_Curator%E6%93%8D%E4%BD%9C.html%2F</url>
    <content type="text"></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[六、Zookeeper的典型应用场景]]></title>
    <url>%2F2017%2F08%2F28%2Fzookeeper%2F6_Zookeeper%E7%9A%84%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html%2F</url>
    <content type="text"><![CDATA[1 典型应用场景及实现]]></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[五、使用Zookeeper]]></title>
    <url>%2F2017%2F08%2F28%2Fzookeeper%2F5_%E4%BD%BF%E7%94%A8Zookeeper.html%2F</url>
    <content type="text"><![CDATA[原书本节全是关于Zookeeper的原生JavaAPI讲解，以及Curator开源框架的讲解，因此使用另外了一个专门的文章用来记录Curator的使用。 此处传送门]]></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[四、Zookeeper与Paxos]]></title>
    <url>%2F2017%2F08%2F25%2Fzookeeper%2F4_Zookeeper%E4%B8%8EPaxos.html%2F</url>
    <content type="text"><![CDATA[本章概要：首先对ZooKeeper进行一个整体上的介绍，包括ZooKeeper的设计目标、由来以及它的基本概念，然后将会重点介绍ZAB这一ZooKeeper中非常重要的一致性协议。 1. 初识ZooKeeper1.1 ZooKeeper介绍ZooKeeper由雅虎创建，是Chubby的开源实现。设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 1.1.1 ZooKeeper是什么ZooKeeper是一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举 、分布式锁和分布式队列等功能。ZooKeeper可以保证如下分布式一致性特性。 .1 顺序一致性从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到ZooKeeper中去。 .2 原子性所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群所有机器都成功应用了某一个事务，要么都没有应用，一定 不会出现集群中部分机器应用了该事务，而另外一部分没有应用的情况。 .3 单一视图（Single System Image）无论客户端连接的是哪ZooKeeper服务器，其看到的服务端数据模型都是一致性。 .4 可靠性一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更。 .5 实时性通常人们看到实时性的第一反应是，一旦一个事务被成功应用，那么客户端能够立即从服务端上读取到这个事务变更后的最新数据状态。这里需要注意的是， ZooKeeper仅仅保证在一定额时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。 1.1.2 ZooKeeper的设计目标ZooKeeper致力于提供一个高性能、高可用，且具有严格的顺序访问控制能力（主要是写操作的严格顺序性）的分布式协调服务。高性能使得ZooKeeper能够应用于 那些对系统吞吐有明确要求的大型分布式系统中，高可用使得分布式的单点问题得到了很好的解决，而严格的顺序访问控制使得客户端能够基于ZooKeeper实现 一些复杂的同步原语。下面我们来具体看一下ZooKeeper的四个设计目标。 .1 目标一：简单的数据模型ZooKeeper使得分布式程序能够通过一个共享的、树型结构的名字空间来进行相互协调。 这里所说的树型结构的名字空间，是指ZooKeeper服务器内存中的一个数据模型，其由一系列被称为ZNode的数据节点组成，总的来说，其数据模型类似于一个文件系统， 而ZNode之间的层级关系，就像文件系统的目录结构一样。不过和传统的磁盘文件系统不同的是，ZooKeeper将全量数据存储在内存中，以此来实现提高 服务器吞吐、减少延迟的目的。 .2 目标二：可以构建集群一个ZooKeeper集群通常由一组机器组成，一般3~5台机器就可以组成一个可用的ZooKeeper集群了（2n+1）。 组成ZooKeeper集群的每台机器都会在内存中维护当前的服务器状态，并且每台机器之间都互相保持着通信。值得一提的，只要集群中存在超过一半的机器 能够正常工作，那么整个集群就能够正常对外服务。 ZooKeeper的客户端程序会选择和集群中任意一台机器共同来创建一个TCP连接，而一旦客户端和某台ZooKeeper服务器之间的连接断开后，客户端会自动连接 到集群中的其他机器。 .3 顺序访问对于来自客户端的每个更新请求，ZooKeeper都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序，应用程序可以使用ZooKeeper 的这个特性来实现更高层次的同步原语。 .4 高性能由于ZooKeeper将全量数据存储在内存中，并直接服务于客户端的所有非事务请求，因此它尤其适用于以读操作为主的应用场景。 1.2 ZooKeeper从何而来ZooKeeper最早起源于雅虎研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是 这些系统往往都存在分布式单点问题。所以雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人眼将精力集中在处理业务逻辑上。 关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的Pig项目），雅虎 的工程师希望给合格项目也取一个动物的名字，大家纷纷表示就叫动物园管理员吧————因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看 上去就像一个大型的动物园了，而ZooKeeper正好要用来进行分布式环境的协调————于是，ZooKeeper的名字也就由此诞生了。 1.3 ZooKeeper的基本概念1.3.1 集群角色通常在分布式系统中，构成一个集群的每一台机器都有自己的角色，最典型的集群模式就是Master/Slave模式（主备模式）。在这种模式下，我们把能够处理所有 写操作的机器称为Master机器，把所有通过异步复制方式获取最新数据，并提供读服务的机器称为Slave机器。 而在ZooKeeper中，这些概念被颠覆了。它没有沿用传统的Master/Slave概念，而是引入了Leader、Follower和Observer三种角色。ZooKeeper集群中的所有 机器通过一个Leader选举过程来选定一台被称为“Leader”的机器，Leader服务器为客户端提供读和写服务。除Leader外，其他机器包括Follower和Observer。 Follower和Observer都能够提供读服务，唯一的区别在于，Observer机器不参与Leader选举过程，也不参与写操作的“过半写成功”策略，因此Observer可以 在不影响写性能的情况下提升集群的读性能。 1.3.2 会话（Session）Session是指客户端会话，在讲解会话之前，我们首先来了解一下客户端连接。在ZooKeeper中，一个客户端连接是指客户端和服务器之间的一个TCP长连接。 ZooKeeper对外的服务端口默认是2181，客户端启动的时候，首先会服务器建立一个TCP连接，从第一次连接建立开始，客户端会话的生命周期也开始了， 通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向ZooKeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。 Session的sessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时， 只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。 1.3.3 数据节点（Znode）在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然后，在ZooKeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点； 第二类则是指数据模型中的数据单元，我们称之为数据几点————Znode。ZooKeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree），由/进行分割 的路径，就是一个Znode，例如/foo/path1。每个Znode上都会保存自己的数据内容，同时还会保存一系列属性信息。 在ZooKeeper中，Znode可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个Znode被创建了，除非主动进行Znode的移除操作，否则这个Znode将一直保存在ZooKeeper 上。临时节点生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。另外，ZooKeeper还允许用户为每个节点 添加一个特殊的属性：SEQUENTIAL。一旦节点被标注上这个属性，那么在这个节点被创建的时候，ZooKeeper会自动在其节点名后面追上一个整型数字，这个 整型数字是一个由父节点维护的自增数字。 1.3.4 版本在前面我们已经提到，ZooKeeper的每个Znode上都会存储数据，对应于每个Znode，ZooKeeper都会为其维护一个叫作Stat的数据结构，Stat中记录了这个Znode 的三个数据版本，分别是version（当前Znode的版本）、cversion（当前Znode字节点的版本）、aversion（当前Znode的ACL版本）。 1.3.5 WatcherWatcher（事件监听器），是ZooKeeper中得意一个很重要的特性。ZooKeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端 会将事件通知到感兴趣的客户端上去，该机制是ZooKeeper实现分布式协调服务的重要特性。 1.3.6 ACLZooKeeper采用ACL（Access Control Lists）策略来进行权限控制。 CREATE：创建子节点的权限。 READ：获取节点数据和子节点列表的权限。 WRITE：更新节点数据的权限。 DELETE：删除子节点的权限。 ADMIN：设置节点ACL的权限。 其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制。 1.4 为什么选择ZooKeeper在解决分布式数据一致性上，除了ZooKeeper之外，目前还没有一个成熟稳定且被大规模应用的解决方案。ZooKeeper无论从性能、易用性还是稳定性上来说， 都已经达到了一个工业级产品的标准。并且开发源码、免费。 2 ZooKeeper的ZAB协议2.1 ZAB协议事实上，ZooKeeper并没有完全采用Paxos算法，而是使用了一种称为ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子消息广播协议）的协议作为其数据一致性的核心算法。 ZAB协议是为分布式协调服务ZooKeeper专门设计的一种支持崩溃恢复的原子广播协议。ZAB协议的开发设计人员在协议设计之初并没有要求其具有很好的扩展性， 最初只是为雅虎公司内部那些高吞吐量、低延迟、健壮、简单的分布式系统场景设计的。在ZooKeeper的官方文档也指出，ZAB协议不像Paxos算法那样，是一种 通用的分布式一致性算法，它是一种特别为ZooKeeper设计的崩溃可恢复的原子消息广播算法。 在ZooKeeper中，主要依赖ZAB协议来实现分布式数据一致性，基于该协议，ZooKeeper实现了一种主备模式的系统架构来保持集群中各副本之间数据的一致性。具体的， ZooKeeper使用一个单一的主进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器数据的状态变更以事务Proposal的形式广播到所有的副本进程上去。 ZAB协议的这个主备模型架构保增乐同一时刻集群中只能够有一个主进程来广播服务器的状态变更，因此能够很好地处理客户端大量的并发请求。另一方面，考虑到在分布式环境中， 顺序执行的一些状态变更其前后会存在一定的依赖关系，有些状态变更必须依赖于比它早生成的那些状态变更，例如变更C需要依赖变更A和变更B。这样的依赖关系 也对ZAB协议提出了一个要求：ZAB协议必须能够保证一个全局的变更序列被顺序应用，也就是说，ZAB协议需要保证如果一个状态变更已经被处理了，那么所有其 依赖的状态变更都应该已经被提前处理掉了。最后，考虑到主进程在任何时候都有可能出现崩溃退出或重启现象。因此，ZAB协议还需要做到在当前主进程出现上述异常情况的时候，依旧能够正常工作。 ZAB协议的核心是定义了哪些会改变ZooKeeper服务器数据状态的事务请求的处理方式，即： 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而余下的其他服务器则成为Follower服务器。 Leader服务器负责将一个客户端事务请求转换成一个事务Proposal（提议），并将该Proposal分发给集群中所有的Follower服务器。之后Leader 服务器需要等待所有Follower服务器的反馈，一旦超过半数的Follower服务器进行了正确的反馈后，那么Leader就会再次向所有的Follower 服务器分发Commit消息，要求其将前一个Proposal进行提交。 2.2 协议介绍ZAB协议包括两种基本的模式，分别是崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当Leader服务器出现网络中断、崩溃退出与重启等异常情况时， ZAB协议就会进入恢复模式并选举产生新的Leader服务器。当选举产生了新的Leader服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后， ZAB协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。 当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。当一台同样遵守ZAB协议的服务器启动后加入到 集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到Leader所在的服务器， 并与其进行数据同步，然后一起参与到消息广播流程中区。正如上文介绍所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求和处理。 Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求， 那么这些非Leader服务器首先将这个事务请求转发给Leader服务器。 当Leader服务器出现崩溃退出或机器重启，亦或是集群中已经不存在过半的服务器与该Leader服务器保持正常通信时，那么在重新开始新一轮的原子广播事务操作之前， 所有进程首先会使用崩溃恢复协议来使彼此达到一个一致的状态，于是整个ZAB流程就会从消息广播模式进入到崩溃恢复模式。 一个机器要称为新的Leader，必须获得过半进程的支持，同时由于每个进程都有可能会崩溃，因此，在ZAB协议运行过程中，前后会出现多个Leader，并且每个进程也有可能 会多次成为Leader。进入崩溃恢复模式后，只要集群中存在过半的服务器能够彼此进行正常通信，那么就可以产生一个新的Leader并再次进入消息广播模式。 举个例子来说，一个由3台机器组成的AZB服务，通常由1个Leader、2个Follower服务器组成。某一时刻，加入其中一个Follower服务器挂了，整个ZAB是 不会中断服务的，这是因为Leader服务器依然能够获得过半机器（包括Leader自己）的支持。 2.2.1 消息广播ZAB协议的消息广播过程使用的是一个原子广播协议，类似于一个二阶段提交过程。针对客户端的事务请求，Leader服务器会为其生成对应的事务Proposal，并 将其发送给集群中其余所有的机器，然后再分别收集各自的选票，最后进行事务提交。在ZAB协议的二阶段提交过程中，移除了中断逻辑，所有的Follower服务器要么正常反馈Leader提出的事务Proposal，要么就抛弃Leader服务器。同时，ZAB协议将二阶段 提交中的中断逻辑移除意味着我们可以在过半的Follower服务器已经反馈Ack之后就开始提交事务Proposal了，而不需要等待集群中所有的Follower服务器都 反馈响应。当然，在这种简化了的二阶段提交模型下，是无法处理Leader服务器崩溃退出而带来的数据不一致问题，因此在ZAB协议中添加了另一个模式， 即采用崩溃恢复模式来解决这个问题。另外，整个消息广播协议是基于具有FIFO特性的TCP协议来进行网络通信的，因此能够很容易地保证消息广播过程中 消息接收与发送的顺序性。 在整个消息广播过程中，Leader服务器会为每个事务请求对应的Proposal来进行广播，并且在广播事务Proposal之前，Leader服务器会首先为这个事务Proposal分配一个 全局单调递增的唯一ID，我们称之为事务ID（即ZXID）。由于ZAB协议需要保证每一个消息严格的因果关系，因此必须将每一个事务Proposal按照其ZXID的 先后顺序来进行排序与处理。 具体的，在消息广播过程中，Leader服务器会为每一个Follower服务器都各自分配一个单独的队列，然后将需要广播的事务Proposal依次放入这些队列中，并且根据FIFO 策略进行消息发送。每一个Follower服务器在接收到这个事务Proposal之后，都会首先将其以事务日志的形式写入到本地磁盘中去，并且在成功写入后反馈给Leader 服务器一个Ack响应。当Leader服务器接收到超过半数Follower的Ack响应后，就会广播一个Comit消息给所有的Follower服务器以通知其进行事务提交，同时Leader自身 也会完成对事务的提交，而每一个Follower服务器在接收到Commit消息后，也会完成对事务的提交。 2.2.2 崩溃恢复一旦Leader服务器出现奔溃，或者说由于网络原因导致Leader服务器失去了与过半Follower的联系，那么就会进入崩溃恢复模式。在ZAB协议中，为了保证程序的正确运行， 整个恢复过程后需要选举出一个新的Leader服务器。因此，AZB协议需要一个高效且可靠的Leader选举算法，从而确保能够快速地选举出新的Leader。同时， Leader选举算法不仅仅需要让Leader自己知道其自身已经被选举为Leader，同时还需要让集群中的所有其他机器也能够快速地感知到选举产生的新的Leader服务器。 .1 基本特性ZAB协议规定了如果一个事务Proposal在一台机器上被处理成功，那么应该在所有的机器上都被处理成功，哪怕机器出现故障崩溃。接下来我们看看在崩溃恢复过程中， 可能会出现的两个数据不一致性的隐患及针对这些情况ZAB协议所需要保证的特性。 ZAB协议需要确保那些已经在Leader服务器上提交的事务最终被所有服务器都提交。 假设一个事务在Leader服务器上被提交了，并且已经得到过半Follower服务器的Ack反馈，但是它将Commit消息发送给所有Follower机器之前，Leader服务器挂了。 例如，在集群正常运行过程中的某一个时刻，Server1是Leader服务器，其先后广播了消息P1、P2、C1、P3、C2，其中，当Leader服务器将消息C2（Commit Of Proposal2） 发出后就立即崩溃退出了。针对这种情况，ZAB协议就需要确保事务Proposal2最终能够在所有的服务器上都被提交成功，否则将出现不一致。 ZAB协议需要确保丢弃那些只在Leader服务器上被提出的事务。 假设初始的Leader服务器Server1在提出了一个事务Proposal3之后就崩溃退出了，从而导致集群中的其它服务器都没有收到这个事务Proposal。于是，当Server1 恢复过来再次加入到集群中的时候，ZAB协议需要确保丢弃Proposal3这个事务。 结合上面的这两个崩溃恢复过程中需要处理的特殊情况，就决定了ZAB协议必须设计这样一个Leader选举算法：能够确保提交已经被Leader提交的事务Proposal， 同时丢弃已经被跳过的事务Proposal。针对这个要求，如果让Leader选举算法能够保证新选举出来的Leader服务器拥有集群中所有机器最高编号（即ZXID）的事务 Proposal，那么就可以保证这个新选举出来的Leader一定具有所有已经提交的提案。更为重要的是，如果让具有最高编号事务Proposal的机器来成为Leader，就 可以省去Leader服务器检查Proposal提交和丢弃工作的这一步操作了。 .2 数据同步完成Leader选举之后，在正式开始工作（即接收客户端的事务请求，然后提出新的提案）之前，Leader服务器会首先确认事务日志中的所有Proposal是否都已经 被集群中过半的机器提交了，即是否完成数据同步。下面我们就来看看ZAB协议的数据同步过程。 所有正常运行的服务器，要么称为Leader，要么称为Follower并和Leader保持同步。Leader服务器需要确保所有的Follower服务器能够接收每一条事务Proposal， 并且能够正确地将所有已经提交了的事务Proposal应用到内存数据中去。具体的，Leader服务器会为每一个Follower服务器都准备一个队列，并将那些没有被 各Follower服务器同步的事务以Proposal消息的形式逐个发送给Follower服务器，并在每一个Proposal消息后面紧接着再发送一个Commit消息，以表示该事务 已经被提交。等到Follower服务器将所有其尚未同步的事务Proposal都从Loeader服务器上同步过来并成功应用到本地数据库中后，Leader服务器就会将 Follower服务器加入到真正的可用Follower列表中，并开始之后的其它流程。 上面讲到的是正常情况下的数据同步逻辑，下面来看ZAB协议是如何处理那些需要被丢弃的事务Proposal的。在ZAB协议的事务编号ZXID设计中，ZID是一个64位的数字， 其中低32位可以看作是一个简单的单调递增的计数器，针对客户端的每一个事务请求，Leader服务器在产生一个新的事务Proposal的时候，都会对该计数器进行加1操作； 而高32位则代表了Leader周期epoch的编号，每当选举产生一个新的Leader服务器，就会从这个Leader服务器上取出本地日志中最大事务Proposal的ZXID，并从 该ZXID中解析出对应的epoch值，然后再对其进行加1操作，之后就会以此编号作为新的epoch，并将低32位置0来开始生成新的ZXID。ZAB协议中的这一通过epoch编号 来区分Leader周期变化的策略，能够有效地避免不同的Leader服务器错误地使用相同的ZXID编号提出不一样的事务Proposal的异常情况，这对于识别在Leader崩溃恢复前后 生成的Proposal非常有帮助，大大简化和提升了数据恢复流程。 基于这样的策略，当一个包含了上一个Leader周期尚无提交过的事务Proposal的服务器启动时，其肯定无法成为Leader，原因很简单，因为当前集群中一定包含一个Quorum集合， 该集合中的机器一定包含了更好epoch的事务Proposal，因此这台机器的事务Proposal肯定不是最高，也就无法成为Leader了。当这台机器加入到集群中，以 Follower角色连接上Leader服务器之后，Leader服务器会根据自己服务器上最后被提交的Proposal来和Follower服务器的Proposal进行比对，比对的结果 当然是Leader会要求Follower进行一个回退操作————回退到一个确实已经被集群中过半机器提交的最新的事务Proposal。（ZXID的高32位是纪元，当已经挂了 的Leader重新恢复变成Leader时，其纪元一定小于当前一直在运行的服务器，因此老的Leader就算恢复了也不会成为Leader。大清亡了，新的时代，） 2.3 ZAB与Paxos算法的联系ZAB协议并不是Paxos算法的一个典型实现，在讲解ZAB和Paxos之间的区别之前，我们首先来看下两者的联系。 两者都存在一个类似于Leader进程的角色，由其负责协调多个Follower进程的运行。 Leader进程都会等待超过半数的Follower做出正确的反馈后，才会将一个提案进行提交。 在ZAB协议中，每个Proposal中都包含了一个epoch值，用来代表当前的Leader周期，在Paxos算法中，同样存在这样的一个标识，只是名字变成了Ballot。 在Paxos算法中，一个新选举产生的主进程会进行两个阶段的工作。第一阶段被称为读阶段，在这个阶段中，这个新的主进程会通过和所有其它进程进程通信的方式来收集上一个主进程提出 的提案，并将它们提交。第二阶段被称为写阶段，在这个阶段，当前主进程开始提出它自己的提案。在Paxos算法设计的基础上，ZAB协议额外添加了一个同步阶段。 在同步阶段之前，ZAB协议也存在一个和Paxos算法中的读阶段非常类似的过程，称为发现（Discovery）阶段。在同步阶段中，新的Leader会确保存在 过半的Follower已经提交了之前Leader周期中的所有事务Proposal。这一同步阶段的引入，能够有效地保证Leader在新的周期中提出事务Proposal之前，所有的 进程都已经完成了对之前所有事务Proposal的提交。一旦完成同步阶段后，那么ZAB就会执行和Paxos算法类似的写阶段。 总的来说，ZAB协议和Paxos算法的本质区别在于，两者的设计目标不太一样。ZAB协议主要用于构建一个高可用的分布式数据主备系统，例如ZooKeeper， 而Paxos算法则是用于构建一个分布式的一致性状态机系统。 3 小结ZooKeeper的设计目标、由来以及基本概念。另外还有它的一致性协议————ZAB，并将其与Paxos算法进行了比对。 ZooKeeper为了保证状态的一致性，提出了两个安全属性： 全序（消息a和消息b发送的顺序Client和Server看的都是一样的），通过TCP协议的FIFO队列特性实现。 因果顺序（消息a先于消息b发送，则消息a先于消息b执行）。通过Leader消息先到先执行。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[三、Paxos的工程实践]]></title>
    <url>%2F2017%2F08%2F22%2Fzookeeper%2F3_Paxos%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html%2F</url>
    <content type="text"><![CDATA[前章提要：主要从理论上讲解了Paxos算法，如何在保证数据一致性的情况下兼顾稳定性和性能也是一个巨大的挑战。从本章开始，我们将结合实际工程实际中的Paxos实现， 来讲解如何真正地使用Paxos算法来解决分布式一致性问题。 1. ChubbyGoogle Chubby是一个大名鼎鼎的分布式锁服务，GFS和Big Table等大型系统多用它来解决分布式协作、元数据存储和Master选举等一系列与分布式锁服务相关的问题。 Chubby的底层一致性实现就是以Paxos算法为基础的，这给Paxos算法的学习者提供了一个理论联系的范例，从而可以了解到Paxos算法是如何在实际工程中得到应用的。 1.1 概述Chubby是一个面向松耦合分布式系统的锁服务，通常用于为一个由大量小型计算机构成的松耦合分布式系统提供高可用的分布式锁服务。一个分布式锁服务的目的是 允许它的客户端进程同步彼此的操作，并对当前所处环境的基本状态信息达成一致。针对这个目的，Chubby提供了粗粒度的分布式锁服务，开发人员不需要使用复杂的同步协议。 而是直接调用Chubby的锁服务接口即可实现分布式系统中多个进程之间粗粒度的同步控制，从而保证分布式数据的一致性。 Chubby的客户端接口设计非常类似于UNIX文件系统结构，应用程序通过Chubby的客户端接口，不仅能够对Chubby服务器上的整个文件进行读写操作，还能够添加对文件节点的锁控制， 并且能够订阅Chubby服务端发出的一些列文件变动的事件通知。 1.2 应用场景在Chubby的众多应用场景中，最为典型的就是集群中服务器的Master选举。例如在Google文件系统（Google File System，GFS）中使用Chubby锁服务来实现对 GFS Master服务器的选举。而在BigTable（用于结构化数据存储与管理的大型分布式存储系统）中，同样被用于Master选举，并且借助Chubby， Master能够非常方便地的感知到其所控制的那些服务器。同时，通过Chubby，BigTable的哭护短还能够方便地定位到当前BitTable集群的Master服务器。 此外，在GFS和BigTable中，都使用Chubby来进行系统运行时元数据的存储。 1.3 设计目标对于Chubby的设计，有的开发人员觉得作为Paxos算法的实现者，Chubby应该构建成一个包含Paxos算法的协议库，从而使应用程序能够便捷地使用Paxos算法。 但是，Chubby的最初设计者并没有选择这么做，而是将Chubby设计成一个需要访问中心化节点的分布式锁服务。 Chubby之所以设计成这样一个完整的分布式锁服务，是因为锁服务具有以下4个传统算法库所不具有的优点。 1. 对上层应用程序的侵入性更小对于应用程序开发初期，开发人员都是从一个只需要支撑较小的负载，并且只需要保证大体可用的原型开始的，往往并没有在代码层面为分布式一致性协议的实现留有余地。 于是，集群中副本复制和Master选举等一系列提高分布式系统可用性的措施，就通过一个封装了分布式一致性协议的客户端来完成，但相比之下， 使用一个分布式锁服务的接口方式对上层应用程序的侵入性会更小。 2. 便于提供数据的发布与订阅几乎在所有使用Chubby进行Master选举的应用场景中，都需要一种广播结果的机制，用来向所有的客户端公布当前的Master服务器。这就意味着Chubby应该 允许其客户端在服务器上进行少量数据的存储与读取————也就是对小文件的读写操作。虽然这个特性也能够通过分布式命名服务来实现，但是根据实际的经验来看， 分布式锁服务本身也非常适合提供这个功能，这一方面能够大大减少客户端依赖的外部服务，另一方面，数据的发布与订阅功能和锁服务在分布式一致性特性上是想通的。 3. 开发人员对基于锁的接口更为熟悉对于绝大部分的开发人员来说，Chubby为其提供了一套近乎和单机锁机制一致的分布式锁服务接口，比提供一个一致性协议的库来得更为友好。 4. 更便捷地构建更可靠的服务通常一个分布式一致性算法都需要使用Quorum机制来进行数据项值的选定。Quorum机制是分布式系统中实现数据一致性的一个比较特殊的策略，它指的是在 一个由若干个机器组成的急群众，在一个数据项值的选定过程中，要求急群众存在过半的机器达成一致，因此Quorum机制也被称作“过半机制”。 在Chubby中通常使用5台服务器来组成一个集群单元，根据Quorum机制，只要整个急群众有3台服务器是正常运行的，那么整个集群就可以对外提供正常的服务。 相反的，如果仅提供一个分布式一致性协议的客户端库，那么这些高可用性的系统部署都将交给开发人员自己来处理，提高了成本。 因此，Chubby被设计成了一个需要访问中心化节点的分布式锁服务。同时，在Chubby的设计过程中，提出了以下几个设计目标。 1. 提供一个完整的、独立的分布式锁服务，而非仅仅是一个一致性协议的客户端库：例如，对于Master选举同时将Master信息登记并广播的场景，应用程序只需要向Chubby请求一个锁，并且在获得锁之后向相应的锁文件写入Master信息即可， 其余的客户端就可以通过读取这个锁文件来获取Master信息。 2. 提供粗粒度的锁服务Chubby锁服务针对的应用场景是客户端获得锁之后会进行长时间的持有（数小时或数天），而非用于短暂获取锁的场景。针对这种应用场景，当锁服务短暂失效时 （例如服务器宕机），Chubby需要保持所有锁的持有状态，以避免持有锁的客户端出现问题。这和细粒度锁的设计方式有很大的区别，细粒度锁通常设计为锁 服务一旦失效就释放所有锁，因为细粒度锁的持有时间很短，相比而言放弃锁带来的代价较小。 3. 在提供锁服务的同时提供对小文件的读写功能Chubby提供对小文件的读写服务，以使得被选举出来的Master可以在不依赖额外服务的情况下，非常方便地向所有客户端发布自己的状态信息。具体的， 当一个客户端成功获取到一个Chubby文件锁而成为Master之后，就可以继续向这个文件里写入Master信息，其他客户端就可以通过读取这个文件得知当前的Master信息。 4. 高可用、高可靠在Chubby的架构设计中，允许运维人员通过部署多台机器（一般是5台机器）来组成一个Chubby集群，从而保证集群的高可用，基于Paxos算法的实现， 只要保证在3台正常运行的机器，整个集群对外服务就能保持可用。 5. 提供事件通知机制Chubby客户单需要实时地感知到Master的变化情况，当然这可以通过让客户端反复轮询来实现，但是在客户端规模不断增大的情况下，客户端主动轮询的实时性效果并不理想， 且对服务器性能和网络带宽压力都非常大。因此，Chubby需要由能力将服务端的数据变化情况（如文件内容变更）以事件的形式通知到所有订阅的客户端。 1.4 Chubby技术架构1.4.1 系统结构Chubby的整个系统结构主要由服务端和客户端两部分组成，客户端通过RPC调用与服务端进行通信一个典型的Chubby集群，或称为Chubby cell，通常由5台服务器组成。这些副本服务器采用Paxos协议，通过投票的方式来选举产生一个获得过半投票的 服务器作为Master。一旦某台服务器成为了Master，Chubby就会保证在一段时期内不会再有其他服务器成为Master————这段时期称为Master租期（Master lease）。 在运行过程中，Master服务器会通过不断续租的方式来延长Master租期，而如果Master服务器出现故障，那么余下的服务器就会进行新一轮的Master选举， 最终产生新的Master服务器，开始新的Master租期。 集群中的每个服务器都维护着一份服务端数据库的副本，但在实际运行过程中，只有Master服务器才能对数据库进行写操作，而其它服务器都是使用Paxos协议从 Master服务器上同步数据库数据的更新。 现在，我们再来看下Chubby的客户端是如何定位到Master服务器的。Chubby客户端通过向记录有Chubby服务端机器列表的DNS来请求获取所有的Chubby服务器列表， 然后逐个发起请求询问该服务器是否是Master。在这个询问过程中，那些非Master的服务器，则会将当前Master所在的服务器标识反馈给客户端，这样 客户端就能够非常快速地定位到Master服务器了。 一旦客户端定位到Master服务器之后，只要该Master正常运行，那么客户端就会将所有的请求都发送到该Master服务器上。针对写请求，Chubby Master 会采用一致性协议将其广播给集群中所有的副本服务器，并且在过半的服务器接受了该写请求之后，再响应给客户端正确的应答。而对于读请求， 则不需要在集群内部进行广播处理，直接由Master服务器单独处理即可。 在Chubby运行过程中，服务器难免会发生故障。如果当前的Master服务器崩溃了，那么集群中的其他服务器会在Master租期到期后，重新开启新一轮的Master 选举。通常，进行一次Master选举大概需要花费几秒钟的时间。而如果是集群中任意一台非Master服务器崩溃，那么整个集群是不会停止工作的， 这个崩溃的服务器会在恢复之后自动加入到Chubby集群中去。新加入的服务器首先需要同步Chubby最新的数据库数据，完成数据同步之后，新的服务器就可以 加入到正常的Paxos运作流程中与其它服务器副本一起协同工作。 如果集群中的一个服务器发生崩溃并在几个小时后仍无法恢复正常，那么就需要加入新的机器，并同时更新DNS列表。Chubby服务器的更换方式非常简单， 只需要启动Chubby服务端程序，然后更新DNS上的机器列表（即使用新机器的IP地址替换老机器的IP地址）即可。在Chubby运行过程中， Master服务器会周期性地轮询DNS列表因此其很快就会感知服务器地址列表的变更，然后Master就会将集群数据库中的地址列表做相应的变更， 集群内部的其他副本服务器通过复制方式就可以获取到最新的服务器地址列表了。 1.4.2 目录与文件Chubby对外提供了一套与Unix文件系统非常相近但是更简单的访问接口。Chubby的数据结构可以看作是一个由文件和目录组成的树，其中每一个节点都可以表示为一个 使用斜杠分割的字符串，典型的节点路径表示如下： /ls/foo/wombat/pouch其中，ls是所有Chubby节点所共有的前缀，代表着锁服务，是Lock Service的缩写；foo则指定了Chubby集群的名字，从DNS可以查询到由一个或多个 服务器组成该Chubby集群；剩余部分的路径wombat/pouch则是一个真正包含业务含义的节点名字，由Chubby服务器内部解析并定位到数据节点。 Chubby的命名空间，包括文件和目录，我们称之为节点（nodes，在本书后面的内容中，我们以数据节点来泛指Chubby的文件或目录）。在同一个Chubby 集群数据库中，每一个节点都是全局唯一的。和Unix系统一样，每个目录都可以包含一系列的子文件和子目录列表，而每个文件中则会包含文件内容。当然， Chubby并非模拟一个完整的文件系统，因此没有符号链接和硬连接的概念。 由于Chubby的命名结构组成了一个近似标准文件系统的视图，因此Chubby的客户端应用程序也可以通过自定义的文件系统访问接口来访问Chubby服务端数据， 比如可以使用GFS的文件系统访问接口，这就大大减少了用户使用Chubby的成本。 Chubby上的每个数据节点都分为持久节点和临时节点两大类，其中持久节点需要显式地调用接口API来进行删除，而临时节点则会在其对应的客户端会话失效后被自动删除。 （zk中的EPHEMERAL）也就是说，临时节点的生命周期和客户端会话绑定，如果该临时节点对应的文件没有被任何客户端打开的话，那么它就会被删除掉。 因此，临时节点通常可以用来进行客户端会话有效性的判断依据。 另外，Chubby上的每个数据节点都包含了少量的元数据信息，其中包括用于权限控制的访问控制列表（ACL）信息。同时，每个节点的元数据中还包括4个单调 递增的64编号，分别如下。 实例编号：实例编号用于标识Chubby创建该数据节点的顺序，节点的创建顺序不同，其实例编号也不同，因此，通过实例编号，即使针对两个名字相同的数据节点， 客户端也能够非常方便地识别出是否是同一个数据节点————因此创建时间晚的数据节点，其实例编号必定大于任意先前创建的同名节点。 文件内容编号（只针对文件）：文件内容编号用于标识文件内容的变化情况，该编号会在文件内容被写入时增加。 锁编号：锁编号用于标识节点锁状态变更情况，该编号会在节点锁从自由（free）状态转换到被持有（held）状态时增加。 ACL编号：ACL编号用于标识节点的ACL信息变更情况，该编号会在节点的ACL配置信息被写入时增加。同时，Chubby还会标识一个64位的文件内容校验码，以便客户端能够识别出文件是否变更。 1.4.3 锁与锁序列器在分布式系统中，锁是一个非常复杂的问题，由于网络通信的不确定性，导致在分布式系统中锁机制变得非常复杂，消息的延迟或是乱序都有可能会引起锁的失效。 一个典型的分布式锁错乱案例是，一个客户端C1获取到了互斥锁L，并且在锁L的保护下发出请求R，但请求R迟迟没有到达服务端（可能出现网络延时或 反复重发等），这时应用程序会认为该客户端进程已经失败，于是便会为另一个客户端C2分配锁L，然后再重新发起之前的请求R，并成功地应用到了服务器 上。此时，不幸的事情发生了，客户端C1发起的请求R在经过一波三折之后也到达了服务端，此时，它有可能会在不受任何锁控制的情况下被服务端处理， 从而覆盖了客户端C2的操作，于是导致系统数据出现不一致。当然，诸如此类消息接收顺序紊乱引起的数据不一致问题已经在人们对分布式计算的长期 研究过程中得到了很好的解决，典型的解决方案包括虚拟时间和虚拟同步。 在Chubby中，任意一个数据节点都可以充当一个读写锁来使用：一种是单个客户端以排他（写）模式持有这个锁，另一种则是任意数目的客户端以共享（读）模式 持有这个锁。同时，在Chubby的锁机制中需要注意的一点是，Chubby舍弃了严格的强制锁，客户端可以在没有获取任何锁的情况下访问Chubby的文件，也就是说， 持有锁F既不是访问文件F的必要条件，也不会阻止其它客户端访问文件F。 .1 锁延迟在Chubby中，主要采用锁延迟和锁序列器两种策略来解决上面我们提到的由于消息延迟和重排序引起的分布式锁问题。其中锁延迟是一种比较简单的策略， 使用Chubby的应用几乎不需要进行任何的代码修改。具体的，如果一个客户端以正常的方式主动释放了一个锁，那么Chubby服务端将会允许其它客户端能够 立即获得该锁。而如果一个锁是因为客户端的异常情况（如客户端无响应）而被释放的话，那么Chubby服务器会为该锁保留一定的时间，我们称之为“锁延迟”（lock-delay） 在这段时间内，其它客户端无法获取这个锁。锁延迟措施能够很好地防止一些客户端由于网络闪断等原因而与服务器暂时断开的场景出现。总的来说， 该方案尽管不完美，但是锁延时能够有效地保护在出现消息延时情况下发生的数据不一致现象。 .2 锁序列器Chubby提供的另一种方式是使用锁序列器，当然该策略需要Chubby的上层应用配合在代码中加入相应的修改逻辑。任何时候，锁的持有者都可以向Chubby请求一个锁 序列器，其包括锁的名字、锁模式（排他或共享模式），以及锁序号。当客户端应用程序在进行一些需要锁机制保护的操作时，可以将该锁序列器一并发送给服务端。 Chubby服务端接收到这样的请求后，会首先检测该序列器是否有效，以及检查客户端是否处于恰当的锁模式；如果没有通过检查，那么服务端就会拒绝该客户端请求。 1.4.4 Chubby中的事件通知机制为了避免大量客户端轮询Chubby服务端状态所带来的压力，Chubby提供了事件通知机制。Chubby的客户端可以向服务端注册事件通知，当触发这些事件的时候， 服务端就会向客户端发送对应的事件通知。在Chubby的事件通知机制中，消息通知都是通过异步的方式发送给客户端的，常见的Chubby事件如下。 .1 文件内容变更例如，BigTable集群使用Chubby锁来确定集群中的哪台BitTable机器是Master；获得锁的BitTable Master会将自身信息写入Chubby上对应的文件中。 BitTable集群中的其他客户端可以通过监视这个Chubby文件的变化来确定新的BitTable Master机器。 .2 节点删除当Chubby上指定节点被删除的时候，会产生“节点删除”事件，这通常在临时节点中比较常见，可以利用该特性来间接判断该临时节点对应的客户端会话是否有效。 .3 子节点新增、删除当Chubby上指定的节点的子节点新增或是删除时，会产生“子节点新增、删除”事件。（还有更新） .4 Master服务器转移当Chubby服务器发生Master转移时，会以事件的形式通知客户端。 1.4.5 Chubby中的缓存为了提高Chubby的性能，同时也是为了减少客户端和服务端之间频繁的读请求对服务端的压力，Chubby除了提供事件通知机制之外，还在客户端中实现了缓存， 会在客户端对文件内容和元数据信息进行缓存。使用缓存机制在提高系统整体性能的同时，也为系统带来了一定的复杂性，其中最主要的问题就是应该如何保证缓存的一致性。 在Chubby中，通过租期机制来保证缓存的一致性。 Chubby缓存的生命周期和Master租期机制紧密相关，Master会维护每个客户端的数据缓存情况，并通过向客户端发送过期信息的方式来保证客户端数据的一致性。 在这种机制下，Chubby就能够保证客户端要么能够从缓存中访问到一致的数据，要么访问出错，而一定不会访问到不一致的数据。具体的，每个客户端的缓存 都有一个租期，一旦该租期到期，客户端就需要向服务端续订租期以继续维持缓存的有效性。当文件数据或元数据被修改时，Chubby服务端首先会阻塞该修改操作， 然后由Master向所有可能缓存了该数据的客户端发送缓存过期信号，以使其缓存失效，等到Master在接收到所有相关客户端针对该过期信息的应答（应答包括两类， 一类是客户端明确要求更新缓存，另一类则是客户端允许缓存租期过期）后，再继续进行之前的修改操作。 通过上面这个缓存机制的介绍，相信读者都已经明白了，Chubby的缓存数据保证了强一致性。尽管要保证严格的数据一致性对于性能的开销和系统的吞吐影响很大， 但由于弱一致性模式在实际使用过程中极容易出现问题，因此Chubby在设计之初就决定了强一致性模型。 1.4.6 会话和会话激活（KeepAlive）Chubby客户端和服务端之间通过创建一个TCP连接来进行所有的网络通信操作，我们将这一连接称为会话（Session）。会话是有生命周期的，存在一个超时时间， 在超时时间内，Chubby客户端和服务端之间可以通过心跳检测来保持会话的活性，以使会话周期得到延续，我们将这个过程称为KeepAlive（会话激活）。如果 能够成功地通过KeepAlive过程将Chubby会话一直延续下去，那么客户端创建的句柄（引用）、锁和缓存数据等都依然有效。 1.4.7 KeepAlive请求下面我们就重点来看看Chubby Master是如何处理客户端的KeepAlive请求的。Master在接收到客户端的KeepAlive请求时，首先会将该请求阻塞住，并等到 该客户端的当前会话租期即将过期时，才为其续租该客户端的会话租期，之后再向客户端响应这个KeepAlive请求，并同时将最新的会话租期超时时间反馈给客户端。 Master对于会话续租时间的设置，默认是12秒，但这不是一个固定的值，Chubby会根据实际的运行情况，自行调节该周期的长短。举个例子来说， 如果当前Master处于高负载运行状态的话，那么Master会适当地延长会话租期的长度，以减少客户端KeepAlive请求的发送频率。客户端在接收到来自Master的续租 响应后，会立即发起一个新的KeepAlive请求，再由Master进行阻塞。因此我们可以看出，在正常运行过程中，每一个Chubby客户端总是会有一个KeepAlive 请求阻塞在Master服务器上。 除了为客户端进行会话续租外，Master还将通过KeepAlive响应来传递Chubby事件通知和缓存过期通知给客户端。具体的，如果Master发现服务端已经触发了 针对该客户端的事件通知或缓存过期通知，那么会提前将KeepAlive响应反馈给客户端。 1.4.8 会话超时谈到会话租期，Chubby的客户端也会维持一个和Master端近似相同的会话租期。为什么是近似相同呢？这是因为客户端必须考虑两方面的因素：一方面，KeepAlive 响应在网络传输过程中会花费一定的时间；另一方面，Master服务端和Chubby客户端存在时钟不一致性现象。因此在Chubby会话中，存在Master端会话租期和客户端本地 会话租期。 如果Chubby客户端在运行过程中，按照本地的会话租期超时时间，检测到期会话租期已经过期却尚未接收到Master的KeepAlive响应，那么这个时候，它将无法确定Master 服务端是否已经中止了当前会话，我们称这个时候客户端处于“危险状态”。此时，Chubby客户端会清空其本地缓存，并将其标记为不可用。同时，客户端还会等待一个被 称作“宽限期”的时间周期，这个宽限期默认是45秒。如果在宽限期到期前，客户端和服务端成功地进行了KeepAlive，那么客户端就会再次开启本地缓存，否则，客户端就会 认为当前会话已经过期了，从而中止本次会话。 我们再着重来看看上面提到的“危险状态”。当客户端进入上述提到的危险状态时，Chubby的客户端库会通过一个“jeopardy”事件来通知上层应用程序。如果 恢复正常，客户端同样会以一个“safe”事件来通知应用程序可以继续正常运行了。但如果客户端最终没能从危险状态中恢复过来，那么客户端会以一个“expired” 事件来通知应用程序当前Chubby会话已经超时。Chubby通过这些不同的事件类型通知，能够很好地辅助上层应用程序在不明确Chubby会话状态的情况下， 根据不同的事件类型来做出不同的处理：等待或重启。有了这样的机制保证之后，对于那些在短时间内Chubby服务不可用的场景下，客户端应用程序可以选择等待，而不是重启， 这对于那些重启整个应用程序需要花费较大代价的系统来说非常有帮助。 1.4.9 Chubby Master故障恢复Chubby的Master服务器上运行着会话租期计时器，用来管理所有会话的生命周期。如果在运行过程中Master出现了故障，那么该计时器会停止，直到新的Master选举 产生后，计时器才会继续计时，也就是说，从旧的Master崩溃到新的Master选举产生所花费的时间将不计入会话超时的计算中，这等价于延长了客户端的会话租期。 如果新的Master在短时间内就选举产生了，那么客户端就可以在本地会话租期过期前与其创建连接。而如果Master的选举花费了较长的时间，就会导致客户端只能情况本地的缓存， 并进入宽限期进行等待。从这里我们可以看出，由于宽限期的存在，使得会话能够很好地在服务端Master转换额过程中得到维持。整个Chubby Master故障恢复过程中 服务端和客户端的交互情况：展示了一个完整的Chubby服务端Master故障恢复过程中所触发的所有事件序列。在这整个故障恢复过程中，客户端必须使用宽限期来保证在Master转换过程完成之后， 其会话依然有效。 一开始在旧的Master服务器上维持了会话租期“lease M1”，在客户端上维持了对应的“lease C1”，同时客户端的KeepAlive请求1一直被Master阻塞着。在一段时间之后， Master向客户端反馈了KeepAlive响应2，同时开始了新的会话租期“lease M2”，而客户端在接收到该KeepAlive响应之后，立即发送了新的KeepAlive请求3，并 同时也开始了新的会话租期“lease C2”。至此，客户端和服务吨Master之间的所有交互都是正常的。但是随后，Master发生了故障，从而无法反馈客户端的KeepAlive 请求3。在这个过程中，客户端检测到会话租期“lease C2”已经过期，它会清空本地缓存，并进入宽限期。在这顿时间内，客户端无法确定Master上的会话周期 是否也已经过期，因此，它不会销毁它的本地会话，而是将所有应用程序对它的API调用都阻塞主，以避免在这个期间进行的API调用导致数据不一致现象。 同时，在客户端宽限期开始时，Chubby客户端会向上层应用程序发送一个“jeopardy”事件。一段时间后，CHubby服务端选举产生了新的Master，并为该客户端初始化 了新的会话租期“lease M3”。当客户端向新的Master发送KeepAlive请求4时，Master检测到该客户端的Master周期号已经过期，因此会在KeepAlive响应5 中拒绝这个客户端请求，并将最新的Master周期号发送给客户端。之后，客户端会携带上新的Master周期号，再次发送KeepAlive请求6给Master，最终，整个 客户端和服务端之间的会话就会再次恢复正常。 通过上面的详细介绍，不难看出，在Master转换的这段时间内，只要客户端的宽限期是够长的，那么客户端应用程序可以在没有任何察觉的情况下，实现Chubby的故障恢复， 但如果客户端的宽限期设置得比较短，那么Chubby客户端就会丢弃当前会话，并将这个异常情况通知给上层应用程序。 一旦客户端与新的Master建立上连接之后，客户端和Master之间会通过互相配合来实现对故障的平滑恢复。新的Master会设法将上一个Master服务器的内存状态构造出来。 具体的，由于本地数据库记录了每个客户端的会话信息，以及其持有的锁和临时文件等信息，因此Chubby会通过读取本地磁盘上的数据来恢复一部分状态。 总的来讲，一个新的Chubby Master服务器选举产之后，会进行如下几个主要处理。 .1 确定Master周期Master周期用来唯一标识一个Chubby集群的Master统治轮次，以便区分不同的Master。一旦新的Master周期确定下来之后，Master就会拒绝所有携带其他Master 周期编号的客户端请求，同时告知其最新的Master周期编号，例如上述提到的KeepAlive请求4。需要注意的一点是，只要发生Master重新选举，就一定会产生新的 Master周期，即使是在选举前后Master都是同一台机器的情况下也是如此。 .2 新Master能够立即对客户端的Master寻址请求进行响应，但是不会立即开始处理客户端会话相关的请求操作。.3 Master根据本地数据库中存储的会话和锁信息，来构建服务器的内存状态。.4 到现在为止，Master已经能够处理客户端的KeepAlive请求了，但依然无法处理其他会话相关的操作。.5 Master会发送一个“Master故障切换”事件给每一个会话。客户端接收到这个事件后，会清空它的本地缓存，并警告上层应用程序可能已经丢失了别的事件，之后再向Master反馈应答。 .6 此时，Master会一直等待客户端的应答，知道每一个会话都应答了这个切换事件。.7 在Master接收到了所有客户端的应答之后，就能够开始处理所有的请求操作了。.8 如果客户端使用了一个在故障切换之前创建的引用，Master会重新为其创建这个引用的内存对象，并执行调用。而如果该引用在之前的Master周期中已经被关闭了，那么它聚不能在这个Master周期内再次被重建了————这一机制就确保了即使由于网络原因使得Master接收到那些延迟或重发的网络数据包， 也不会错误地重建一个已经关闭的引用。 1.5 Paxos协议实现Chubby服务端的基本架构大致分为三层： 最底层是容错日志系统（Fault-Tolerant Log），通过Paxos算法能够保证集群中所有机器上的日志完全一致，同时具有较好的容错性。 日志层之上是Key-value类型的容错数据库（Fault-Tolerant DB），其通过下层的日志来保证一致性和容错性。 存储层之上就是Chubby对外提供的分布式锁服务和小文件存储服务。Paxos算法的作用就在于保证集群内各个副本节点的日志能够保持一致。Chubby事务日志中的每一个Value对应Paxos算法中的一个Instance，由于Chubby需要对外提供 不间断的服务，因此事务日志无限增长，于是在整个Chubby巡行过程中，会存在多个Paxos Instance。同时，Chubby会为每一个Paxos Instance都按序分配一个全局唯一 的Instance编号，并将其顺序写入到事务日志中去。 在多Paxos Instance的模式下，为了提升算法执行的性能，就必须选举出一个副本节点作为Paxos算法的主节点，以避免因为每一个Paxos Instance都提出提案而陷入多个Paxos Round 并存的情况。同时，Paxos会保证在Master重启或出现故障而进行切换的时候，允许出现短暂的多个Master共存却不影响副本之间的一致性。 在Paxos中，每一个Paxos Instance都需要进行一轮或多轮“Prepare-&gt;Promise-&gt;Propose-&gt;Accept”这样完整的二阶段请求过程来完成对一个提案值的选定， 而多个Instance之间是完全独立的，每个Instance可以自己决定每一个Round的序号，仅仅只需要保证在Instance内部不会出现序号重复即可。为了在保证正确性的前提下尽可能 地的提高算法运行性能，可以让多个Instance共用一套序号分配机制，并将“Prepare-&gt;Promise”合并为一个阶段，具体做法如下。 当某个副本节点通过选举成为Master后，就会使用新分配的编号N来广播一个Prepare消息，该Prepare消息会被所有未达成一致的Instance和目前还未开始的Instance共用。 当Acceptor接收到Prepare消息后，必须对多个Instance同时做出回应，这通常可以通过将反馈信息封装在一个数据包中来实现。假设最多允许K个Instance同时进行提案值的选定，那么： 当前至多存在K个未达成一致的Instance，将这些未决的Instance各自最后接收的提案值（若该提案尚未接收任何值。则使用null来代替）封装进一个数据包，并作为Promise消息返回。 同时，判断N是否大于当前Acceptor的highestPromisedNum值（当前已经接受的最大提案编号值），如果大于该值的话，那么就标记这些未决Instance和 所有未来的Instance的highestPromisedNum值为N————这样，这些未决Instance和所有未来Instance都不能再接受任何编号小于N的提案。 然后Master就可以对所有未决Instance和所有未来Instance分别执行“Propose-&gt;Accept”阶段的处理。值得注意的是，如果当前Master能够一直稳定运行的话， 那么在接下来的算法运行过程中，就不再需要进行“Prepare-&gt;Promise”的处理了。但是，一但Master发现Acceptor返回了一个Reject消息，说明集群中存在另一个Master， 并且试图使用更大的编号发送了Prepare消息。碰到这种情况，当前Master就需要重新分配新的提案编号，并再次进行“Prepare-&gt;Promise”阶段的逻辑处理。 利用上述改进的Paxos算法，在Master稳定运行的情况下，只需要使用同一个编号来依次执行每一个Instance的“Promise-&gt;Accept”阶段逻辑处理。在每个Instance 的运行过程中，一旦接收到多数派的Accept反馈后，就可以将对应的提案值写入本地事务日志并广播COMMIT消息给集群中的其他副本节点，其他副本节点在接收到这个COMMIT消息之后也会 将提案值写入到事务日志中。如果某个副本节点因为宕机或者网络原因没有接收到COMMIT消息，可以主动向集群中的其他副本节点进行查询。因此，我们可以看到，在Chubby的Paxos 算法的实现中，只要维持集群中存在多数派的机器能够正常运行，即使其他机器在任意时刻发生宕机，也能保证已经提交的提案的安全性。 至此，我们已经实现了一套满足一致性的日志副本，在此基础上就可以在上层实现一个一致的状态机副本，即容错数据库层。初期，使用Berkeley DB作为容错数据库， 这个数据库底层实现了B树数据结构，即存储大量数据的HashMap，将每一个数据节点的节点路径名作为键，同时按照节点路径名进行排序，这就能够使得兄弟节点在排序顺序中相邻， 方便对数据节点的检索。 后来，Chubby自己实现了一套更为简单的、基于日志预写和数据快照技术的底层数据复制组件。 数据快照和事务日志回放机制：集群中的某台机器在宕机重启以后，为了恢复状态机的状态，最简单的方法就是将已经记录的所有事务日志重新执行一遍。但这 会有一个明显的问题，就是如果机器上的事务日志已经积累了很多，那么恢复的时间就会非常长，因此需要定期对状态机数据做一个数据快照并将其存入磁盘， 然后就可以将数据快照点之前的事务日志清除。 通常副本节点在进行宕机后的恢复过程中，会出现磁盘未损坏和损坏两种情况。前者最为常见，一般通过磁盘上保存的数据库快照和事务日志就可以恢复到之前某个时间点的状态， 之后再向集群中其他正常运行的副本节点索取宕机后缺失的部分数据变更记录，这样即可实现宕机后的数据恢复。另外一种则是磁盘损坏，无法直接从本地数据恢复的情况， 需要从其它副本节点索取全部的状态数据。 副本节点在完成宕机重启之后，为了安全起见，不会立即参与Paxos Instance流程，而是需要等待检测到K个Paxos Instance流程陈宫完成之后才能开始参与————这样就能够保证 新分配的提案编号不会和自己以前发过的重复。 最后，为了提高整个集群的性能，还有一个改进之处在于：得益于Paxos算法的容错机制，只要任意时刻保证多数派的机器能够正常运行，那么在宕机瞬间未能真正写入到 磁盘上（只有当真正调用操作系统Flush接口后，数据才能被真正写入物理磁盘中）的那一小部分事务日志也可以通过从其它正常运行的副本上复制来进行获取，因此 不需要实时地进行事务日志的Flush操作，这可以极大地提高事务写入的效率。 1.2 Hypertable1.2.1 概述使用C++开发的开源、高性能、可伸缩的数据库。只支持增删改查，不支持事务。 支持对大量并发请求的处理。 支持对海量数据的管理。 扩展性良好，在保证可用性的前提下，能够通过随意添加集群中的机器来实现水平扩容。 可用性极高，具有非常好的容错性，任何节点的失效，既不会造成系统瘫痪也不会影响数据的完整性。 1.2.2 算法实现选举Master是根据所有服务器上事务日志的更新时间来确定哪个服务器的数据最新，那么被选举的可能性就越大。 3 小结列举了使用Paxos算法的工业实践应用，更好的理解Paxos算法。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二、一致性协议]]></title>
    <url>%2F2017%2F08%2F18%2Fzookeeper%2F2_%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE.html%2F</url>
    <content type="text"><![CDATA[前章提要：上章我们讲到分布式往往会在系统可用性和数据一致性之间反复权衡，于是就产生了一系列的一致性协议（为什么没有可用性协议？博主认为，数据才是王道）。 1. 2PC和3PC在分布式系统总，每一个机器节点虽然都能够明确地知道自己在进行事务操作过程中的结果是成功或失败，但却无法直接获取到其他分布式节点的操作结果。 因此，当一个事务操作需要跨越多个分布式节点的时候，为了保持事务处理的ACID特性（某个节点为单位），就需要引入一个称为“协调者（Coordinator）” 的组件来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为“参与者（Participant）”。 Coordinator负责调度Participant的行为，并最终决定这些Participant是否要把事务真正的提交。基于这个思想，衍生除了二阶段提交和三阶段提交两种协议， 在本节中，我们将重点对这两种分布式事务中涉及的一致性协议进行讲解。 1.1 2PC2PC是Two-Phase Commit的缩写，即二阶段提交，是计算机网络尤其是在数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务处理过程中能保持 原子性和一致性而设计的算法。 1.1.1 阶段一：提交事务请求 事务询问：协调者向所有的参与者发送事务内容，询问是否可以执行事务提交曹组，并开始等待各参与者的响应。 执行事务：各参与者节点执行事务操作，并将Undo和Redo信息记入事务日志中。 各参与者向协调者反馈事务询问的响应：如果参与者成功执行了事务操作，那么反馈给协调者Yes响应，表示事务可以执行；如果参与者没有成功执行事务， 那么就反馈给协调者No响应，表示事务不可以执行。 由于上面讲述的内容在形式上近似是协调者组织各参与者对一次事务操作的投票表态过程，因此二阶段提交协议的阶段一页被称为“投票阶段”，即各参与者投票 表明是否要继续执行接下去的事务提交操作。 1.1.2 阶段二：执行事务提交正常情况，包含以下两种可能： .1 可能一：执行事务提交：假如协调者从所有的参与者的反馈都是Yes响应，那么就会执行事务提交。.1.1 发送提交请求：协调者向所有参与者发出Commit请求。.1.2 事务提交：参与者接收到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放整个事务执行期间占用的事务资源。.1.3 反馈事务提交结果：参与者在完成事务提交之后，向协调者发送Ack消息。.1.4 完成事务：协调者接收到所有参与者反馈的Ack消息后，完成事务。.2 可能二：执行事务中断：假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。.2.1 发送回滚请求：协调者向所有参与者节点发出Rollback请求。.2.2 事务回滚：参与者接收到Rollback请求后，会利用其在阶段一记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。.2.3 反馈事务回滚结果：参与者在完成事务回滚之后，向协调者发送Ack消息。.2.4 中断事务：协调者接收到所有参与者反馈的Ack消息后，完成事务中断。以上就是二阶段提交过程中，前后两个阶段分别进行的处理逻辑。简单地讲，二阶段提交将一个事务的处理分成了投票和执行两个阶段，其核心是对每个事务 都采用了先尝试后提交的处理方式，因此也可以将二阶段提交看作一个强一致性的算法。 1.1.3 优缺点原理简单，实现方便；但是同步阻塞、单点问题、数据不一致、太过保守。 .1 同步阻塞：在事务的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，也就是说，各个参与者在登台其他参与者响应的过程中，将无法进行其他任何操作。 .2 单点问题：一旦协调者出现问题，整个二阶段提交流程将无法运转，更为严重的是，如果协调者是在阶段二中出现问题的话，那么其他参与者将会一直处于锁定事务资源的状态中，而无法继续完成事务操作。 .3 数据不一致：当协调者向所有参与者发送Commit请求之后，发生了协调者在尚未发送完Commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了Commit请求。于是，其他没有收到Commit请求的参与者没有进行事务提交，而收到Commit请求的参与者会进行事务提交，最终数据不一致。 .4 太过保守：任何一个节点的失败都会导致整个事务的失败。1.2 3PC研究者在二阶段提交协议的基础上进行了改进，提出了三阶段提交协议。3PC是Three-Phase Commit的缩写，将二阶段提交协议的“提交事务请求”过程分为两个，形成了CanCommit、PreCommit和DoCommit。 1.2.1 阶段一：CanCommit.1 事务询问：协调者向所有的参与者发送一个包含事务内容的CanCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。.2 各参与者向协调者反馈响应：如果自身可以顺序执行事务，反馈Yes响应，并进入预备状态，否则反馈No响应。1.2.2 阶段二：PreCommit.1 执行事务预提交：假如协调者从所有参与者获得的反馈都是Yes响应。.1.1 发送预提交请求：协调者向所有参与者节点发出PreCommit的请求，并进入Prepared阶段。.1.2 事务预提交：参与者接收到PreCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中。.1.3 各参与者向协调者反馈事务执行的响应：如果参与者成功执行了事务操作，那么就会反馈给协调者Ack响应，同时等待最终的指令：提交（commit）或中止（abort）。 .2 中断事务：假如任何一个参与者向协调者反馈了No响应，或等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。.2.1 发送中断请求：协调者向所有参与者节点发出abort请求。.2.2 中断事务：无论是收到来自协调者的abort请求，或者是在等待协调者请求过程中出现超时时，参与者都会中断事务。1.2.3 阶段三：DoCommit.1 可能一：执行提交.1.1 发送提交请求：协调者从“预提交”状态转换到“提交”状态，并向所有的参与者发送DoCommit请求。.1.2 事务提交：参与者接收到DoCommit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。.1.3 反馈事务提交结果：参与者在完成事务提交之后，向协调者发送Ack消息。.1.4 完成事务：协调者接收到所有参与者反馈的Ack消息后，完成事务。.2 可能二：中断事务.2.1 发送中断请求：协调者向所有参与者节点发送abort请求。.2.2 事务回滚：参与者接收到abort请求后，利用Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。.2.3 反馈事务回滚结果：参与者在完成事务回滚之后，向协调者发送Ack消息。.2.4 中断事务：协调者接收到所有参与者反馈的Ack消息后，中断事务。需要注意的是，一旦进入阶段三，可能会存在以下两种故障： 协调者出现问题。 协调者和参与者之间的网络出现故障。 无论出现哪种情况，参与者都会在等待超时之后，继续进行事务提交。即，默认为允许提交。 1.2.3 优缺点降低参与者的阻塞范围，出现单点故障后继续达成一致；但是在参与者接收到PreCommit消息后，如果协调者所在的节点和参与者无法正常通信， 该参与者仍然会进行事务的提交，这必然出现数据不一致性。 2. Paxos算法我们将重点讲解另一种非常重要的分布式一致性协议：Paxos。Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式 一致性问题最有效的算法之一。 我们现在已经知道，在常见的分布式系统中，总会发生诸如机器宕机或网络异常等情况。Paxos算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中， 快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常都不会破坏整个系统的一致性。 2.1 追本溯源1982年，Lamport与另两人提出了一种计算容错理论。在理论描述过程中，为了将要所描述的问题形象的表达出来，Lamport设想出了下面这样一个场景： 拜占庭帝国有许多支军队，不同军队的将军之间必须制定一个统一的行动计划，从而做出进攻或者撤退的决定，同时，各个将军在地理上都是被 分割开来的，只能依靠军队的通讯员来进行通讯。然而，在所有的通讯员中可能会存在叛徒，这些叛徒可以任意篡改消息，从而达到欺骗将军的目的。 这就是著名的“拜占庭将军问题”。从理论上来说，在分布式计算领域，试图在异步系统和不可靠的通道上来达到一致性状态是不可能的，因此在堆一致性的研究 过程中，都往往假设信道是可靠地。而事实上，大多数系统都是部署在同一个局域网中的，因此消息被篡改的情况非常罕见，另一方面，由于硬件和网络原因而 造成的消息不完整问题，只需一套简单的校验算法即可避免——因此，在实际工程实践中，可以假设不存在拜占庭问题，也即假设所有消息都是完整的，没有被 篡改的。那么，在这种情况下需要什么样的算法来保证一致性呢？ Lamport在1990年提出了一个理论上的一致性解决方案，同时给出了严格的数学证明。鉴于之前采用故事类比的方式成功的阐述了“拜占庭将军问题”，因此这次Lamport 同样用新娘库地设想除了一个场景来描述这种一致性算法需要解决的问题，及其具体的解决过程： 在古希腊有一个叫Paxos的小岛，岛上采用议会的形式来通过法令，议会中的议员通过信使进行消息的传递。值得注意的是，议员和信使都是兼职的， 他们随时有可能会离开议会厅，并且信使可能会重复的传递消息，也可能一去不复返。因此，议会协议要保证在这种情况下法令仍然能够正确的产生， 并且不会出现冲突。 这就是兼职议会，而Paxos算法名称的由来也是取自提到的Paxos小岛。 2.2 Paxos算法详解Paxos作为一种提高分布式系统容错性的一致性算法，一直以来总是被很多人抱怨其算法理论太难理解。 2.2.1 问题描述： 假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点： 在这些被提出的提案中，只有一个会被选中。 如果没有提案被提出，那么就不会有被选定的提案。 当一个提案被选定后，进程应该可以获取被选定的提案信息。 对于一致性来说，安全性需求如下： 只有被提出的提案才能被选定。 只能由一个值被选定。 如果某个进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个。 在对Paxos算法的讲解过程中，我们不去精确地定义其活性需求，从整体上来说，Paxos算法的目标就是要保证最终有一个提案会被选定，当提案被选定后， 进程最终也能获取到被选定的提案。 在该一致性算法中，有三种参与角色，我们用Proposer、Acceptor、Learner来表示，在具体的实现中，一个进程可能充当不止一种角色，在这里我们并 不关心进程如何映射到各种角色。假设不同参与者之间可以通过收发消息来进行通信，那么： 每个参与者以任意的速度执行，可能会因为出错而停止，也可能会重启。同时，即使一个提案被选定后，所有的参与者也都有可能失败或重启，因此除非 哪些失败或重启的参与者可以记录某些信息，否则将无法确定最终的值。 消息在传输过程中可能会出现不可预知的延迟，也可能会重复或丢失，但是消息不会被损坏。2.2.2 提案的选定要选定一个唯一提案的最简单方式莫过于只允许一个Accpetor存在，这样的话，Proposer只能发送提案给该Accpetor，Acceptor会选择它接收到的第一个 提案作为被选定的提案。这种解决方式尽管实现起来非常简单，但是却很难让人满意，因为一旦这个Accpetor出现问题，那么整个系统就无法工作了。 因此，应该寻找一种更好的解决方式，例如可以使用多个Acceptor来避免Accpetor的单点问题。现在我们就来看看，在存在多个Acceptor的情况下，如何 进行提案的选取：Proposer向一个Acceptor集合发送提案，同样，集合中的每个Acceptor都可能会批准该提案，当有足够多的Acceptor批准这个提案的时候， 我们就可以认为该提案被选定了。那么，什么是足够多呢？我们假定足够多的Acceptor是整个Acceptor集合的一个子集，并且让这个集合大得可以包含Acceptor 集合中的大多数成员，因为任意炼哥包含大多数Acceptor的子集至少有一个公共成员。另外我们再规定，每一个Acceptor最多只能批准一个提案，那么就能 保证只有一个提案被选定了。 2.2.3 推导过程在没有失败和消息丢失的情况下，如果我们希望即使在只有一个提案被提出的情况下，仍然可以选出一个提案，这就暗示了如下的需求。 P1：一个Acceptor必须批准它收到的第一个提案。 上面这个需求就引出了另外一个问题：如果有多个提案被不同的Proposer同时提出，这可能会导致虽然每个Acceptor都批准了它收到的第一个提案，但是没有一个 提案是由多数人批准的。可能会现以下两种情况Acceptor接收的提案数量相同，此时无法选定最终的提案了。因此，在P1的基础上，需要再加上一个提案被选定需要由半数以上的Acceptor批准的需求暗示着一个Acceptor必须能够批准不止一个提案。在这里，我们使用一个全局的编号 （这种全局唯一编号的生成并不是Paxos算法需要关注的地方，就算法本身而言，其假设当前已经具备这样的外部组件能够生成一个全局唯一的编号）来标识每一个 被Acceptor批准的提案，当一个具有某Value值的提案被半数以上的Acceptor批准后，我们就认为该Value被选定了，此时我们也认为该提案被选定了。需要注意的是， 此处讲到的提案和Value不是同一个概念了，提案变成了由编号和Value组成的组合体，因此我们以“[编号，Value]”来表示一个提案。（编号多少的提案被选中了，其中value是多少） 根据上面讲到的内容，我们虽然允许多个提案被选定，但同时必须保证所有被选定的提案都具有相同的Value值——这是一个关于提案Value的约定，结合提案 的编号，该约定可以定义如下： P2：如果编号为M0、Value值为V0的提案（即[M0、V0]）被选定了，那么所有比编号M0更高的，且被选定的提案，其Value值必须也是V0。 因为提案的编号是全序的，条件P2就保证了只有一个Value值被选定这一关键安全性属性。同时，一个提案要被选定，其首先必须至少一个Acceptor批准，因此 我们可以通过满足如下条件来满足P2。 P2a：如果编号为M0、Value值为V0的提案（即[M0、V0]）被选定了，那么所有比编号M0更高的，且被Acceptor批准的提案，其Value值必须也是V0。 至此，我们仍然需要P1来保证提案会被选定，但是因为通信是异步的，一个提案可能在某个Acceptor还未收到任何提案时就被选定了。如上图，在Acceptor1没有接收到任何提案的情况下，其他4个Acceptor已经批准了来自Proposer2的提案[M0,V1]，而此时，Proposer1产生了一个具有其他Value值的、 编号更高的提案[M1,V2]，并发送给了Acceptor1。根据P1，就需要Acceptor1批准该提案，但是这与P2a矛盾，因此如果要同时满足P1和P2a，需要对P2a进行如下强化： P2b：如果一个提案[M0,V0]被选定后，那么之后任何Proposer产生的编号的提案，其Value值都为V0。 因为一个提案必须在被Proposer提出后才能被Acceptor批准，因此P2b包含了P2a，进而包含了P2。于是，接下去的重点就是论证P2b成立即可： 假设某个提案[M0,V0]已经被选定了，证明任何编号Mn &gt; M0的提案，其Value值都是V0。 2.2.4 数学归纳法证明略过。 2.2.5 Proposer生成提案对于一个Proposer来说，获取哪些已经被通过的提案远比预测未来可能会被通过的提案来得简单。因此，Proposer在产生一个编号为Mn的提案时， 必须要知道当前某一个将要或已经被半数以上Acceptor批准的、编号小于Mn但为最大编号的提案。并且，Proposer会要求所有的Acceptor都不要 再批准任何编号小于Mn的提案——这就引出了如下的提案生成算法。 .1 Proposer选择一个新的提案编号Mn，然后向某个Acceptor集合的成员发送请求，要求该集合中的Acceptor做出如下回应。 向Proposer承诺，保证不再批准任何编号小于Mn的提案。 如果Acceptor已经批准过任何提案，那么其就向Proposer反馈当前该Acceptor已经批准的编号小于Mn但为最大编号的那个提案的值。 我们将该请求称为编号为Mn的提案的Prepare请求。 .2 如果Proposer收到了来自半数以上的Acceptor的响应结果，那么它就可以产生编号为Mn、Value值的Vn的提案，这里的Vn是所有响应中编号最大的提案的Value值。当然还存在另一种情况，就是半数以上的Acceptor都没有批准过任何提案，即响应不包含任何的提案，那么此时Vn值就可以 由Proposer任意选择。 在确定提案之后，Proposer就会将该提案再次发送给某个Acceptor集合，并期望获得它们的批准，我们称此请求为Accept请求。需要注意的一点是， 此时接受Accept请求的Acceptor集合不一定是之前响应Prepare请求的Acceptor集合——这点相信读者也能够明白，任意两个半数以上的Acceptor集合，必定 包含至少一个公共Acceptor。 2.2.6 Acceptor批准提案在上文中，我们已经讲解了Paxos算法中Proposer的处理逻辑，下面我们来看看Acceptor是如何批准提案的。 根据上面的内容，一个Acceptor可能会收到来自Proposer的两种请求，分别是Prepare请求和Accept请求，对这两类请求做出相应的条件分别如下。 Prepare请求：Acceptor可以在任何时候响应一个Prepare请求。 Accept请求：在不违背Accept现有承诺的前提下，可以任意响应Accept请求。因此，对Acceptor逻辑处理的约束条件，大体可以定义如下。 P1a：一个Acceptor只要尚未响应过任何编号大于Mn的prepare请求，那么它就可以接受这个编号为Mn的提案。 从上面这个约束条件中，我们可以看出，P1a包含了P1。同时，值得一提的是，Paxos算法允许Acceptor忽略任何请求而不用担心破坏其算法的安全性。 2.2.7 算法优化在上面的内容中，我们分别从Proposer和Acceptor对提案的生成和批准两方面来讲解了Paxos算法在提案选定过程中的算法细节，同时也在提案的编号全局唯一 的前提下，获得了一个满足安全性需求的提案选定算法，接下来我们再对这个初步算法做一个小优化。尽可能地忽略Prepare请求： 假设一个Acceptor收到了一个编号为Mn的prepare请求，但此时该Acceptor已经对编号大于Mn的prepare请求做出了响应，因此它肯定不会再批准 任何新的编号为Mn的提案，那么狠显然，Acceptor就没有必要对这个Prepare请求做出响应，于是Acceptor可以炫册忽略这样的Prepare请求。同时 Acceptor也可以忽略掉那些它已经批准过的提案的Prepare请求。 通过这个优化，每个Acceptor只需要记住它已经批准的提案的最大编号以及它已经做出Prepare请求响应的提案的最大编号，以便在出现故障或节点重启的情况下， 也能保证P2c的不变性。而对于Proposer来说，只要它可以保证不会产生具有相同编号的提案，那么就可以丢弃任意的提案以及它所有的运行时状态信息。 2.2.8 算法陈述.1 阶段一： Proposer选择一个提案编号Mn，然后向Acceptor的某个超过半数的子集成员发送编号为Mn的Prepare请求。 如果一个Acceptor收到一个编号为Mn的Prepare请求，且编号Mn大于该Acceptor已经响应的所有Prepare请求的编号，那么它就会将它已经批准过的最大编号的提案 作为响应反馈给Proposer，同时Acceptor会承诺不会再批准任何编号小于Mn的提案。 举个例子来说，假定一个Acceptor已经响应过的所有Prepare请求对应的提案编号分别为1、2、…、5和7，那么该Acceptor在接收到一个编号为8的 Prepare请求后，就会将编号为7的提案作为响应反馈给Proposer。 .2 阶段二： 如果Proposer收到来自半数以上的Acceptor对于其发出的编号为Mn的Prepare请求的响应，那么它就会发送一个针对[Mn，Vn]提案的Accept请求给Acceptor。 注意，Vn的值就是收到的响应中编号最大的提案的值，如果响应中不包含任何提案，那么它就是任意值。 如果Acceptor收到这个针对[Mn，Vn]提案的Accep请求，只要改Acceptor尚未对编号大于Mn的Prepare请求做出响应，它就可以通过这个提案。 当然，在实际运行过程中，每一个Proposer都有可能会产生多个提案，但只要每个Proposer都遵循如上所述的算法运行，就一定能够保证算法执行的正确性。 值得一提的是，每个Proposer都可以在任意时刻丢弃一个提案，哪怕针对该提案的请求和响应在提案被丢弃后会到达，但根据Paxos算法的一系列规约，依然可以保证 其在提案选定上的正确性，事实上，如果某个Proposer已经在试图 生成编号更大的提案，那么丢弃一些旧的提案未尝不是一个好的选择。 因此，如果一个Acceptor因为已经收到过更大编号的Prepare请求而忽略某个编号更小的Prepare或者Accept请求，那么它也应当通知其对应的Proposer， 以便该Proposer也能够将该提案进行丢弃——这和上面“算法优化”部分中提到的提案丢弃是一致的。 2.2.9 提案的获取在上文中，我们已经介绍了如何来选定一个提案，下面我们再来看看如何让Learner获取提案，大体可以有以下几种方案。 .1 方案一：Learner获取一个已经被选定的提案的前提是，该提案已经被半数以上的Acceptor批准。因此，最简单的做法就是一旦Acceptor批准了一个提案，就将该 提案发送给所有的Learner。很显然，这种做法虽然可以让Learner尽快地获取被选定的提案，但是却需要让每个Acceptor与所有的Learner逐个进行一次通信，通信的次数至少为二者个数的乘积。 .2 方案二：另一种可行的方案是，我们可以让所有的Acceptor将它们对提案的批准情况，统一发送给一个特定的Learner（下文中我们将这样的Learner称为“主Learner”）， 在不考虑拜占庭奖金问题的前提下，我们假定Learner之间可以通过消息通信来互相感知提案的选定情况。基于这样的前提，当主learner被通知一个提案 已经被选定时，它会负责通知其它的Learner。 在这种方案中，Acceptor首先会将得到批准的提案发送给主Learner，再由其同步给其他Learner，因此较方案一而言，方案二虽然需要多一个步骤才能将 提案通知到所有的Learner，但其通信次数却大大减少了，通常只是Acceptor和Learner的个数总和。但同时，该方案引入了一个新的不稳定因素：主Learner随时可能出现故障。 .3 方案三：在讲解方案二的时候，我们提到，方案二最大的问题在于主Learner存在单点问题，即主Learner随时可能出现故障。因此，对方案二进行改进，可以将主Learner的范围扩大， 即Acceptor可以将批准的提案发送给一个特定的Learner集合，该集合中的每个Learner都可以在一个提案被选定后通知所有其他的Learner。 这个Learner集合中的Learner个数越多，可靠性就越好，但同时网络通信的复杂度也就越高。 2.2.10 通过选取主Proposer保证算法的活性根据前面的内容坚决，我们已经基本了解Paxos算法的核心逻辑，下面我们再来看看Paxos算法在实际运作过程中的一些细节。假设存在这样一种极端情况， 有两个Proposer依次提出了一系列编号递增的议案，但是最终都无法被选定，具体流程如下： Proposer P1提出了一个编号为M1的提案，并完成了上述阶段一的流程。但与此同时，另外一个Propoesr P2提出了一个编号为M2的提案，同样也完成了 阶段一的流程，于是Acceptor已经承诺不再批准编号小于M2的提案了。因此，当P1进入阶段二的时候，其发出的Accept请求将被Acceptor忽略， 于是P1再次进入阶段一并提出了一个编号为M3的提案，而这又导致P2在第二阶段的Accept请求被忽略，以此类推，提案的选定过程将陷入死循环。 为了保证Paxos算法流程的可持续性，以避免陷入上述提到的“死循环”，就必须选择一个主Proposer，并规定只有主Proposer才能提出议案。这样一来， 只要主Proposer和过半的Acceptor能够正常进行网络通信，那么但凡主Proposer提出一个编号更高的提案，该提案终将会被批准。当然，如果Proposer发现当前 算法流程中已经有一个编号更大的提案被提出或正在接受批准，那么它会丢弃当前这个编号较小的提案，并最终能够选出一个编号足够大的提案。因此， 如果系统中有足够多的组件（包括Propsoer、Acceptor和其他网络通信组件）能够正常工作，那么通过选择一个主Proposer，整套Paxos算法流程就能够保持活性。 3 小结2PC和3PC：1.牧师分别问新郎和新娘：你是否愿意……不管生老病死……（投票阶段）。2.当新郎和新娘都回答愿意后（锁定一生的资源，只要有一个没有反应，这场结婚就失败）。（投票阶段）3.牧师就会说：我宣布你们……（执行阶段）。存在的问题：1.阻塞问题：如果新郎回答原意，新娘没反应，则整个结婚就阻塞。（投票阶段之后增加眼神交流阶段（3PC的额外阶段），之后才真正承诺一生一世不分离即锁定资源）。2.单点问题：如果牧师没反应，整个结婚就失败。（3PC的超时机制，给牧师5秒反应时间） 主要从协议设计和原理实现角度详细讲解了二阶段提交协议、三阶段提交协议和Paxos这三种典型的一致性算法。其中二阶段提交协议解决了分布式事务的原子性问题， 保证了分布式事务的多个参与者要么都执行成功，要么都执行失败。但是，在二阶段解决部分分布式事务问题的同时，依然存在一些难以解决的诸如同步阻塞、 无限期等待问题。三阶段提交协议则是在二阶段提交协议的基础上，添加了PreCommit过程，从而避免了二阶段提交协议中的无限期等待问题。而Paxos算法支持 分布式节点角色之间的轮换，这极大地避免了分布式单点的出现，因此Paxos算法既解决了无限期等待问题，是目前来说最优秀的分布式一致性协议之一。传送门，视频30分钟讲解paxos的演变]]></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一、分布式架构]]></title>
    <url>%2F2017%2F08%2F17%2Fzookeeper%2F1_%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84.html%2F</url>
    <content type="text"><![CDATA[1. 从集中式到分布式1.1 集中式的特点所谓的集中式系统就是指由一台或多台主计算机组成中心节点，数据集中存储于这个中心节点，并且整个系统的所有业务单元都部署在这个中心节点上， 系统的所有功能均由其集中处理。也就是说，在集中式系统中，每个终端或客户端机器仅仅负责数据的录入和输出，而数据的存储与控制处理完全 交由主机来完成。 最大的特点就是部署结构简单。由于集中式系统往往基于底层性能卓越的大型主机，因此无须考虑如何对服务进行多个节点的部署，也就不用考虑多个 节点之间的分布式协作问题。 1.2 分布式的特点 分布式系统是一个硬件或者软件组成分布在不同的网络计算上，彼此之间仅仅通过消息传递进行通信和协调的系统。 一个标准的分布式系统在没有任何特定业务逻辑约束的情况下，都会有如下几个特征： 分布性：分布式系统中的多台计算机在空间上随意分布。 对等性：分布式系统中的计算机没有主/从之分，既没有控制整个系统的主机，也没有被控制的从机，组成分布式系统的所有计算机节点都是对等的。 副本（Replica）是分布式系统最常见的概念之一，指的是分布式系统对数据和服务提供一种冗余方式。在常见的分布式系统中，为了对外提供高可用的服务， 我们往往会对数据和服务进行副本处理。不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取到该数据，另一类副本是 服务副本，指多个节点提供同样的服务，每个节点都有能力接收来自外部的请求并进行相应的处理。 并发性：同一个分布式系统中的多个节点，可能会并发地操作一些共享的资源，诸如数据库或分布式存储等，如何准确并高效地协调分布式并发操作也成为了分布式 系统架构与设计中最大的挑战之一。 缺乏全局时钟：一个典型的分布式系统是由一系列在空间上随意分布的多个进程组成的，具有明显的分布性，这些进程之间通过交换下次来进行相互通信。 因此，在分布式系统中，很难定义两个时间的顺序，原因就是因为分布式系统缺乏一个全局的时钟序列控制。 故障总是会发生：组成分布式系统的所有计算机，都有可能发生任何形式的故障。任何在设计阶段考虑到的异常情况，一定会在系统实际运行中发生！ 1.3 分布式环境的各种问题1.3.1 通信异常分布式引入了网络因素，而由于网络本身的不可靠性，因此每次网络通信都会伴随网络不可用的风险，网络光纤、路由器和DNS等。因此消息丢失和消息延迟变得非常普遍。 1.3.2 网络分区当网络由于发生异常情况，导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点中，只有部分节点之间能够正常通信， 而另一些节点则不能——我们将这个现象称为网络分区。网络分区出现时，分布式系统会出现局部小集群，在极端情况下，这些局部小集群会独立完成原本 需要整个分布式系统才能完成的功能，包括对数据的事务处理，这就对分布式一致性提出了非常大的挑战（某个复杂业务原本需要多个机器完成，现在被一个机器 执行）。 1.3.3 三态分布式系统的每一次请求与响应，存在特有的“三态”概念，即成功、失败与超时。超时的现象，通常有以下两种情况： 由于网络原因，请求并没有被成功地发送到接收方，在发送过程就发生了消息丢失现象。 请求成功的被接收方接收后，并进行了处理，但是在将响应反馈给发送方的过程中，发生了消息丢失现象。（rabitMQ的解决方案是，消费者（接收方）开始处理消息前发送响应A， 消费者（接收方）处理完成消息后发送响应B，生产者（发送方）必须得到AB两个响应才能确定消息成功被处理了） 2. 从ACID到CAP/BASE2.1 ACID事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元（Unit）。 2.1.1 原子性（Atomicity）要么全部成功执行，要么全部不执行。 2.1.2 一致性（Consistency）事务的运行被迫中断时，这些未完成的事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于不一致的状态。 2.1.3 隔离性（Isolation）并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。SQL规范定义了4个事务隔离级别： 读未提交（Read Uncommitted）：A事务更新过程中，从1更新到10，B事务能获取过程中间值，获取到2，3等值。（脏读） 读已提交（Read Committed）：A事务更新过程中，从1更新到10，B事务只能获取最终的值10。 可重复读（Repeatable Read）：A事务更新过程中，从1更新到10，B事务先获取了1，后来B事务中有个操作重新获取了一次值为10。（幻影读） 串行化（Serializable）：事务只能串行执行，不能并发。 2.1.4 持久性（Durability）事务一旦提交，对数据库对应数据的状态变更就应该被永久保存下来。 2.1 分布式事务设想一个最典型的分布式事务场景：一个跨银行的转账操作涉及调用两个异地的银行服务，其中一个是本地银行提供的取款服务，另一个则是目标银行提供的存款 服务，这两个服务本身是无状态并且是互相独立的，共同构成了一个完整的分布式事务。如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么 就必须回滚到取款前的状态，否则用户可能会发现自己的钱不翼而飞了。 我们可以看到，一个分布式事务可以看作是由多个分布式的操作序列组成的，例如上面例子中的取款服务和存款服务，通常可以把这一系列分布式的操作序列称为 子事务。因为，分布式事务也可以被定义为一种嵌套型的事务，同时也就具有了ACID事务特性。但由于在分布式事务中，各个子事务的执行时分布式的， 因此要实现一种能够保证ACID特性的分布式事务处理系统就显得格外复杂。 2.3 CAP和BASE理论ACID是属于单机系统的理论，分布式有属于自己的理论，即CAP和BASE。 2.3.1 CAP定理一个分布式系统不可能同时满足一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）这三个基本需求，最多只能同时 满足其中的两项。 .1 Consistency在分布式环境下，数据在多个副本之间是否能够保持一致性，当某个副本执行更新操作后，应该保证系统的数据仍然处于一致的状态。如果做到一个数据项的更新 操作执行成功后，所有的用户都可以读取到最新的值，那么这样的系统就被认为具有强一致性。 .2 Availability对于用户的每一个操作请求总是能够在有限的时间内返回结果。划重点：有限的时间内、返回结果。 有限的时间内：对于用户的一个艹做请求，系统必须能够在指定的时间内返回对应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。 比如，对于一个在线搜索引擎来说，通常在0.5秒内需要给出用户搜索关键词对应的检索结果，而对于一个面向HIVE的海量数据查询平台来说，正常一次数据 检索时间可能在20秒，这是正常的，系统必须存在一个合理的响应时间。 返回结果：要求系统在完成堆用户请求的处理后，返回一个正常的结果，而不是返回系统错误。 .3 Partition tolerance分布式系统在遇到任何网络分区故障的时候（节点间的故障），仍然需要保证对外提供满足一致性和可用性的服务，除非整个网络环境发生了故障。 .4 总结 AC：所有的数据都放在一个分布式节点上。（谈什么分布式？） PC：系统正在维修，请等待。（要么可用，要么直接不能访问） AP：放弃数据的强一致性，保留数据额最终一致性。（双11xx商品正在被5126人浏览，可能每个人看到的数字都不一样，但是系统最终会让所有人看到一样的数字） 2.3.2 BASE理论基于CAP定理结合实际演化而来，即Basically Available（基本可用）、Soft state（软状态）、Eventually consistency（最终一致性）。 .1 Basically Available分布式在出现不可预知故障的时候，允许损失部分可用性： 响应时间上的损失：搜索正常是0.5秒返回用户，出现故障变成2秒。 功能上的损失：网上购物在双11时选择购买可能会跳转到排队页面。 .2 Soft state允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 .3 Eventually consistency强调数据最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 在实际工程实践中，最终一致性存在以下五类主要变种。 .3.1 因果一致性（Causal consistency）进程A更新完某个数据项后通知了进程B，那么进程B之后对该数据的访问都应该能够获取到进程A更新后的最新纸，并且如果进程B要对该数据项进行更新操作的话， 务必基于进程A更新后的最新值。而进程C的数据访问则没有这样的限制。 .3.2 读己之所写（Read your writes）进程A更新了一个数据项，它自己总是能够访问到更新过的最新值。特殊的因果一致性（A进程通知了A进程）。 .3.3 会话一致性（Session consistency）系统能保证在同一个有效的会话中实现“读己之所写”的一致性，即客户端能够在同一绘画中始终读取到该数据项的最新值。 .3.4 单调读一致性（Monotonic read consistency）如果一个进程从系统读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。 .3.5 单调写一致性（Monotonic write consistency）系统保证来自同一个进程的写操作被顺序地执行。 .3.6 总结最终一致性并不是只有那些大型分布式系统才涉及的特性，许多关系型数据库都采用了最终一致性模型，采用同步和异步方式来实现主备数据复制技术。 在同步方式中，数据的复制过程通常是更新事务的一部分，因此在书屋完成后，主备数据库的数据就会达到一致。 在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长达，如果传输时间过长或者甚至在日志传输过程中出现异常导致 无法及时将事务应用到备库上，那么很显然，从备库读取的数据将是旧的，就出现了数据不一致的情况。 但是，无论采用重试、人为修正，关系型数据库还是能够保证最终数据达到一致性——这就是系统提供最终一致性保证的经典案例。 总的来说，BASE理论面向大型高可用可扩展的分布式系统，和传统事务的ACID特性是相反的，不同于ACID的强一致性模型，而是通过强一致性和高可用性的 平衡，最终达到一致性。因此在具体的分布式系统架构设计过程中，ACID和BASE理论往往会结合一起使用用来面对不同的业务场景的要求。 3. 小结分布式架构发展过程中的ACID-&gt;CAP-&gt;BASE等分布式事务与一致性方面的经典理论。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>从Paxos到Zookeeper分布式一致性原理与实践</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[线程间通信]]></title>
    <url>%2F2017%2F08%2F17%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F%E4%B8%80%E3%80%81%E7%BA%BF%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"></content>
      <categories>
        <category>Java多线程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[十、深入理解Session与Cookie]]></title>
    <url>%2F2017%2F08%2F17%2Fdeepknowjavaweb%2F10_%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Session%E4%B8%8ECookie.html%2F</url>
    <content type="text"><![CDATA[本章概要：当我们的一个应用系统有几百台服务器时，如何解决Session在多台服务器之间共享的问题？它们还有一些安全问题，如Cookie被盗、Cookie伪造等问题应 如何避免？Session与Cookie的作用都是为了保持访问用户与后端服务器的交互状态。例如，使用Cookie来传递信息时，随着Cookie个数的增多和访问量的 增加，它占用的网络带宽也很大，试想假如Cookie占用200个字节，如果一天的PV有几亿，那么它要占用多少带宽？所以有大访问量时希望用Session，但是 Session的致命弱点是不容易在多台服务器之间共享，这也限制了Session的使用。 1. 理解CookieCookie的作用通俗地说就是当一个用户通过HTTP访问一个服务器时，这个服务器会将一些Key/Value键值对返回给客户端浏览器，并给这些数据加上一些 限制条件，在条件符合时这个用户下次访问这个服务器时，数据又被完整地带回给服务器。 当初W3C设计Cookie时实际考虑的是为了记录用户在一段时间内访问Web应用的行为路径。由于HTTP是一种无状态协议，当用户的一次访问请求结束后， 后端服务器就无法知道下一次来访问的还是不是上次访问的用户。例如，在一个很短的时间内，如果与用户相关的数据被频繁访问，可以针对这个数据做缓存， 这样可以大大提高数据的访问性能。Cookie的作用正是如此，由于是同一个客户端发出的请求，每次发出的请求都会带有第一次访问时，服务端设置的信息， 这样服务端就可以根据Cookie值来划分访问的用户了。 1.1 Cookie属性项当前Cookie有两个版本：Version0和Version1，它们有两种设置响应头的标识，分别是“Set-Cookie”和“Set-Cookie2”。它们属性项有些不同。 Version0属性项： 属性项 属性项介绍 NAME=VALUE 设置要保存的Key/Value，注意这里的NAME不能和其它属性项的名字一样 Expires 过期时间 Domain 生成该Cookie的域名 Path 该Cookie是在当前哪个路径下生成的 Secure 如果设置了这个属性，那么只会在SSH连接时才会回传该Cookie Expires 过期时间 在Java Web的Servlet规范并不支持Set-Cookie2响应头，在实际应用中Set-Cookie2的一些属性项却可以设置在Set-Cookie中。博主在查看Cookie源码， 发现是支持的： 另外也可以从源码可以得知，一般所说的Cookie键值对，都是值NAME和VALUE属性，其实Cookie还有其他的属性，通过Get/Set方法进行获取和设置。 另外下面是博主在使用Chrome浏览器查看的Cookie： 1.2 Cookie如何工作当我们用如下方式创建Cookie时： 123456789101112131415161718192021222324String getCookie(Cookie[] cookies, String key) &#123; if (cookies != null) &#123; for (Cookie cookie : cookies) &#123; if (cookie.getName().equals(key)) &#123; return cookie.getValue(); &#125; &#125; &#125; return null;&#125;@Overridepublic void doGet(HttpServletRequest req, HttpServletResponse res) &#123; Cookie[] cookies = req.getCookies(); String userName = getCookie(cookies, "userName"); String userAge = getCookie(cookies, "userAge"); if (userName == null) &#123; res.addCookie(new Cookie("userName", "liwenguang")); &#125; if (userAge == null) &#123; res.addCookie(new Cookie("userAge", "22")); &#125; res.getHeaders("Set-Cookie");&#125; 以下几点需要注意： 所创建Cookie的NAME不能和Set-Cookie或者Set-Cookie2的属性项值一样。 所创建Cookie的NAME和VALUE的值不能设置成非ASCII字符，如果要使用中文，可以通过URLEncoder将其编码。 当NAME和VALUE的值出现一些TOKEN字符（如“\”、“，”等）时，构建返回头会将该Cookie的Version自动设置为1。 当在该Cookie的属性项中出现Version为1的属性项时，构建HTTP响应头同样会将Version设置为1。 1.3 使用Cookie的限制任何语言对Cookie的操作，其实都是让浏览器对Cookie的操作，Cookie的浏览器的特性，而浏览器对Cookie有数量限制（50个/每个域名），总大小限制（4096，Chrome没有这个限制）。 2 理解Session前面已经介绍了Cookie可以让服务端程序跟踪每个客户端的访问，但是每次客户端的访问都必须传回这些Cookie，如果Cookie很多，则无形地增加了客户端 与服务端的数据传输量，而Session的出现正是为了解决这个问题。 同一个客户端每次和服务端交互时，不需要每次都传回所有的Cookie值，而是只要传回一个ID，这个ID是客户端第一次访问服务端时生成的，而且每个客户端是唯一的。 这样每个客户端就有了一个唯一的ID，客户端只要传回这个ID就行了，这个ID通常是NAME为JSESIONID的一个Cookie。 2.1 Session与Cookie下面详解讲一下Session是如何基于Cookie来工作的。实际上有以下三种方式可以让Session正常工作。 基于URL Path Parameter，默认支持。 基于Cookie，如果没有修改Context容器的Cookies标识，则默认也是支持的。 基于SSL，默认不支持，只有connector.getAttribute(“SSLEnabled”)为TRUE时才支持。 在第一种情况，当浏览器不支持Cookie功能时，浏览器会将用户的SessionCookieName重写到用户请求的URL参数中，传递格式如/path/Servlet;name=value;name2=value2?Name3=value3， 其中“Servlet；”后面的K-V就是要传递的Path Parameters，服务器会从这个Path Parameters中拿到用户配置的SessionCookieName。关于这个SessionCookieName， 如果在web.xml中配置session-config配置项，其cookie-config下的name属性就是这个SessionCookieName的值。如果没有配置sessio-config配置项， 默认的SessionCookieName就是大家熟悉的“JSESSIONID”。需要说明的一点是，与Session关联的Cookie与其他Cookie没有什么不同。接着Request根据这个SessionCookieName 到Parameters中拿到Session ID并设置到request.setRequestedSessionId中。 请注意，如果客户端也支持Cookie，则Tomcat仍然会解析Cookie中的Session ID，并会覆盖URL中的Session ID。 如果是第三种情况，则会根据javax.servlet.request.ssl_session属性值设置Session ID。 2.2 Session如何工作有了Session ID，服务端就可以创建HttpSession对象了，第一次触发通过request.getSession()方法。如果当前的Session ID还没有对应的HttpSession对象， 那么就创建一个新的，并将这个对象加到org.apache.catalina.Manager的session容器中保存。Manager类将管理所有Session生命周期，Session过期将被回收， 服务器关闭，Sessoin将被序列化到磁盘等。只要这个HttpSession对象存在，用户就可以根据Session ID来获取这个对象，也就做到了对状态的保持。从Request中获取的Session对象保存在org.apache.catalina.Manager类中，它的实现类是org.apache.catalina.session.StandardManager，通过 requestedSessionId从StandardManager的Sessions集合取出对应的StandardSession对象。由于一个requestedSessionId对应一个访问的客户端， 所以一个客户端也就对应了一个StandardSession对象，这个对象正是保存我们创建的Session值的。下面我们看一下StandardManager这个类是如何管理StandardSession 的生命周期的。 StandardManager类负责Servlet容器中所有的StandardSession对象的生命周期管理。当Servlet容器重启或关闭时，StandardManager负责持久化没有过期的 StandardSession对象，它会将所有的StandardSession对象持久化到一个以“SESSIONS。ser”为文件名的文件中。到Servlet容器重启时，也就是StandardManager 初始化时，它会重新读取这个文件，解析出所有Session对象，重新保存在StandardManager的sessions集合中。 当Servlet容器关闭时StandardManager类会调用unload方法将session集合中的StandardSession对象写到“SESSIONS.ser”文件中，然后在启动时 再重新恢复，注意要持久化保存Servlet容器中的Session对象，必须调用Servlet容器的stop的start命令，而不能直接结束（kill）Servlet容器的进程。 因为直接结束进程，Servlet容器没有机会调用unload方法来持久化这些Session对象。 另外，在StandardManager的sessions集合中的StandardSession对象并不是永远保存的，否则Servlet容器的内存将容易被消耗尽，所以必须给每个Session对象定义一个有效时间， 超过这个时间则Session对象将被清除。在Tomcat中这个有效时间是60s（maxInactiveInterval属性通知），超过60s该Session将会过期。检查每个Session是否失效是 Tomcat的一个后台线程中完成的。 除了后台进程检查Session是否失效外，当调用request.getSession()时也会检查该Session是否过期。值得注意的是，request.getSession()方法调用的 StandardSession永远都会存在，即使与这个客户端关联的Session对象已经过期。如果过期，则又会重新创建一个全新的StandardSession对象，但是 以前设置的Session值将会丢失。如果你取到了Session对象，但是通过session.getAttribute取不到前面设置的Session值，请不要奇怪，因为很可能已经失效了， 请检查以下中maxInactiveInterval配置项的值，如果不想让Session过期则可以设置为-1。 但是你要仔细评估一下，网站的访问量和设置的Session的大小，防止将你的Servlet容器内存撑爆。如果不想自动创建Session对象，也可以通过 request.getSession(bolean create)方法来判断与该客户端关联的Session对象是否存在。 3 Cookie安全问题Cookie通过把所有要保存的数据通过HTTP的头部从客户端传递到服务端，又从服务端传回到客户端，所有的数据都存储在客户端的浏览器里，所以这些Cookie 数据可以被访问到，通过浏览器插件可以对Cookie进行修改等。 相对而言Session的安全性要高很多，因为Session是将数据保存在服务端，只是通过Cookie传递一个SessionID而已，所以Session更适合存储用户隐私和重要的数据。 4 分布式Session框架4.1 Cookie存在哪些问题 客户端Cookie存储限制 Cookie管理的混乱，每个应用系统都自己管理每个应用使用的Cookie会导致混乱，由于通常应用系统都在同一个于明霞，Cookie又有上面一条提到的限制， 所以统一管理很容易出现Cookie超出限制的情况。 不安全，虽然通过设置HttpOnly属性防止一些私密Cookie被客户端访问，但是仍然不能保证Cookie无法被篡改。为了保证Cookie的私密性通常会对Cookie 进行加密，但是维护这个加密Key也是一件麻烦的事情，无法保证定期更新加密Key也是会带来安全性问题的一个重要因素。 4.2 Cookie+Session可以解决哪些问题下面是分布式Session框架可以解决的问题： Session配置的统一管理。 Cookie使用的监控和统一规范管理。 Session存储的多元化。 Session配置的动态修改。 Session加密key的定期修改。 充分的容灾机制，保持框架的使用稳定性。 Session各种存储的监控和报警支持。 Session框架的可扩展性，兼容更多的Session机制如wapSession。 跨域名Session与Cookie如何共享的问题。现在同一个网站可能存在多个域名，如何将Session和Cookie在不同的域名之间共享是一个具有挑战性的问题。 4.3 总体实现思路为了达成上面所说的几个目标，我们需要一个服务订阅服务器，在应用启动时可以从这个订阅服务器订阅这个应用需要的可写Session项和可写Cookie项， 这些配置的Session和Cookie可以限制这个应用能够使用哪些Session和Cookie，甚至可以通知Session和Cookie可读或可写。这样可以精确地控制哪些应用 可以操作哪些Session和Cookie，可以有效控制Session的安全性和Cookie的数量。如Session的配置项可以为如下形式： 123456789&lt;sessions&gt; &lt;session&gt; &lt;key&gt;sessionID&lt;/key&gt; &lt;cookiekey&gt;sessionID&lt;/cookiekey&gt; &lt;lifeCycle&gt;9000&lt;/lifeCycle&gt; &lt;base64&gt;true&lt;/base64&gt; &lt;/session&gt; .......&lt;/sessions&gt; Cookie的配置可以为如下形式： 1234567891011&lt;cookies&gt; &lt;cookie&gt; &lt;key&gt;cookie&lt;/key&gt; &lt;lifeCycle&gt;10000&lt;/lifeCycle&gt; &lt;type&gt;1&lt;/type&gt; &lt;path&gt;/wp&lt;/path&gt; &lt;domain&gt;liwenguang.website&lt;/domain&gt; &lt;decrypt&gt;false&lt;/decrypt&gt; &lt;httpOnly&gt;false&lt;/httpOnly&gt; &lt;/cookie&gt;&lt;/cookies&gt; 统一通过订阅服务器推送配置可以有效地几种管理资源，所以可以省去每个应用都来配置Cookie，简化Cookie的管理。如果应用要使用一个新增的Cookie， 则可以通过一个统一的平台来申请，申请通过才将这个配置项增加到订阅服务器。如果是一个所有应用都要使用的全局Cookie，那么只需要将这个Cookie通过 订阅服务器统一推送过去就行了，省去了要在每个应用中手动增加Cookie的配置。 关于这个订阅服务器现在有很多开源的配置服务器，如ZooKeeper集群管理服务器，可以统一管理所有服务器的配置文件。 由于应用是一个集群，所以不可能将创建的Session都保存在每台应用服务器的内存中，因为如果每台服务器有几十万的访问用户，那么服务器的内存可能不够用， 即使内存够用，这些Session也无法同步到这个应用的所有服务器中。所以要共享这些Session必须将它们存储在一个分布式缓存中，可以随时写入和读取， 而且性能要很好才能满足要求。当前能满足这个要求的系统有很多，如MemCache或者淘宝的开源分布式缓存系统Tair都是很好的选择。 解决了配置和存储问题，下面看一下如何存取Session和Cookie。 既然是一个分布式Session的处理框架，必然会重新实现HttpSession的操作接口，使得应用操作Session的对象都是我们实现的InnerHttpSession对象， 这个操作必须在进入应用之前完成，所以可以配置一个filter拦截用户的请求。 先看一下如何封装HttpSession对象和拦截请求，如下时序图： 我们可以在应用的web.xml中配置一个SessionFilter，用于在请求到达MVC框架之前封装HttpServletRequest和HttpServletResponse对象，并创建 我们自己的InnerHttpSession对象，把它设置到request和response对象中。这样应用系统通过request.getHttpSession()返回的就是我们创建的 InnerHttpSession对象了，我们可以拦截response的addCookies设置的Cookie。 在时序图中，应用创建的所有Session对象都会保存在InnerHttpSession对象中，当用户的这次访问请求完成时，Session框架将会把这个InnerHttpSession 的所有内容再更新到分布式缓存中，以便于这个用户通过其它服务器再次访问这个应用系统。另外，为了保证一些应用对Session稳定性的特殊要求，可以将一些 非常关键的Session再存储到Cookie中，如当分布式缓存存在问题时，可以将部分Session存储到Cookie中，这样即使分布式缓存出现问题也不会影响关键业务的正常运行。 4.4 增加Session跨域实现还有一个非常重要的问题就是如何处理跨域名来共享Cookie的问题。我们知道Cookie是有域名限制的，也就是在一个域名下的Cookie不能被另一个域名访问， 所以如果在一个域名下已经登录成功，如何访问到另外一个域名的应用且保证登录状态仍然有效，对这个问题大型网站应该经常会遇到。如何解决这个问题呢？ 下面介绍一种处理方式，流程图如下：访问域名A时服务器A获得了session，用户访问域名B时，如果发现服务器B没有session，则跳转到中转服务器C，服务器C进行302重定向到服务器A获得了 session后，则再进行302重定向到A服务器，写入session，从而完成了session跨域。 5 Cookie压缩6 表单重复提交问题7 多终端Session统一8 总结]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[九、Servlet工作原理解析]]></title>
    <url>%2F2017%2F08%2F17%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%B9%9D%E7%AB%A0%EF%BC%9AServlet%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1. 从Servlet容器说起Servlet和Servlet容器的关系像子弹和枪，枪是为子弹而生的，而子弹又让枪有了杀伤力。为了适应工业化生产，他们是相互独立发展，通过标准化接口来相互协作。 Servlet容器种类多，各有各的优缺点，我们以Tomcat为例介绍Servlet容器是如何管理Servlet的。 在Tomcat的容器等级中，Context容器直接管理Servlet在容器中的包装类Wrapper，所以Context容器如何运作将直接影响Servlet的工作方式。分四个等级，真正管理Servlet的容器是Context容器，一个Context对应一个Web工程，Tomcat中WEB容器配置文件：conf/context.xml中的节点配置 Context容器，你可以配置多个。 2. Servlet容器的启动过程现在很多博客已经把Tomcat解析很清晰了，就不再多累赘编写了。另外由于博主一直使用Jetty，因此以后待研究Tomcat或者Jetty。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[内置函数]]></title>
    <url>%2F2017%2F08%2F16%2FSQL%2FMySQL%2F%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172-- 数字类的函数-------------------------------------------------------------------------------- 返回最小的不小于X的整数select CEIL(1.1)select CEILING(-1.1)-- 进制转换，值N，以from的进制，输出为to进制select CONV('a',16,2)-- 计算出循环冗余校验数字select CRC32('MySQL')-- 返回最大的不大于X的整数select FLOOR(2.5)-- 隔断小数点，技巧：后面如果是'en_US'，则实现的四舍五入select FORMAT(123456987.537,0,'en_US');select FORMAT(123456987.437,0);-- 十六进制，如果是Number则返回该数字的十进制，如果是String，则每个字符转化ASCII的16进制表示-- 数字的相反函数：CONV(HEX(255),16,10)，字符的相反函数：UNHEX(HEX('abc')) select HEX(255)select HEX('abc')select UNHEX(HEX('中国'))-- 获取余数select MOD(18, 5)-- 获取X的Y次方select POW(2, -1)select POWER(2, -1)-- 返回-1、0、1select SIGN(54)-- 获取非负数的平方根select SQRT(5)select SQRT(-5)-- 直接截断小数点select TRUNCATE(-215.211,1)-- 日期和时间类的函数-------------------------------------------------------------------------- 获取当前的年月日select now(), CURDATE()-- 增加时间select ADDDATE(CURDATE(),INTERVAL 10 DAY)-- 时区转换，需要设置时区select CONVERT_TZ('2017-01-02 12:21:30','GMT','MET')-- 比较日期，前面减去后面select DATEDIFF('2017-11-30 12:30','2017-11-29 13')-- INTERVAL，具体参数参见：http://imysql.com/mysql-refman/5.7/functions.html#function_date-addselect '2017-01-01 12:12:12' + INTERVAL 1 SECOND-- 日期格式化，具体参数参见：http://imysql.com/mysql-refman/5.7/functions.html#function_date-formatselect DATE_FORMAT('2017-01-01 22:12:32','%W %M %Y')-- 日期减法select DATE_SUB('2017-01-01',INTERVAL 2 DAY)-- 获取星期select DAYNAME('2007-02-03')select DAYOFWEEK('2017-02-03')-- 获取某个月的最后一天select LAST_DAY('2013-02-05 12:32:21')-- 输入天数，获取年月日select MAKEDATE(2017,45)-- 获取月份差select PERIOD_DIFF(200802,200911)-- 获取季度select QUARTER('2017-02-05')-- 秒转化时间select SEC_TO_TIME(2354)-- 字符串转化时间select STR_TO_DATE('a09:12:30','a%h:%i:%s')-- 配合GROUP BY的函数-------------------------------------------------------------------------- 求平均AVG([DISTINCT] expr)-- 求和COUNT(DISTINCT expr,[expr...])-- 字段连接, with rollup将额外多出一条记录用于汇总SELECT id, event_day, GROUP_CONCAT(dimension_value ORDER BY dimension_value DESC SEPARATOR '`') FROM sqq_report.member_dimension_index_day where tenant_id = '9001' AND event_day = 20170815GROUP BY event_day WITH ROLLUP]]></content>
      <categories>
        <category>SQL</category>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[八、JVM内存管理]]></title>
    <url>%2F2017%2F08%2F14%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9AJVM%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. 物理内存与虚拟内存所谓物理内存就是RAM（随机存储器）。在计算机中，还有一个存储单元叫寄存器，它用于存储计算单元执行指令（如浮点、整数等运算时）的中间结果。 寄存器的大小决定了一次计算可使用的最大数值。（博主直接理解成内存条，内存条也是RAM的一种） 连接处理器和RAM或者连接处理器和寄存器的是：地址总线，这个地址总线的宽度影响了物理地址的索引范围，因为总线的宽度决定了处理器一次可以从寄存器 或者内存中获取多少个bit。同时也决定了处理器最大可以寻址的地址空间，如32位地址总线可以寻址的范围为0x0000 0000~0xffff ffff。这个范围 是2^32=4294967296个内存位置，每个地址会引用一个字节，所以32位总线宽度可以有4GB的内存空间。通常情况下，地址总线和寄存器或者RAM有相同的位数，因为这样更容易传输数据。 不管是什么系统，我们要运行程序，都要向操作系统先申请内存地址。通常操作系统管理内存的申请空间是按照进程来管理的，每个进程拥有一段独立的 地址空间，每个进程之间不会相互重合，操作系统也会保证每个进程只能访问自己的内存空间。这主要从程序的安全性来考虑，也便于操作系统来管理物理内存。 其实上面所说的进程的内存空间的独立主要是指逻辑上独立，也就是这个独立是由操作系统来保证的，但是真正的物理空间是不是只能由一个进程来使用就 不一定了。因为随着程序越来越庞大和设计的多任务性，物理内存无法满足程序的需求，在这种情况下就有了虚拟内存的出现。 虚拟内存的出现使得多个进程在同时运行时可以共享物理内存，这里的共享只是空间上共享，在逻辑上它们仍然是不能相互访问的。虚拟地址不但可以让进程 共享物理内存、提高内存利用率，而且还能够扩展内存的地址空间，如一个虚拟地址可能被映射到一段物理内存、文件或者其他可以寻址的存储上。 一个进程在不活动的情况下，操作系统将这个物理内存中的数据移到一个磁盘文件中（也就是通常Windows系统上的页面文件，或者Linux系统上的交换分区）， 而真正高效的物理内存留给正在活动的程序使用。在这种情况下，在我们重新唤醒一个很长时间没有使用的程序时，磁盘会吱吱作响，并且会有一个短暂的 停顿得到印证，这时操作系统又会把磁盘上的数据重新交互到物理内存中。但是我们必须要避免这种情况的经常出现，如果操作系统频繁地交互物理内存的 数据和磁盘数据，则效率将会非常低，尤其在Linux服务器上，我们要关注Linux中swap的分区的活跃度。如果swap分区被频繁使用，系统将会非常缓慢， 很可能意味着物理内存已经验证不足或者某些程序没有及时释放内存（物理内存可以理解为内存条大小）。 程序-&gt;虚拟内存-&gt;物理内存，如果你的内存条是8G，虚拟内存可能是大于8G，因此虚拟内存在某些情况下将磁盘也算了进去（某个程序一直处于后台，就被 放入了磁盘，方便用户更好的利用真正的内存）。 另外，虚拟内存隔绝了程序和物理内存的交互，程序以为是连续的内存地址，实际在物理内存中并不是连续的，这样就可以高效的利用物理内存的碎片。 2. 内核空间与用户空间一个计算机通常有一定大小的内存空间，如使用的计算机是4GB的地址空间，但是程序并不能完全使用这些地址空间，因为这些地址空间被划分为内核空间和 用户空间。程序只能使用用户空间的内存，这里所说的使用是指程序能够申请的内存空间，并不是程序真正访问的地址空间。 内核空间主要是指操作系统运行时所使用的用于程序调度、虚拟内存的使用或者连接硬件资源等的程序逻辑。为何需要内存空间和用户空间的划分呢？很显然 和前面所说的每个进程都独立使用属于自己的内存一样，为了保证安全，访问硬件资源只能由操作系统来发起。用户需要访问硬件资源，如网络连接等， 需要调用操作系统提供的接口实现，这个调用接口的过程也就是系统调用。每一次系统调用都会存在两个内存空间的切换，通常的网络传输也是一次系统调用， 通过网络传输的数据先是从内核空间接收到远程主机的数据，然后再从内核空间复制到用户空间，供用户程序使用 。这种从内核空间到用户空间的数据复制 很费时，以效率换取的安全稳定。 内核空间和用户空间的大小如何分配也是一个问题，是更多地分配给用户空间供用户程序使用，还是首先保住内核有足够的空间来运行，这要平衡一下。 如果是一台登录服务器，要分配更多的内核空间，因为每个登录用户操作系统都会初始化一个用户进程，这个进程大部分都在内核空间里运行。Window32位操作系统默认内核：用户=1:1，即各有2GB，而在Linux32位则是1:3。 3. 在Java中哪些组件需要使用内存Java启动后作为一个进程运行在操作系统中，那么这进程有哪些部分需要分配内存空间呢？ 1. Java堆用于存储Java对象的内存区域，堆的大小在JVM启动时就一次向操作系统申请完成，通过-Xmx和-Xms两个选项来控制大小，Xmx表示堆的最大大小，Xms表示 初始大小。一旦分配完成，堆的大小固定，不能在内存不够时再向操作系统重新申请，同时当内存空闲时也不能将多余的空间交还给操作系统。 在Java堆中内存空间的管理由JVM来控制，对象创建由Java应用程序控制，但是对象所占的空间释放由管理堆内存的垃圾收集器来完成。根据GC算法的不同， 内存回收的方式和时机也会不同。 2. 线程JVM运行实际程序的实体是线程，当然线程需要内存空间来存储一些必要的数据，每个线程创建时JVM都会为它创建一个堆栈，堆栈的大小根据不同的JVM实现而不同， 通常在256KB~756KB之间。 线程所占用空间相对堆空间来说比较下。但是如果线程过多，线程堆栈的总内存使用量可能也非常大。当前有很多应用程序根据CPU的核书来分配创建的线程数， 如果运行的应用程序的线程数量比可用于处理它们的处理器数量多，效率通常很低。 3. 类和类加载器在Java中的类和加载类的类加载器本身同样需要存储空间，在Sun JDK它们也被存储在Java堆中，这个区域叫做永久代（PermGen区）。 JVM是按需来加载类的，曾经有个疑问：JVM如果要加载一个jar包是否要把这个jar包中的所有类都加载到内存中？显然不是的。 JVM只会加载那些在你的应用程序中明确使用的类到内存中。要查看JVM到底加载了哪些类，可以在启动参数上加上-verbose:class。 博主在idea的vm options加上这个之后，运行一个Demo，发现加载了很多很多rt.jar的类，日志输出很多。 理论上使用的Java类越多，需要占用的内存也会越多，还有一种情况是可能重复加载同一个类。通常情况下JVM只会加载一个类到内存一次， 但是如果是自己实现的类加载器会出现重复加载的情况，如果PermGen区不能对已经失效的类做卸载，可能会导致PermGen区内存泄漏。所以徐需要注意 PermGen区的内存回收问题。通常一个类能够被卸载，有如下条件需要满足： 该类所有的实例都已经被GC。 加载该类的ClassLoader实例已经被GC。 该类的java.lang.Class对象没有在任何地方被引用。 需要注意的是，JVM所创建的3个默认类加载器都不可能满足这些条件，因此，任何系统类（如java.lang.String）或者通过应用程序类加载器加载的任何应用 程序类都不能在运行时释放。 4. NIO基于通道和缓冲区来执行I/O的新方式。使用java.nio.ByteBuffer.allocateDirect()分配内存，这个方法分配的内存是本机内存而不是Java堆上的内存， 这也进一步说明每次分配内存时会调用操作系统的os::malloc()函数。另一方面直接ByteBuffe产生的数据如果和网络或者磁盘交互都在操作系统的内核 空间发生，不需要将数据复制到Java内存中，很显然这种I/O操作要比一般的从操作系统的内和空间到Java堆上的切换操作快得多，如果你的IO频繁发送 很小的数据，这种系统调用的开销可能会抵消数据在内核空间和用户空间复制带来的好处（即，如果频繁IO小数据，就不用NIO了）。 直接ByteBuffer对象会自动清理本机缓冲区，但这个过程只能作为Java堆GC的一部分来执行，因此它们不会自动响应施加在本机堆上的压力。 GC仅在Java堆被填满，以致于无法为堆分配请求提供服务时发生，或者在Java应用程序中显示请求时发生。当前在很多NIO框架中都在代码中显式调用System.gc() 来释放NIO持有的内存。但是这种方式会影响应用程序的性能，因为会增加GC的次数，一般通过设置-XX:+dISABLEeXPLICITgc来控制System.gc()的影响，但是 又会导致NIO direct memory内存泄漏问题。 5. JNIJNI技术使得本机代码（如C）可以调用Java方法，也就是通常所说的native memory。实际上Java运行时本身也依赖于JNI代码来实现类库功能，如 文件操作、网络IO操作或者其他系统调用。所以JNI也会增加Java运行时的本机内存占用。 4. JVM内存结构JVM是如何使用内存的？JVM按照运行时数据的存储结构来划分内存结构的，JVM在运行Java程序时，将它们划分成几种不同格式的数据，分别存储在不同的区域，这些数据统一称为 运行时数据（Runtime Data）。运行数据包括Java程序本身的数据信息和JVM运行Java程序需要的额外数据信息，如要记录当前程序指令执行的指针。 PC寄存器数据 Java栈 堆 方法区 本地方法区 运行时常量池 1. PC寄存器PC寄存器严格来说是一个数据结构，它用于保存当前正在执行的程序的内存地址。同时Java陈旭是多线程执行的，所以不可能一直都按照线性执行下去，当 有多个线程交叉执行时，被中断线程的程序当前执行到哪条的内存地址必然要保存下来，以便于它被恢复执行时再按照被中断时的指令地址继续执行下去。 但是JVM规范只定义了Java方法需要记录指针信息，而对于Native方法，并没有要求记录执行的指针地址。 2. Java栈Java栈总是和线程关联在一起，每当创建一个线程时，JVM就会为这个线程创建一个对应的Java栈，在这个Java栈中又会含有多个栈帧，这些栈帧是与每个方法 关联起来的，每运行一个方法就创建一个栈帧，每个栈帧会含有一些内部变量（局部变量）、操作栈和方法返回值等信息。 每当一个方法执行完成时，这个战争就会弹出栈帧的元素作为这个方法的返回值，并清除这个栈帧，Java栈的栈顶的栈帧就是当前正在执行的活动栈，也就是 当前正在执行的方法，PC寄存器也会指向这个地址。只有这个活动的栈帧本地变量可以被操作栈使用，当在这个栈帧中调用另外一个方法时， 与之对应的一个新的栈帧又被创建，这个新创建的栈帧又被放大Java栈的顶部，变为当前的活动栈帧。同样现在只有这个栈帧的本地变量才能被使用，当 在这个栈帧中所有指令执行完成时这个栈帧移出Java栈，刚才的那个栈帧又变成活动栈帧，前面的栈帧的返回值又变为这个栈帧的操作数。如果前面的栈帧 没有返回值，那么当前的栈帧的操作栈的操作数没有变化。 由于Java栈是与Java线程对应起来的，这个数据不是线程共享的，所以不用关心数据一致性以及同步锁的问题。 3. 堆堆是存储Java对象的地方，它是JVM管理Java对象的核心存储区域，堆是Java程序员最应该关心的，因为它是我们的应用程序与内存关系最密切的存储区域。每一个存储在堆中的Java对象都会是这个对象的类的一个副本，它会复制包括继承自它父类的所有非静态属性。堆是被所有Java线程所共享的，所以对它的访问需要注意同步问题，方法和对应的属性都需要保证一致性。 4. 方法区JVM方法区是用于存储类结构信息的地方，如果在第7章介绍的将一个class文件解析成JVM能识别的几个部分，这些不同的部分在这个class被加载到JVM时， 会被存储在不同的数据结构中，其中的常量池、域、方法数据、方法体、构造函数、包括类中的专用方法、实例初始化、接口初始化都存储在这个区域。 方法区这个存储区域也属于后面介绍的Java堆中的一部分，也就是我们通常所说的Java堆的永久区。这个区域可以被所有的线程共享，并且它的大小可以通过参数来设置。这个方法区存储区域的大小一般的程序启动后的一段时间内就是固定的了，JVM运行一段时间后，需要加载的类通常都已经加载到JVM中了，但是有一种情况是需要注意的， 那就是项目中如果存在对类的动态编译，而且是同样一个类的多次编译，那么需要观察方法区的大小是否能满足类存储。 方法区这个区域有点特殊，由于它不像其他Java堆一样会频繁的被GC回收，它存储的信息相对比较稳定，但是它仍然占用了Java堆的空间，所以仍然会被JVM的GC 回收器管理。在一些特殊的场合下，有时通常需要缓存一块内容，这个内容也很少变动，但是如果把它置于Java堆中它会不停的被GC扫描，知道经过很长的 时间后会进入Old区。在这种情况下，通常是能够控制这个缓存区域中数据的生命周期的，我们不希望它被JVM内存管理，但是又希望它在内存中。面对这种情况， 淘宝正在开发一种技术用于在JVM中分配另外一个内存存储区域，它不需要GC回收器来回收，但是可以和其他内存中对象一样来使用。 5. 运行时常量池在JVM规范中是这样定义运行时常量池这个数据结构的：Runtime Constant Pool代表运行时每个class文件中的常量表。它包括几种常量：编译器的数字常量、 方法或者域的引用（在运行时解析）。Runtime Constant Pool的功能类似于传统编程语言的符号表，尽管它包含的数据比典型额符号表要丰富得多。 每个Runtime Constant Pool都是JVM的Method area中分配的，每个Class或者Interface的Constant Pool都是在JVM创建class或接口时创建的。 这个常量池和前面方法区的常量池是否是一回事？答案是肯定的。它是方法区额一部分，所以它的存储也受方法区的规范约束，如果常量池无法分配， 同样会抛出OutOfMemoryError。 6. 本地方法栈本地方法栈是为JVM运行Native方法准备的空间，和前面介绍的Java栈的作用是类似的，由于很多Native方法都是用C语言实现的，所以它通常又叫C栈， 还有JVM利用JIT技术时会将一些Java方法重新编译为Native Code代码，这些编译后的本地代码通常也是利用这个栈来跟踪方法的执行状态的。 在JVM规范中没有对这个区域的严格限制，它可以由不同的JVM实现者自由实现，但是它和其他存储区一样会抛出OutOfMemoryError和StackOverflowError。 7. 总结此图镇楼： 5. JVM内存分配策略1. 通常的内存分配策略操作系统的三种内存分配策略： 静态内存分配 栈内存分配 堆内存分配 静态内存分配是指在程序编译时就能确定每个数据在运行时的粗出空间需求，因此在编译时就可以给它们分配固定的内存空间。这种分配策略不允许在程序 代码中有可变数据结构（如可变数组）的存在，也不允许有嵌套或者递归的结构出现，因为它们都会导致编译程序无法计算准确的存储空间需求。 栈式内存分配也可称为动态存储分配，是由一个类似于堆栈的运行栈来实现的。和静态内存分配相反，在栈式内存方案中，程序对数据区的需求在编译时是完全未知的， 只有到运行时才能知道，但是规定在运行中进入一个程序模块时，必须知道该程序模块所需的数据区大小才能够为其分配内存。和我们所熟知的数据结构中的栈一样， 栈式内存分配按照先进后出的原则进行分配。 堆内存分配，当程序真正运行到相应代码时才会知道空间大小。 2. Java中的内存分配详解Java内存分配主要基于堆和栈。 Java栈的分配是和线程绑定在一起的，当我们创建一个线程时，很显然，JVM就会为这个线程创建一个新的Java栈，一个线程的方法的调用和返回对应于这个 Java栈的压栈和出栈。当线程激活一个Java方法时，JVM就会在线程的Java堆栈里新压入一个栈帧，这个帧自然成了当前帧。在此方法执行期间， 这个帧将用来保存参数、局部变量、中间计算过程和其它数据。 栈中主要存放了一些基本类型的变量数据（int、short、long、byte、float、double、boolean、char）和引用。存取速度比堆要快、仅次于寄存器， 栈数据可以共享。缺点是，存在栈中的数据大小与生存期必须是确定的，这也导致缺乏了其灵活性。 每个Java应用都唯一对应一个JVM实例，每个实例唯一对应一个堆。应用程序在运行中所创建的所有类实例或数组都放在这个堆中，并由应用程序所有的线程共享。 在Java中分配堆内存是自动初始化，所有对象的存储空间都是在堆中分配的，但是这个对象的引用却是在堆栈中分配的。也就是说在建立一个对象时两个地方都 分配内存，在堆中分配的内存实际建立这个对象，而在堆栈中分配的内存只是一个指向这个堆对象的引用而已。 Java的堆是一个运行时数据区，它们不需要程序代码来显式地释放。堆是由垃圾回收来负责的，堆的优势是可以动态地分配内存大小，生存期也不必事先告诉编译器， 因为它是在运行时动态分配内存的。但缺点是，由于要在运行时动态分配内存，存取速度较慢。 从堆和栈的功能和作用来通俗地比较，堆主要用来存放对象，栈主要用来执行程序，这种不同主要是由堆和栈的特点决定的。 在编程中，如C/C++中，所有的方法调用都是通过栈拉进行的，所有的局部变量】形参都是从栈中分配内存空间的。实际上也不是什么分配，只是从栈顶向上用就行， 就好像工厂中的传送带一样，栈指针会自动指引你到放东西的位置，你所要做的只是把东西放下来就行。在退出函数时，修改栈指针就可以把栈中的内容销毁。 这样的模式速度最快，当然要用来运行程序了。注意：在分配时，如为一个即将要调用的程序模块分配数据区时，应事先知道这个数据区的大小，也就是说虽然分配 是在程序运行时进行的，但是分配的大小是确定的、不变的，而这个“大小多少”是在编译时确定的，而不是在运行时。 堆在应用程序运行时请求操作系统给自己分配内存，由于操作系统管理内存分配，所以在分配和销毁都要占用时间，因此用堆的效率非常低。但是堆的优先在于编译器 不必知道要从堆里分配多少存储空间，也不必知道存储的数据要在堆里停留多长时间，因此，用堆保存数据时会得到更大的灵活性。事实上，由于面向对象的多态性， 堆内存分配是必不可少的，因为多态变量所需的存储空间只有在运行时创建对象之后才能确定。在C++中，要求创建一个对象时，只需要new命令编制相关的代码即可。 执行这些代码时，会在堆里自动进行数据的保存。当然，为达到这种灵活性，必然会付出一定的代价–在堆里分配存储空间会花掉更长的时间 6. JVM内存回收策略1. 静态内存分配和回收在编译时就能够确定需要的内存空间，当程序被加载时系统把内存一次性分配给它。 1234567public void staticData(int arg_) &#123; String s = "String"; long l_ = 1; Long lg = 1L; Object o = new Object(); Integer i = 0;&#125; 其中参数arg、l是原生的数据类型，s、lg、o、i是指向对象的引用。其中int分配4个字节，long分配8个字节，对象的引用占用4个字节，所以这个方法 占用的静态内存空间是：4+4+8+4+4+4=28个字节。 静态内存空间当这段代码运行结束时回收，根据第七章的介绍，我们知道这些静态内存空间是在Java栈上分配的，当这个方法运行结束时，对应的栈帧也就撤销， 所以分配的静态内存空间也就回收了。 2. 动态内存分配和回收在前面的例子中变量lg和i存储与值虽然与l和arg变量一样，但是它们存储的位置是不一样的，后者是原生数据类型，它们存储在Java栈中，方法执行结束 就会消失，而前者是对象类型，它们存储在Java堆中，它们是可以被共享的。变量l和lg的内存空间大小也不一样，l在Java栈中被分配8个字节，而lg 被分配4个字节的地址指针空间，这个地址指针指向这个对象在堆中的地址。很显然在堆中Long类型数字1肯定不止8个字节，所以Long代表的数字肯定比 long类型占用的空间要大很多。 在Java中对象的内存空间是动态分配的，所谓的动态分配就是在程序执行时才知道要分配的存储空间大小，而不是在编译时就能够确定的。lg代表的Long对象， 只有JVM在解析Long类时才知道在这个类中有哪些信息，这些信息都是哪些类型，然后再为这些信息分配相应的存储空间存储相应的值。而这个对象什么时候 被回收也是不确定的，只有等到这个对象不再使用时才会被回收。 内存的分配是在对象创建时发生的，而内存的回收是以对象不再引用为前提的。 3. 如何检测垃圾垃圾收集器必须能够完成两件事： 正确地检测出垃圾对象。 能够释放垃圾对象占用 的内存空间。 除了f和h对象之外，其它都可以称为活动对象，因为它们都可以被根对象集合达到。 那么这个根对象集合中又都是些什么呢？虽然根对象集合和JVM的具体实现也有关系，但是大都会包含如下一些元素： 在方法中局部变量区的对象的引用：如在前面的staticData方法中定义的lg和o等对象的引用就是根对象集合中的一个根对象，这些根对象直接存储在栈帧的局部变量区中。 在Java操作栈中的对象引用：有些对象是直接在操作栈中持有的，所以操作栈肯定也包含根对象集合。（博主：即Java栈中除了native栈） 在常量池中的对象引用：每个类都会包含一个常量池，这些常量池也会包含很多对象引用，如表示类名的字符串就保存在堆中，那么常量池中只会持有这个 字符串对象引用。 在本地方法中持有的对象引用：有些对象被传入本地方法中，这些对象是不会被释放。 类的Class对象：当每个类被JVM加载时都会创建一个代表这个类的唯一数据类型的Class对象，而这个Class对象也同样存放在堆中，当这个类不再被 使用时，在方法区中类数据和这个Class对象同样需要被回收。 4. 基于分代的垃圾收集算法将对象按照寿命长短来分组，分为年轻代和年老代，新创建的对象被分在年轻代，如果对象经过几次回收后仍然存活，那么再把这个对象划分到年老代。 年老代的手机频度不像年轻代那么频繁。这样就减少了每次垃圾收集时所要扫描的对象的数量，从而提高了垃圾回收效率。 Young区又分为Eden区和两个Survivor，其中所有新创建的对象都在Eden区，当Eden区满后会触发minor GC将Eden区仍然存活的对象复制到其中一个 Survivor区，另外一个Survivor区中的存活对象也复制到这个Survivor中，以保证始终有一个Survivor区是空的。 Old区存储的是Young区的Survivor满后触发minor GC后仍然存活的对象，当Eden区满后将对象放到Survivor区中，如果Survivor区仍然存不下这些 对象，GC收集器会将这些对象直接存放到Old区。如果在Survivor区中的对象足够老，也直接存放到Old区。如果Old区也满了，将会触发Full GC，回收整个 堆内存。 Perm区存放的主要是类的Class对象，如果一个类被频繁地加载，也可能会导致Perm区满，Perm区的垃圾回收也是由Full GC触发的。 Sun建议堆中Young区的大小为整个堆的1/4，而Young区中Survivor区一般设置为整个Young区的1/8。 GC收集器对这些区采用的垃圾收集器算法也不一样，Hotspot提供了三类垃圾收集算法： Serial Collector Parallel Collector CMS Collector 1. Serial Collector串行收集器是JVM在client模式下默认的GC方式。可以通过JVM配置参数-XX:+UseSerialGC来指定GC使用该收集算法。我们指定所有的对象都在Young区 的Eden中创建，但是如果创建的对象超过Eden区的总大小，或者超过了PretenureSizeThreshold配置参数配置的大小，就只能在Old区分配了。 当Eden空间不足时就触发了Minor GC，触发Minor GC时首先会检查之前每次Minor GC时晋升到Old区的平均对象大小是否大小Old区的剩余空间，如果大于， 则将直接触发Full GC，如果小于，则要看-XX:-HandlePromotionFailure参数的值。如果为true，仅触发Minor GC，否则再触发一次Full GC。 JVM在做GC时由于是船形的，所以这些动作都是单线程完成的，在JVM中的其他应用程序全部停止。 2. Parallel Collector根据Minor GC和Full GC的不同分为三种，分别是ParNewGC、ParallelGC、ParallelOldGC。 1. ParNewGC通过-XX:+UseParNewGC参数来指定，它的对象分配和回收策略与Serial Collector类似，只是回收的线程不是单线程的，而是多线程并行回收。在 Parallel Collector中还有一个UseAdaptiveSizePolicy配置参数，这个参数是用来动态控制Eden、From Space和To Space的TenuringThreshold 大小的，即控制哪些对象经过多少次回收后可以直接放入Old区。 2. ParallelGC在Server下默认的GC方式，可以通过-XX:+UseParallelGC参数来强制指定，并行回收的线程数可以通过-XX:ParallelGCThreads来指定， 这个值有个计算公式，如果CPU核书小于8，线程数可以和核书一样，如果大于8，值为3+(core*5)/8。 当在Eden区中申请内存空间时，如果Eden区不够，那么看当前申请的空间是否大于等于Eden的一半，如果大于则这次申请直接在Old中分配，如果小于则触发 Minor GC。在触发GC之前首先会检查每次晋升到Old区的平均大小是否大于Old区的剩余空间，如大于则再触发Full GC。在这次触发GC后仍然会按照这个规则重新检查一次。 也就是如果满足上面这个规则，Full GC会执行两次。 3. ParallelOldGC可以通过-XX:UseParallelOldGC参数来强制指定。它和ParallelGC有何不同呢？其实不同之处在Full GC上，前者Full GC进行的动作为清空整个Heap 堆中的垃圾对象，清楚Perm区中已经被卸载的类信息，并进行压缩。而后者是清楚Heap堆中的部分垃圾对象，并进行部分的空间压缩。 GC垃圾回收都是以多线程方式进行的，同样也将暂停所有的应用程序。 3. CMS Collector它既不是上面所说的Minor GC，也不是Full GC，它是基于这两种GC之间的一种GC。它的触发规则是检查Old区或者Perm区的使用率，当达到一定比例就会 触发CMS GC，触发时会收回Old区中的内存空间。 触发CMS GC时回收的只是Old区或者Perm区的垃圾对象，在回收时和前面所说的Minor GC和Full GC基本没有关系。 7. 总结中间有很多原作者用于分析真实场景JVM异常的实例，但是由于博主并没有达到那个高度，就并没有列出来。 JVM的内存：PC寄存器、Java栈、堆、方法区、运行时常量池、本地方法栈，以及栈是线程安全的。 堆的划分用于GC效率：Young（Eden，Survivor（From、To））、Old、Perm。 垃圾回收算法：Serial Collector、ParallelC Collector、CMS Collector（Old、Perm）。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[虚拟机初始化部署]]></title>
    <url>%2F2017%2F08%2F14%2Fhadoop%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[1. 虚拟机设置静态IP使用VMware12安装CentOS 64位，安装一台之后，并进行设置好静态IP。详细地址：http://blog.csdn.net/readiay/article/details/50866709主要通过查看VMware12的网关、网段，并且设置虚拟机的IP、网关、子网掩码。 设置网卡：/etc/sysconfig/network-scripts/ifcfg-xxx,xxx可能不同。设置主机名：/etc/sysconfig/network。设置DNS：/etc/resolv.conf。这步完成，虚拟机可以上网，使用SecureCRT主机可以登录虚拟机。 2. 虚拟机进行拷贝增加用户hadoop之后。进行拷贝，拷贝出两个虚拟机用作从机，并重新设置网卡以及主机名。并使用ssh localhost命令在虚拟机互相登录。 3. 使用公钥登录使用root账号，在第一个机器输入ssh-keygen，生成ssh公钥私钥，然后使用ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.xxx.x 发送到指定的某个机器，就可以直接使用ssh登录而不用输入密码了，因为有三台，ssh-keygen需要每台输入，而后面的命令需要每台输入两次，用于 连接两台电脑。详细地址：http://blog.topspeedsnail.com/archives/6985 4. 配置hosts文件在第一步设置了主机名之后，接着在每台虚拟机中，设置hosts文件，以后ssh连接直接输入别名，不用输入IP。 5. 配置Java到环境变量http://www.jianshu.com/p/cde3083fc42d 6. 设置请求转发我们需要主机去访问虚拟机的服务，详情设置：http://graybull.is-programmer.com/posts/36941.html]]></content>
      <categories>
        <category>linux</category>
        <category>hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[七、JVM体系结构与工作方式]]></title>
    <url>%2F2017%2F08%2F12%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9AJVM%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1. JVM体系结构前言：JVM能够跨计算机体系结构来执行Java字节码，主要是由于JVM屏蔽了与各个计算机平台相关的软件或者硬件之间的差异， 使得与平台相关的耦合统一由JVM提供者来实现。 1. 何谓JVMJVM的全称是Java Virtual Machine(Java虚拟机)，它通过模拟一个计算机来达到一个计算机所具体的计算功能。 我们先来看看一个真实的计算机如何才能具备计算的功能。 指令集，这个计算机能够识别的计算语言的命令集合. 计算单位，即能够识别并且控制指令执行的功能模块。 寻址方式，地址的位数、最小地址和最大地址范围，以及地址的运行规则。 寄存器定义，包括操作数寄存器、变址寄存器、控制寄存器等的定义、数量和使用方式。 存储单元，能够存储操作数和保存操作结构的单元，如内核级缓存、内存和磁盘等。 在上面的几个部分中，与代码执行最密切的还是指令集部分。什么是指令集？有何作用？所谓指令集就是在CPU中用来计算和控制计算机系统的一套指令的集合，每一种新型的CPU在设计时都规定了 一系列与其他硬件电路相配合的指令系统。而指令集的先进与否也关系到CPU的性能发挥，它是体现CPU性能的一个重要标志。在当前计算机中有哪些指令集？从主流的体系结构上分为精简指令集(Reduced Instruction Set Computing, RISC)和复杂指令集 (Complex Instrction Set Computing, CISC)。当前使用的桌面操作系统中基本上使用的都是CISC，如x86架构的的CPU都使用CISC。除了这两种指令集之外Intel和AMD公司还在它们 的基础上开发出了很多扩展指令集，包括多媒体扩展指令，以及3D处理性能开发的指令集等。指令集与汇编语言有什么关系？指令集是可以直接被机器识别的机器码，也就是它必须以二进制格式存在于计算机中。而汇编语言是能够 被人识别的指令，汇编语言在顺序和逻辑上是与机器指令一一对应的。换句话说，汇编语言是为了让人能够更容易地记住机器指令而使用 的助记符。每一条汇编指令都可以直接翻译成一个机器指令，如MOVAX,1234H这条汇编语言对应的机器指令码为B83412。当然也不是所有 的汇编语言都有对应的机器指令，如nop指令。指令集与CPU架构有何联系？如Intel与AMD的CPU的指令集是否兼容？也就是CPU的结构是否会影响指令集？答案都是肯定的。学过汇编语言 的人都知道在汇编语言中都是对寄存器和段的直接操作的命令，这些寄存器和段等芯片都是架构的一部分，所以不同的芯片架构设计一定会 对应到不同的机器指令集合。但是现在不同的芯片厂商往往都会采用兼容的方式来兼容其它不同架构的指令集。如AMD会兼容32为Intel的 x86系统架构的CPU，而当AMD开发出了支持64位指令的x86-64架构时，Intel又迫于压力不得不兼容这种架构而起了另外一个名字EM64T。这种压力来自什么地方？当然是垄断了操作系统的微软，由于现在操作系统是管理计算机的真正入口，几乎所有的程序都要通过操作系统来调用， 所以如果操作系统不支持某种芯片的指令集，用户的程序是不可能执行的。这种情况也存在于我们国家自己设计的龙芯CPU，龙芯CPU不得不使用基于 MIPS架构的指令集(RISC)，因为目前有直接支持MIPS架构的操作系统(Linux)。如果没有操作系统和应用软件，再好的CPU也没有使用价值。 当然在一些很少用到的大型机方面不存在这个问题。回到JVM的主题中来，JVM和实体机到底有何不同呢？大体有如下几点。 一个抽象规范，这个规范就约束了JVM到底是什么，它有那些组成部分。 一个具体的实现，所谓具体的实现就是不同的厂商按照这个抽象的规范，用软件或者软件和硬件结合的方式在相同或者不同的平台上的具体实现。 一个运行中的实例，当用其运行一个Java程序时，它就是一个运行中的实例，每个运行中Java程序都是一个JVM实例。 JVM和实体机一样也必须有一套合适的指令集，这个指令集能够被JVM解析执行。这个指令集我们称为JVM字节码指令集， 符合class文件规范的字节码都可以被JVM执行。 2. JVM体系结构详解除了指令集，JVM还需要哪些组成部分： 类加载器，在JVM启动时或者在类运行时将需要的class加载到JVM中。 执行引擎，执行引擎的任务是负责执行class文件中包含的字节码指令，相当于实际机器上的CPU。 内存区，将内存划分成若干个区以模拟实际机器上的存储、记录和调度功能模块，如实际机器上的各种功能的寄存器或者PC指针的记录器等。 本地方法调用，调用C或C++实现的本地方法的代码返回结果。 1. 类加载器在深入分析ClassLoader时我们详细分析了ClassLoader的工作机制，这里需要说明的是，每个被JVM装载的类型都有一个对应的java.lang.Class类的实例 来表示该类型，该实例可以唯一标识被JVM装载的class类，要求这个实例和其他类的实例一样都存放在Java的堆中。 2. 执行引擎执行引擎是JVM的核心部分，执行引擎的作用就是解析JVM字节码指令，得到执行结果。在《Java虚拟机规范》中详细地定义了执行引擎遇到每条 字节码指令时应该处理什么，并且应该得到什么结果。但是并没有规定执行引擎应该如何或取什么方式处理而得到这个结果。 因为执行引擎具体采取什么方式由JVM的实现厂家自己去实现，是直接解释执行还是采用JIT技术或转成本地代码去执行，还是采用寄存器这个芯片 模式去执行都可以。所以执行引擎的具体实现有很大的发挥空间，如SUN的hotspt是基于栈的执行引擎，而Google的Dalvik是基于寄存器的执行引擎。执行引擎也就是执行一条条代码的一个流程，而代码都是包含在方法体内的，所以执行引擎本质上就是执行一个个方法所串起来的流程， 对应到操作系统中一个执行流程是一个Java进程还是一个Java线程呢？很显然是后者，因为一个Java进程可以有多个同时执行的执行流程。 这样说来每个Java县城就是一个执行引擎的实例，那么在一个JVM实例中就会同时有多个执行引擎在工作，这些执行引擎有的在执行用户的程序， 有的在执行JVM内存的程序（如Java垃圾收集器）。 3. Java内存管理执行引擎在执行一段程序时需要存储一些东西，如操作码需要的操作数，操作码的执行结果需要保存。class类的字节码还有类的对象等信息都需要在执行 引擎执行之前就准备好。一个JVM实例会有一个方法区、Java堆、Java栈、PC寄存器和本地方法区。其中方法区和Java堆时所有线程共享的， 也就是可以被所有的执行引擎实例访问。每个新的执行引擎实例被创建时会为这个执行引擎创建一个Java栈和一个PC寄存器， 如果当前正在执行一个Java方法，那么在当前的这个Java栈中保存的是该线程中方法调用的状态，包括方法的参数、方法的局部变量、方法的返回值 以及运算的中间结果等。而PC寄存器会指向即将执行的下一条指令。如果是本地方法调用，则存储在本地方法调用栈中或者特定实现中的某个内存区域中。 2. JVM工作机制1. 机器如何执行代码在分析JVM的执行引擎如何工作之前，我们不妨先看看在普通的实体机上程序是如何执行的。前面已经分析了计算机只接受机器执行，其他高级语言首先必须 经过编译器编译成机器指令才能被计算机正确执行，所以从高级语言到机器语言之间必须要有个翻译的过程，我们知道机器语言一般都是和硬件平台密切相关 的，而高级语言一般都是屏蔽所有底层的硬件平台甚至包括软件平台（如操作系统）的。高级语言之所以能屏蔽这些底层硬件架构的差异就是因为有中间的 一个转换环节，这个转换环节就是便宜，与硬件耦合的麻烦就交给了编译器，所以不同的硬件平台通常需要的编译器也是不同的。在当前这种环境下我们所 说的不同的硬件平台已经被更上一层的软件平台所代替了，这个软件平台就是操作系统，与其说不同的硬件平台的差异还不如说操作系统之间的差异，因为 现在的操作系统几乎完全向用户屏蔽了硬件，所以我们说编译器和操作系统的关系非常密切会更加容易让人理解。如C语言在Windows下的编译器为Microsoft C, 而在linux下通常是gcc，当然还有很多不同厂家的编译器，这些编译器都和操作系统关系不大，只是在实现上有些差异。通常一个程序从编写到执行会经历以下一些阶段： 源代码(source code) -&gt; 预处理器(preprocessor) -&gt; 编译器(compiler) -&gt; 汇编程序(assembler) -&gt; 目标代码(object code) -&gt; 链接器 (Linker) -&gt; 可执行程序(executables) 除了源代码和最后的可执行程序，中间的所有环节都是由现代意义上的编译器统一完成的，如在Linux平台下我们通常安装一个软件需要经过 configure、make、make install、make clean这4个步骤来完成。 configure：为这个程序在当前的操作系统环境下选择合适的编译器来编译这个程序代码，也就是为这个程序代码选择合适的编译器和一些环境参数。 make：自然就是对程序代码进行编译操作了，它会将源码编译成可执行的目标文件。 make install：将已经编译好的可执行文件安装到操作系统指定或者默认的安装目录下。 make clean：用于删除编译时临时产生的目录或文件。 值得注意的是，我们通常所说的编译器都是将某种高级语言直接编译成可执行的目标机器语言（实际上在某种操作系统中是需要动态链接的目标二进制文件： 在Windows下是dynamic link library，DDL；在Linux下是Shared Library，SO库）。但是实际上还有一些编译器是将一种高级语言编译成 另一种高级语言，或者将低级语言编译成高级语言（反编译），或者将高级语言编译成虚拟机目标语言，如Java编译器等。再回到如何让机器（不管是实体机还是虚拟机）执行代码的主题，不管是何种指令集都只有集中最基本的元素：加、减、乘、求余、求模等。 这些运算又可以进一步分解成二进制位运算：与、或、异或等。这些运算又通过指令来完成，而指令的核心目标就是确定需要运算的种类（操作码） 和运算需要的数据（操作数），以及从哪里（寄存器或栈）获取操作数、将运算结果存放到什么地方（寄存器或是栈）等。这种不同的操作 方式又将指令划分为：一地址指令、二地址指令、三地址指令和零地址指令等n地址指令。相应的指令集会有对应的架构实现，如基于寄存器 的架构实现或基于栈的架构实现，这里的基于寄存器或者栈都是指在一个指令中的操作数是如何存取的。 2. JVM为何选择基于栈的架构JVM执行字节码指令是基于栈的架构，也就是所有的操作数必须先入栈，然后根据指令中的操作码选择从栈顶弹出若干个元素进行计算后再将结果压入栈中。 在JVM中操作数可以存放在每一个栈帧中国的一个本地变量集中，即在每个方法调用时就会给这个方法分配一个本地变量集，这个本地变量集在编译时就已经 确定，所以操作数入栈可以直接是常量入栈或者从本地变量集中取一个变量压入栈中。这和一般的基于寄存器的操作有所不同，一个操作需要频繁的入栈和出栈， 如进行一个加法运算，如果啷个操作数都在本地变量中，那么一个加法操作就要有5次栈操作，分别是将两个操作数从本地变量入栈（2次入栈操作），再将 两个操作数出栈用于加法运算（2次出栈），再将加法结果压入栈顶（1次入栈）。如果是基于寄存器的话，一般只需要将两个操作数存入寄存器进行加法运算后 再将结果存入其中一个寄存器即可，不需要这么多的数据移动的操作。那么为什么JVM还要基于栈来设计呢？JVM为何要基于栈来设计有几个理由。一个是JVM要设计成与平台无关的。而平台无关性就是要保证在没有或者有很少的寄存器的机器上也要同样能正确的执行 Java代码。例如，在80x86的机器上寄存器就是没有规律的，很难针对某一款机器设计通用的基于寄存器的指令，所以基于寄存器的架构很难做到通用。在 手机操作系统方面，Google的Android平台上的Dalvik VM就是基于特定芯片（ARM）设计的基于寄存器的架构，这样在特定芯片上实现基于寄存器的架构 可能更多考虑性能，但是也牺牲了跨平台的移植性，当然在当前的手机上这个需求还不是最迫切的。还有一个理由是为了指令的紧凑性，因为Java的字节码可能在网络上传输，所以class文件的大小也是设计JVM字节码指令的一个重要因素，如在class文件 中字节码除了处理两个表示跳转的指令外，其他都是字节对齐的，操作码可以只占一个字节大小，这都是为了尽量让编译后的class文件更加紧凑。为了提高 字节码在网络上的传输效率。Sun设计了一个Jar包的压缩工具Pack2000，它可以将多个class文件中的重复的常量池的信息进行合并，如一般在每个calss文件 中都含有“Ljava/lang/String;”，那么多个class文件中的常量就可以共用，从而起到减少数据量的作用。 3. 执行引擎的架构设计每当创建一个新的线程时，JVM会为这个线程创建一个Java栈，同时会为线程分配一个PC寄存器，并且这个PC寄存器会指向这个线程的第一行可执行代码。 每当调用一个新方法时会在这个栈上创建一个新的栈帧数据结构，这个栈帧会保留这个方法的一些元信息，如在这个方法中定义的局部变量、 一些用来支持常量池的解析、正常方法返回及异常处理机制等。JVM在调用某些指令时可能需要使用到常量池中的一些常量，或者是获取常量代表的数据或者这个数据指向的实例化对象，而这些信息都存储在所有线程共享 的方法区和Java堆中。 4. 执行引擎的执行过程1234567public class Math &#123; public static void main(String[] args) &#123; int a = 1; int b = 2; int c = (a+b) * 10; &#125;&#125; 其中main的字节码指令如下：对应到执行引擎的各执行部件如下所示：（注意：原书图的标记有问题，这里仍然使用错误的标记易于理解） 5. JVM方法调用栈JVM的方法调用分两种：一种是Java方法调用，另一种是本地方法调用。本地方法调用由于各个虚拟机的实现不太相同(因为跨平台)，所以这里主要介绍Java的方法调用情况。 12345678910public class Math &#123; public static void main(String[] args) &#123; int a = 1; int b = 2; int c = math(a, b) / 1; &#125; public static int math(int a, int b) &#123; return (a + b) * 10; &#125; &#125; 调用细节就不贴图了，记住一点，任何的数据都要入栈，进入存储到变量区时，都要出栈。PC寄存器存储的是下一条指令的指针。 3. 总结 计算机的体系结构：指令集（机器语言）、计算单元（控制指令）、寻址方式（地址的位数，寻址范围）、寄存器、存储单元（存储操作数和保存操作结构）。 class(通过ClassLoader类加载器后)-&gt;执行引擎(内存、方法区、堆、栈、PC寄存器)-&gt;调用本地方法接口(native) JVM和DVM（Dalvik）的核心区别在于，一个基于栈一个基于寄存器，为什么Sun和Google设计的不一样？后者相对来说，执行效率更高，但是前者真正实现 了跨平台，后者是每个APP都是一个VM，就相当于一个操作系统里面运行了多个DVM，而Sun是，一个操作系统运行一个JVM里面运行多个java程序。（相对 而言，Dalvik是可以预加载（Zygote）的，更叼一点，只不过Dalvik为了增加效率（毕竟运行在手机中），在运行时，不同应用是共享相同的类（打开QQ相机， 你再打开微信相机试试？），而JVM里面的程序，打包之后，运行之后，是真正的独立的程序，即便在包里使用了相同的类，运行都是独立加载的。 这里有更加详细的解答，博主也是抽出的简单精华。）]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[六、深入分析ClassLoader工作机制]]></title>
    <url>%2F2017%2F08%2F10%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90ClassLoader%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1. ClassLoader的等级加载机制 如何保证不同等级的会员通过不同的会员接待室进入会场？有可能有些会员并不能正确的找到接待自己的接待室，也有可能有些会员冒充更高级的会员身份混进去，所以必须要有机制能够保证所有会员都被正确的接待室接待进入会场，而且一个会员只能被一个接待室接待，不能出现被两个接待室 重复接待的情况。如何设计这个接待规则呢？ ClassLoader就设计了这样一种接待机制，即上级(双亲)委托接待机制。任何一个会员到达任何一个会员接待室时，这个接待室首先会检查这个会员P是否已经被自己A接待过，如果已经接待过，则拒绝本次接待，如果自己没有接待过，那么会向上B询问这个会员是否应该在 上一级的更高级别的接待室B接待，上级接待室B会根据它们的接待规则，检查这个会员是否被自己B接待过，如果接待过，将已经接待的结果反馈下一级A， 如果也没有接待过，则向上一级询问这个会员P是否应该在上一级的更高级别的接待室接待，一直这样接待，直到有一级接待室接待或者告诉它 下一级这个会员不是自己接待的结果； 如果这个会员来到的这个接待室A得到它上一级B的接待室反馈认为这个会员没有被接待，并且也不应该由它们BC接待，这个接待室A将会正式 接待这个会员，并发入会证明，这个会员就被定义为这个接待室等级的会员。 整个JVM平台提供三层ClassLoader，这三层ClassLoader可以分为两种类型，可以理解为：为接待室服务的接待室和为会员服务的接待室两种。 1. BootstrapClassLoader这个ClassLoader就是接待室服务自身的，它主要加载JVM自身工作需要的类，这个ClassLoader完全是由JVM自己控制的，需要加载哪个类、 怎么加载都由JVM自己控制，别人也访问不到这个类，所以这个ClassLoader是不遵守前面介绍的加载规则的，它仅仅是一个类的加载工具而已， 既没有更高一级的父加载器，也没有子加载器。 2. ExtClassLoader这个类加载器有点特殊，它是JVM自身的一部分，但是它的血统不是很纯正，它并不是JVM亲自实现的，我们可以理解为这个类加载器是那些与这个大会合作单位的员工会员， 这些会员既不是JVM内部的，也和普通的外部会员不同，所以就由这个类即在其来加载。它服务的特定目标在System.getProperty(&quot;java.ext.dirs&quot;)目录下。 3. AppClassLoader这个类加载器就是专门为接待会员服务的，它的父类是ExtClassLoader。它服务的目标是广大普通会员，所有在System.getProperty(&quot;java.class.path&quot;) 目录下的类都可以被这个类加载器加载，这个目录就是我们经常用到的classpath。 如果我们要实现自己的类加载器，不管你是直接实现抽象类ClassLoader，还是继承URLClassLoader类，或者其他子类，它的父加载器都是AppClassLoader， 因为不管调用哪个父类构造器，创建的对象都必须最终调用getSystemClassLoader()作为父加载器。而getSystemClassLoader()方法获取 到的正是AppClassLoader。很多文章在介绍ClassLoader的等级结构时把Bootstrap ClassLoader也列在ExtClassLoader的上一级中，其实BootstrapClassLoader并不属于JVM的类等级层次， 因为BootstrapClassLoader并没有遵守ClassLoader的加载规则。另外BootstrapClassLoader并没有子类。ExtClassLoader的父类也不是BootstrapClassLoader，ExtClassLoader并没有父类，我们在应用中能提取到的顶层父类是ExtClassLoader。ExtClassLoader和AppClassLoader都位于sun.misc.Launcher类中，它们是Launcher类的内部类。如果在Java应用中没有定义其他ClassLoader，那么除了System.getProperty(&quot;java.ext.dirs&quot;)目录下的类是由ExtClassLoader加载外， 其他类都由AppClassLoader加载。JVM加载class文件到内存由两种方式。 隐式加载：即不在代码里调用ClassLoader来加载所需要的类，而是通过JVM来自动加载所需要的类到内存的方式。例如，当我们在类中继承或者引用某个类时， JVM在解析当前这个类时发现引用的类不在内存中，那么就会自动将这么类加载到内存中。 显式加载：即调用this.getClass().getClassLoader().loadClass()或者Class.forName()，或者我们自己实现的ClassLoader的findClass()方法等。 ClassLoader().loadClass()底层是loadClass(name, false),即只加载不解析。而Class.forName()底层是forName0(className, true, ClassLoader.getClassLoader(caller), caller)， 即初始化。注意：在Java中，类装载分三步，对应三种状态，即：加载-&gt;链接(校验、准备、解析)-&gt;初始化。第一种对应的加载后，第二种对应的时链接后。例如：即要对驱动初始化才能使用就使用的后者加载Class.forName(“com.mysql.jdbc.Driver”)。 2. 如何加载class文件 找到.class文件，并把这个文件包含的字节码加载到内存中。 字节码验证、Class类数据结构分析、内存分配，符号表的链接。 [类中静态属性和初始化赋值][1]，以及静态块的执行等。 1. 加载字节码到内存抽象类ClassLoader中并没有定义如何去加载，让子类具体实现找到指定类并把它的字节码加载到内存需要的子类中， 例如：URLClassLoader如何实现的findClass()方法，这个类底层通过URLClassPath取得要加载的class文件字节流， 而这个URLClassPath定义了到哪里去找这个class文件，如果找到了这个class文件，再读取它的byte字节流，通过 调用defineClass()方法来创建类对象。URL数组是创建URLClassPath对象的必要条件。 2. 验证与解析 字节码验证：确保格式正确、行为正确。 类准备：准备类中定义的字段、方法和实现接口所必须的数据结构 解析：类装入器装入类所引用的其他所有累。如超类(父类)、接口、字段、方法签名、方法中使用的本地变量。 3. 初始化Class对象在类中包含的静态初始化器都被执行，在这一阶段末尾静态字段被初始化为默认值。 3. 常见加载类错误分析1. ClassNotFoundExceptionJVM要加载指定文件的字节码到内存时，并没有找到这个文件对应的字节码文件，即.class文件不存在。解决的办法就是检查 在当前的classpath目录下有没有指定的文件存在。可通过以下命令：this.getClass().getClassLoader().getResource(&quot;&quot;).toString()获取之后结果，让我大吃一惊，这不是我用idea设置的output文件夹么，原来idea设置的output文件夹有这个作用！ 2.NoClassDefFoundError确保每个类引用的类都在当前的classpath下面。 3. UnsatisfiedLinkError常见在JVM启动时，JVM中的某个lib删除了，可能会报这个错误（并这个lib中包含native标示的方法）。 4. ClassCastException 对于普通对象，对象必须是目标类的实例或目标类的子类的实例。如果目标类是接口，那么 会把它当作实现了该接口的一个子类。 对于数组类型，目标类型必须是数组类型或java.lang.Object、java.lang.Cloneable、java.io.Serializable。 123456Integer[] a = new Integer[]&#123;1&#125;;Object b = a;Cloneable c = a;Serializable d = a;System.out.println(b + "," + c + "," + d);//output:[Ljava.lang.Integer;@78e03bb5,[Ljava.lang.Integer;@78e03bb5,[Ljava.lang.Integer;@78e03bb5 建议先使用instanceof检查是不是目标类型，再进行强制类型转换。 5. ExceptionInInitializerError1234567891011public static Map m = new HashMap()&#123; &#123; m.put("a","2"); &#125; &#125;;@Testpublic void sss() &#123; Integer s = (Integer) m.get("a"); System.out.println(s);&#125; 初始化类的时候，给静态属性m赋值出现了异常导致抛出错误。 4. 常用ClassLoader分析基于对Tomcat的源码分析，对部署在Tomcat的Servlet的项目，执行 12345ClassLoader classLoader = this.getClass().getClassLoader();while (classLoader != null) &#123; System.out.println(classLoader.getClass().getCanonicalName()); classLoader = classLoader.getParent();&#125; Tomcat本身自己实现了WebappClassLoader，会优先检查WebappClassLoader加载到额缓存，而不是JVM的findLoaderClass缓存。并设置WebappClassLoadera的加载路径为WEB-INF/classes目录，查找文件的字节码，然后保存类的元信息，方便下次查找。 （前提是被查找的类再BootstrapClassLoader、ExtClassLoader、AppClassLoader等父加载器都反馈为不为他们加载）。 5. 如何实现自己的ClassLoaderClassLoader能够完成的事情： 在自定义路径下查找定义的class类文件，也许我们需要的class文件并不总在已经设置好的ClassPath下面，那么我们 必须想办法来找到这个类，这时，就需要自己实现一个ClassLoader。 对我们自己的要加载的类做特殊处理，如保证通过网络传输的类的安全性，可以将类经过加密后再传输，再加载到JVM 之前需对类的字节码再解码，这个过程就可以在自定义的ClassLoader中实现。 可以定义类的实现机制，我们可以检查已经加载的class文件是否被修改，如果修改了，可以重新加载这个类，从而实现 类的热部署。 1. 加载自定义路径下的class文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class PathClassLoader extends ClassLoader &#123; private String classPath; private String packageName = "com.lwg.classknow"; public PathClassLoader(String classPath) &#123; this.classPath = classPath; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; if (name.startsWith(packageName)) &#123; // 这里写从自己的缓冲中寻找，找到就直接返回。 byte[] classData = getData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; // 这里写放入自己的缓存中，或者注册到一个Bean管理器，统一管理等。 return defineClass(name, classData, 0, classData.length); &#125; &#125; else &#123; return super.loadClass(name); &#125; &#125; private byte[] getData(String className) &#123; String path = classPath + File.separator + className.replace('.', File.separatorChar) + ".class"; try&#123; // 如果是通过某种加密的文件，则这么可以进行特殊的解密 InputStream is = new FileInputStream(path); ByteArrayOutputStream stream = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int num = 0; while ((num = is.read(buffer)) != -1) &#123; stream.write(buffer, 0, num); &#125; return stream.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void main(String[] agrs) &#123; PathClassLoader loader = new PathClassLoader("C:\\lwg\\lwg\\out\\production\\lwg"); try &#123; Class cus = loader.findClass("com.lwg.classknow.classloader.ssss"); System.out.println(cus); //output:class com.lwg.classknow.classloader.ssss &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 还有直接继承URLClassLoader(下面代码没有经过验证): 1234567891011121314151617181920212223242526public class URLPathClassLoader extends URLClassLoader &#123; private String packageName = "com.lwg.classknow.classloader"; public URLPathClassLoader(URL[] urls, ClassLoader parent) &#123; super(urls, parent); &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; clz = findLoadedClass(name); if (clz != null) &#123; return clz; &#125; if (!packageName.startsWith(name)) &#123; return super.loadClass(name); &#125; else &#123; return findClass(name); &#125; &#125; public static void main(String[] args) throws ClassNotFoundException, MalformedURLException &#123; URLPathClassLoader loader = new URLPathClassLoader(new URL[]&#123;new URL("http://www.xxx.com")&#125;, null); loader.findClass("com.lwg.classknow.classloader.ssss"); &#125;&#125; 6. 实现类的热部署JVM在加载类之前会检查请求的类是否已经被加载起来，也就是要调用findLoaderClass()方法查看是否能偶返回类实例。如果类已经加载过来，再调用 loadClass()将会导致类冲突。但是JVM标示一个类是否是同一个类会有两个条件。 类的完整类名是否一样，这个类名包括类所在的包名。 加载这个类的ClassLoader是否是同一个实例。所以要实现类的热部署可以创建不同的ClassLoader的实例对象，然后通过对这个不同的实例对象来加载同名的类。 使用不同的ClassLoader实例加载同一个类，会不会导致JVM的PermGen区无限增大？答案是否定的，因为我们的ClassLoader对象也会和其他对象一样， 当没有对象再引用它以后，也会被JVM回收。但是需要注意的一点是，被这个ClassLoader加载的类的字节码会保存在JVM的PermGen区，这个数据一般 只是在执行Full GC时才会被回收的，所以如果在你的应用中都是大量的动态类加载，Full GC又不是太频繁，也要注意PermGen区的大小，防止内存溢出。 7. Java应不应该动态加载类我想大家都知道用Java有一个痛处，就是修改一个类，必须要重启一遍，很费时。于是就想能不能来个动态类的加载而不需要重启JVM，如果你了解JVM 的工作机制，就应该放弃这个念头。Java的优势正是基于共享对象的机制，达到信息的高度共享，也就是通过保存并持有对象的状态而省去类信息的重复创建和回收。我们知道对象一旦被创建， 这个对象就可以被人持有和引用。假如，我们能够动态加载一个对象进入JVM，但是如何做到JVM中对象的平滑过渡？几乎不可能！虽然在JVM中对象只有一份，在理论上可以直接诶替换这个 对象，然后更新Java栈中所有对原对象的引用关系。看起来好像对象可以被替换了，但是这仍然不可行，因为它违反了JVM的设计原则，对象的引用关系 只有对象的创建者持有和使用，JVM不可以干预对象的引用关系，因为JVM并不知道对象是怎么被使用的，这就涉及JVM并不知道对象的运行时类型 而只知道编译时类型。假如一个对象的属性结构被修改，但是在运行时其他对象可能仍然引用该属性。虽然完全的无障碍的替换时不现实的，但是如果你非要那么做，也还是可以。前面的分析造成不能动态提供类对象的关键是，对象的状态被保存了， 并且被其他对象引用了，一个简单的解决方法就是不保存对象的状态，对象被创建使用后被释放掉，下次修改后，对象也就是新的了。这就是JSP，动态的加载类，所有其他解释型语言都是如此。 8. 总结ClassLoader的基本工作机制，以及双亲委派机制的解释，自己创建ClassLoader以及热部署的原理。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[五、深入class文件结构]]></title>
    <url>%2F2017%2F08%2F10%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5class%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[1. JVM指令集简介前言：从底层讲解Java为什么是“一次编译导出运行”，以及一个class文件的内容。在分析class文件之前我们先学会使用Oolong汇编语言，它能将class文件的二进制表示的结构形式先转化成能够理解的汇编语言。下载Oolong.jar 包后将其放在jdk的lib目录下，然后增加一个CLASSPATH精准的指向该Oolong.jar目录。 1234567package com.lwg.classknow;public class Message &#123; public static void main(String[] args) &#123; System.out.printf("junshan say: Hello World"); &#125;&#125; 在当前class文件目录下，命令行输入:java COM.sootNsmoke.oolong.Gnoloo Message.class即可获得Message.j文件，如下： 12345678910111213141516171819202122232425262728293031.source Message.java.class public super com/lwg/classknow/Message.super java/lang/Object.method public &lt;init&gt; ()V.limit stack 1.limit locals 1.var 0 is this Lcom/lwg/classknow/Message; from l0 to l5.line 3l0: aload_0l1: invokespecial java/lang/Object/&lt;init&gt; ()Vl4: return.end method.method public static main ([Ljava/lang/String;)V.limit stack 3.limit locals 1.var 0 is args [Ljava/lang/String; from l0 to l14.line 5l0: getstatic java/lang/System/out Ljava/io/PrintStream;l3: ldc &quot;junshan say: Hello World&quot;l5: iconst_0l6: anewarray java/lang/Objectl9: invokevirtual java/io/PrintStream/printf (Ljava/lang/String;[Ljava/lang/Object;)Ljava/io/PrintStream;l12: pop.line 6l13: return.end method 汇编比较复杂，就不深究了，但是要知道，跨平台其实是JVM的跨平台，.java-&gt;.class-&gt;JVM(跨平台)-&gt;机器码(平台)。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[四、Javac编译原理]]></title>
    <url>%2F2017%2F08%2F08%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9AJavac%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1. Javac是什么前言：Java语言与Java语言规范，Java虚拟机有Java虚拟机规范，如何让Java的语法规则适应Java虚拟机的语法规范呢？它的任务就是 由Javac编译器完成的，将Java语言规范转化为Java虚拟机语言规范，完成“翻译”工作。 Javac是一种编译器，将一种语言规范转化成另外一种语言规范。虽然机器码执行非常高效，但是对人不友好，开发这个代码 的成本远远高于省下的机器的执行成本，所以才有了编译器的出现，有了编译器才有可能出现这么多的高级编程语言。关于具体的机器，平台，Javac是不管的，这是JVM的事情，Javac的任务就是将Java源代码语言先转化成JVM能够识别的 一种语言，然后由JVM将JVM语言再转化为当前这个机器能够识别的机器语言。表面上Javac的任务就是将Java源码编译成Java字节码，也就是JVM能够识别的二进制码，即.java-&gt;.class的转化 而实际上Java的源码转为一连串二进制数字，这些二进制数字是有格式的，只有JVM能够正确识别它们表达的意思。 2. Javac编译器的基本结构必须要先知道一个编译器完成一个语言规范到另一种语言规范的转化需要哪些步骤，如何完成这些步骤，也就是这个编译器 的基本结构是什么。 词法分析：首先，读取源代码，一个字节为一节地都进来，找出这些字节中哪些是我们定义的语法关键字，如Java中的if、else等关键词： 要识别哪些if是合法的关键词，哪些不是，这个步骤就是词法分析过程。词法分析的结构就是从源代码中找出一些规范化的Token流，就像在人类预言中，一句话中哪些是词语，哪些是标点符号，哪些是 动词，哪些是名词等。 语法分析：接着就是对Token流进行语法分析，即检查是不是符合Java语言规范，如if的后面是不是紧跟着一个布尔判断表达式。就像人类语言是不是有主谓宾。语法分析的结果就是形成一个符合Java语言规范的抽象语法树，对这棵语法树我们可以在后面按照新的规则再重新组织。语法分析之后的结果是符合规范的。 词义分析：的结果就是将复杂的语法转化成最简单的语法，对应到Java中，如将foreach转成for循环结构，还有注 解等，最后形成一个注解过后的抽象语法树，这棵语法树更接近目标语言的语法规则。 代码生成器：就是最后生成符合Java虚拟机规范的字节码了。即：主要四个模块：词法分析器、语法分析器、词义分析器、代码生成器。 3. Javac工作原理分析1. 词法分析器从源文件的第一个字符开始，按照Java语法规范依次找出package、import、类定义以及属性和方法定义等，最后生成一个Token流。其中有两个关键点： Javac是如何分辨这一个个Token的呢？例如，它怎么知道package就是一个Token.PACKAGE,而不是用户自定义的Token. IDENTIFIEDR的名称呢? Javac是如何分辨一个Token的，如compile这个词就是一个Token，为什么不是com或者comp抑或compi等，也就是Javac是如何知道 哪些字符组合在一起就是一个Token的呢？ 答案是：Java有特定的语法规则，即空格分词，第一个是package，一行结束最后必然是}或者;等。而Token类似一个key、value的数据结构，PACKAGE:package。 2. 语法分析器获得了Token流，接着，获取每个token的值，根据Java语法规则，进行顺序的，使用不同的解析方法进行解析，例如发现这个Token是import，则使用import语法分析，检查是否有static关键字 等，判断是否静态引入。接着进行类的解析，包括interface、class、enum等，分别进行语法分析。最后进行classBody的解析，即按照变量定义解析、方法定义解析和内部类定义解析进行的。这个过程比较复杂，将结果保存再list集合中，最后添加到class（假如是class）树中。例如下面的class和语法树的对应关系： 123456789101112public class Yufa &#123; int a; private int c = a + 1; public int getC() &#123; &#125; public void setC(int c) &#123; this.c = c; &#125;&#125; 部分节点在图中省略了。最后这个类节点加入到这个类对应的包路径的顶层节点中： 3. 语义分析器我们需要将树进行细化，例如：添加默认的构造函数，检查变量在使用前是否初始化，将一些常量进行合并处理，检查操作变量类型是否匹配， 检查checked exception异常是否已经捕获或抛出，解除Java的语法糖等等，还有符号，有专门的类进行完成。还有专门进行处理annotation（注解）分析，以及变量的自动转化，包装等。内部类是如何解析的呢？ 1234567891011public class Yuyi &#123; public void main(String[] args) &#123; Inner inner = new Inner(); inner.print(); &#125; class Inner &#123; public void print() &#123; System.out.println("print"); &#125; &#125;&#125; 最后被解析成： 12345678910111213141516171819202122232425public class Yuyi &#123; public Yuyi() &#123; super(); &#125; public void main(String[] args) &#123; Yuyi$Inner inner = new Yuyi$Inner(this); inner.print(); &#125; &#123; &#125;&#125;class Yuyi$Inner &#123; final Yuyi this$0; Yuyi$Inner(final Yuyi this$0) &#123; this.this$0 = this$0; super(); &#125; public void print() &#123; System.out.println("print"); &#125;&#125; 内部类会有外部类对象的引用，并且会独立出来。 4. 代码生成器4. 设计模式解析之访问者模式遍历语法树，都会进行不同的处理工作，同时也对这棵语法树进行进一步处理。实际采用的访问者模式设计，每次遍历都是 一次访问者的执行过程。访问者，得到被访问者的实例，并进行操作。 12345678910111213141516171819202122232425262728293031323334353637public abstract class Visitor &#123; protected String name; public void setName(String name) &#123; this.name = name; &#125; public abstract void visit(JCCompiletionUnit_tree jcCompiletionUnitTree); public abstract void visit(JCIf_tree jcIfTree);&#125;public class Attr_visitor extends Visitor&#123; @Override public void visit(JCCompiletionUnit_tree jcCompiletionUnitTree) &#123; jcCompiletionUnitTree.length = 2; System.out.println("Attr_visitor修改Unit_tree"); &#125; @Override public void visit(JCIf_tree jcIfTree) &#123; System.out.println("Attr_visitor修改JCIf_tree"); &#125;&#125;public class Enter_visitor extends Visitor &#123; @Override public void visit(JCCompiletionUnit_tree jcCompiletionUnitTree) &#123; System.out.println("Enter_visitor修改Unit_tree"); &#125; @Override public void visit(JCIf_tree jcIfTree) &#123; jcIfTree.length = 3; System.out.println("Enter_visitor修改Unit_tree"); &#125;&#125; 被访问者，有个接受访问者的方法，接着将自己放入到这个被访问者中，比较绕： 123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class Tree &#123; protected Integer length; public Tree (Integer length) &#123; this.length = length; &#125; public abstract void accept(Visitor visitor); public Integer getLength() &#123; return length; &#125; public void setLength(Integer length) &#123; this.length = length; &#125;&#125;public class JCIf_tree extends Tree &#123; public JCIf_tree(Integer length) &#123; super(length); &#125; @Override public void accept(Visitor visitor) &#123; System.out.println("被访问者的JCIf方法"); visitor.visit(this); &#125;&#125;public class JCCompiletionUnit_tree extends Tree &#123; public JCCompiletionUnit_tree(Integer length) &#123; super(length); &#125; @Override public void accept(Visitor visitor) &#123; System.out.println("被访问者的unit方法"); visitor.visit(this); &#125;&#125; 最后是主函数： 12345678910111213141516171819202122232425public class Demo &#123; List&lt;Tree&gt; trees = new ArrayList&lt;&gt;(); public void add(Tree tree) &#123; trees.add(tree); &#125; public void print(Visitor visitor) &#123; for (Tree tree : trees) &#123; tree.accept(visitor); &#125; &#125; @Test public void testVisitorPattrn()&#123; Visitor attr_visitor = new Attr_visitor(); Demo demo = new Demo(); Tree jcCompiletionUnit_tree = new JCCompiletionUnit_tree(0); Tree jcif_tree = new JCIf_tree(0); demo.add(jcCompiletionUnit_tree); demo.add(jcif_tree); demo.print(attr_visitor); &#125;&#125; 5. 总结基于编译器原理，讲解Javac的编译以及使用的设计模式，访问者模式，遍历语法树。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[三、深入分析Java Web中的中文编码问题]]></title>
    <url>%2F2017%2F08%2F07%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java%20Web%E4%B8%AD%E7%9A%84%E4%B8%AD%E6%96%87%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 几种常见的编码格式1. 为什么需要编码？ 计算机中存储信息的最小单位是1个字节，即8个bit，所以能表示的字符范围是2^8=256个。 人类符号过于复杂，至少一个几个字节才能满足人类的一个单位。 2. 常见编码编码即就是人类的字符-&gt;机器的字符的过程。 1. ASCII码总共有128个，用1个字节的低七位表示，0~31是控制字符，如换行、回车、删除，32~126是打印字符，可以通过键盘输入并且能够显示出来。 2. ISO-8859-1128个字符显示是不够的，于是ISO组织在ASCII码基础上又制定了一系列标准来扩展ASCII编码，他们是ISO-8859-1至ISO-8859-15。ISO-8859-1仍然 是单字节编码，它总共能表示256个字符。 3. GB2312GB2312全称是《信息技术·中文编码字符集》，总的编码范围是：A1~F7。它是双字节编码。包含了符号以及汉字。 4. GBKGBK全称是《汉字内码扩展规范》，是国家技术监督局为Windows95所制定新的汉字内码规范，它的出现是为了扩展GB2312，并加入更多的汉字。 编码范围是8140~FEFE，总共23940，表示21003个汉字，编码是和GB2312兼容，也就是GB2312编码的汉字可以用GBK解码，不会乱码。 5. GB18030应用不广泛，与GB2312兼容 6. UTF-16Unicode（Universal Code统一码），ISO试图创建一个全新的超语言字典，世界上所有的语言都可以通过这个字典来相互翻译。可想而知这个字典是多么 复杂。Unicode是Java和XML的基础。UTF-16具体定义了Unicode字符在计算机中的存取方法，UTF-16用两个字节来表示Unicode的转化格式，它采用定长的表示方法，即不论什么字符都可以用 两个字节表示。两个字节是16个bit，所以叫UTF-16。UTF-16表示字符非常方便，每两个字节表示一个字符，简化了字符串操作，这也是Java以UTF-16作为内存的字符存储 格式的一个重要的原因。 7. UTF-8UTF-16统一采用两个字节表示一个字符，虽然表示上简单方便，但是也有其缺点，很大一部分字符用一个字节就可以表示的现在要用两个字节表示，存储空间 放大了一倍。而UTF-8采用了一种变长技术，每个编码区域有不同的字码长度。不同类型的字符可以由1~6个字节组成。 如果是一个字节。最高为为0，则表示这是一个ASCII字符，可见，所有ASCII编码已经是UTF-8了。 如果是一个字节，以11开头，则连续的1的个数暗示这个字符的字节数。例如：110xxxxx代表它是双字节UTF-8字符的首字节。 如果是一个字节，以10开始，表示它不是首字节，需要向前查找才能得到当前字符的首字节。 2. 编码的场景1. I/O操作Reader类和InputStream之间的InputStreamReader，通过StreamDecoder以及StreamEncoder进行字符和字节的转换，在解码过程必须指定编码格式， 否则按系统编码。 123456789101112131415161718String file = "D:\\source\\eclipse\\liwen\\src\\main\\java\\liwen\\com\\io\\data.txt";String charset = "UTF-8";FileOutputStream fileOutputStream = new FileOutputStream(file);OutputStreamWriter writer = new OutputStreamWriter(fileOutputStream);writer.write("这是要保存的中文字符");writer.close();FileInputStream fileInputStream = new FileInputStream(file);InputStreamReader reader = new InputStreamReader(fileInputStream, charset);char[] buf = new char[1024];int count = 0;StringBuffer buffer = new StringBuffer();while((count = reader.read(buf)) != -1) &#123; buffer.append(buf, 0, count);&#125;System.out.print(buffer.toString());reader.close(); 2. 在内存操作中的编码12345678910111213141516// 第一种，通过字符串操作String s = "中文";byte[] b = s.getBytes("UTF-8");String n = new String(b, "UTF-8");System.out.print(n);// 第二种，通过nio中的Charset与Buffer实现编码解码。Charset charset = Charset.forName("UTF-8");ByteBuffer buffer = charset.encode(s); //字符转字节CharBuffer buffer1 = charset.decode(buffer); //字节转字符char[] a = buffer1.array();System.out.print(a);// 第三种，通过将16bit的char拆分为2个8bit的byte，没有编码解码，只是软转化ByteBuffer byteBuffer = ByteBuffer.allocate(1024);ByteBuffer byteBuffer1 = byteBuffer.putChar('a'); 3. 在Java中如何编解码UTF_32，GBK等编码都是继承自Charset（查看GB18030类的源码，会让你大吃一惊）。Java内存编码采用的UTF-16编码，编码效率高，虽然用双字节存储，但是不适合网络之间传输，因为网络传输容易损坏字节流，当一个字节损坏，就两个字节没用了，UTF-8更适合网络传输。UTF-8对ASCII字符采用单字节存储，另外单个字符损坏也不会影响后面的其他字符，编码效率上介于GBK和 UTF-16之间，所以UTF-8在编码效率上和编码安全性上做了平衡，是理想的中文编码方式。 4. 在Java Web中设计的编解码有I/O的地方就会涉及编码。网络传输都是以字节为单位的，所以所有的数据必须能够被序列化，即继承Serializable。一个文本的实际大小应该怎么计算。例如：把整型数字1234567当做字符哎存储，则采用UTF-8编码会占用7个字节，采用UTF-16编码会占用14个字节，但是当把它当成int类型的数字来存储则只需要4个字节。 1. URL的编码其中浏览器对PathInfo和QueryString是编码不同的，因此服务器分别在不同的地方对其进行解码。例如Tomcat先判断URIEncoding是否有定义，如果没有则默认使用ISO-8859-1解析。而QueryString，无论POST请求还是GET请求，对它们的解码都是在request.getParameters()方法中，当然内部对POST和GET解码是不同的。其中GET请求，是通过HTTP的Header传到服务端的，是通过useBodyEncodingForURL设置。因此在服务器最好设置URIEncoding和useBodyEncoding两个参数。 2. HTTP Header的编解码如Cookie等，一些头信息，Tomcat对Header解码是在调用request.getHeader()方法时进行的。如果有非ASCII字符，使用URLEncoder进行编码，网络传输。 3. POST表单的编解码提交时，浏览器先根据ContentType的Charset编码进行参数编码，然后再提交到服务端，服务端同样也用ContentType中的字符集进行解码。服务端可以通过 request.setCharacterEncoding(charset)来设置。注意：要在第一次调用request.getParameter()方法之前就设置request.setCharacterEncoding(charset)。如果服务端没有设置request.setCharacterEncoding(charset)，那么表单提交的数据将会按照系统的默认编码方式解析。另外，针对multipart/form-data类型的参数，即上传文件，也是通过ContentType定义的字符编码。上传文件是用字节流的方式传输到服务器的本地 临时目录，这个过程并没有涉及字符编码，而真正编码是在讲文件内容添加到parameters，如果用这个不能编码，则会使用默认的ISO-8859-1编码。 4. HTTP BODY的编解码通过Response返回给客户端浏览器。这个过程要经过编码，即response.setCharcterEncoding()来设置，它将会覆盖request.getCharacterEncoding() 的值，并通过Header的Content-Type返回客户端，浏览器接收到返回的Socket流时将通过Content-Type的charset来解码。如果返回的HTTP Header中Content-Type 没有设置charset，那么浏览器将根据浏览器的中的charset来解码， 如果浏览器中没有定义，则使用默认的编码。连接JDBC也是指定一致的编码：jdbc:mysql://localhost:3306?DB?useUnicode=true&amp;characterEncoding=GBK。 5. 在JS的编码1. 外部引入JS文件1&lt;script scr="script.js" charset="gbk"&gt;&lt;/script&gt; 而script.js脚本中，有如下代码： 1document.write("中国"); 如果引入的时候没有设置charset，浏览器就会以当前页面的默认字符集解析这个JS文件。如果一致那就没问题，但是如果页面和js字符编码不一致，就会变成乱码。 2. JS的URL编码1. escape()这组函数已经从ECMAScript v3标准删除了，URL的编码可以用encodeURI和encodeURIComponent来代替。 2. encodeURI()对某些特殊的字符不进行编码如!、a-z、A-Z、0-9、=、@、?、;、:、-、+、(、)、&amp;、#、.、~、*。 3. encodeURIComponent()编码更加彻底，用于整个URL编码，因为它将&amp;也编码了。除了!、a-z、A-Z、0-9、-、、.、~、*。 4. Java与JS编解码问题Java端处理URL编解码有两个类，分别是URLEncoder和URLDecoder。这两个类可以将所有“%”加UTF-8码值用UTF-8解码，从而得到原始的值。对应的前端JS是encodeURIComponent和decodeURLComponent。注意，前端用encodeURIComponent，服务端用URLDecoder解码可能会乱码， 可能是两个字符编码类型不一致，JS编码默认是UTF-8编码，而服务端中文解码一般都是GBK或者GB2312，所以encodeURIComponent编码后是 UTF-8，而Java用GBK去解码显然不对。解决方式是encodeURIComponent两次编码，服务端使用request.getParameter()用GBK解码后，再用UTF-8解码。 6. 常见编码问题1. 中文变成看不懂的字符1234String a = "淘！我喜欢！";byte[] b = a.getBytes("GBK"); //可以表示中文，占两个字节String c = new String(b, "ISO-8859-1"); //将两个字节分别作为一个单独的字符显示System.out.println(c); // output: ÌÔ£¡ÎÒÏ²»¶£¡ 双字节变成单字节 2. 中文变成一个问号 1234String a = "淘！我喜欢！";byte[] b = a.getBytes("ISO-8859-1"); //找不到对应的字符String c = new String(b, "ISO-8859-1");System.out.println(c); // ?????? 3. 中文变成两个问号经过了多次的编码解码。 4. 一种不正常的正确编码直接调用 String value = request.getParameter(name);会出现乱码。但是 String value = new String(request.getParameter(name).getBytes(&quot;ISO-8859-1&quot;), &quot;GBK&quot;)会正常，为什么呢？网络通过GBK编码之后的字节数组进行传输，Tomcat没有配置useBodyEncodingForURI，造成第一次解析通过ISO-8859-1解析， 这时候我们手动通过ISO-8859-1编码，再通过GBK解码就可以获得正确的值，但是额外增加了一次编解码过程。 7. 总结总结了几种常见编码格式的区别： ISO-8859-1：单字节编码，最多能表示256个字符。 GBK、GB2312：双字节编码，前者兼容后者。 UTF-16：双字节编码，Java内部内存额字符存储格式，操作方便，全部都是两个字节，但是浪费空间。 UTF-8：动态字节编码。以及IO的编码实现类：StreamEncoder/StreamDecoder，对char和byte的编解码。 HTTP过程的编码，包括： URL、URI的编码。 Header的编解码。 POST表单的编解码。Java使用request.getParameter()获取之前，先设置request.setCharacterEncoding(charset)。 BODY的编解码，即Response的编解码。 JS的编解码。 Tomcat编解码源码。以及常见乱码问题的原因。注意一定要手动设置编码的格式，实现真正的跨平台。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二、课外学习NIO]]></title>
    <url>%2F2017%2F08%2F04%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%BA%8C%E7%AB%A0%E8%AF%BE%E5%A4%96%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%85%B3%E4%BA%8ENIO%2F</url>
    <content type="text"><![CDATA[1.跑个Channel实例12345678910111213141516171819202122232425262728@Test public void testFileChannel() throws Exception &#123; // 源目标，春运的100W人 RandomAccessFile aFile=new RandomAccessFile("data.txt","rw"); // 获得源目标的运载交通工具，例如动车，同时动车的站台也站了100W人。 FileChannel inChannel=aFile.getChannel(); // 分配buffer，这次春运，这辆D8888，每次跑两个字节单位的座位 ByteBuffer buf=ByteBuffer.allocate(2); // 把动车的站台人和座位连接在一起，得到一个返回值，即该动车和两个字节单位座位的车票信息。 int bytesRead=inChannel.read(buf); // 车票如果是-1说明车票没了，载完了，动车就去保养了。 while(bytesRead!=-1) &#123; // 座位的保险带绑上，人不能下座位或者上座位了，只能被车站人员检查 buf.flip(); // 车站人员检查座位是否有对应的人的信息 while(buf.hasRemaining()) &#123; // 打印出以两个字节为单位的座位的人的信息 System.out.print((char)buf.get()); &#125; // 座位保险带放开，人下车，座位就被清空 buf.clear(); // 动车继续拉两个字节座位的人，又得到了座位的车票信息 bytesRead=inChannel.read(buf); &#125; aFile.close();&#125; 其中的Buffer作为一个顶层抽象类，下面有不止八个子类，对应八种数据类型以及其他一些类型。 当Buffer，即座位在调用flip()方法之前，是写模式，即保险带是放开的，想上就上想下就下。切记：Buffer只是在一个改变capacity、position、limit三个值的方法（还有mark，用于临时标记position，通常用于 发送某个指定位置之后，返回到发送指定位置之前的position，因为内部提供了方法用于这个需求）。 1. 写模式 capacity：固定的大小。 position：初始值为0，写一单位数据就移动下一个可插入数据的单位，最大为capacity-1。 limit：额外的变量，用于读写分离。此时limit=capacity，写入的最大值。 2. 读模式 capacity：固定的大小。 position：重置为0，读一单位数据就移动下一个可插入数据的单位。 limit：重置为position，你只能读你写了多少单位的数据。（flip()方法其实，就是将limit重置为position，position重置为0） 2. Buffer读写数据以及常用方法除了通过Channel写入数据，还可以使用Buffer.put()，写入执行某个位置。也可以通过Buffer.get()，读取某个位置的数据。 1. Buffer.clear()limit设置为capacity，position重置为0。 2. Buffer.compact()释放缓存区无用数据。当源目标为Mellow，我们已经读取了Me，现在缓存区还是Mellow，但是Me是无用的，这时候就可以调用该方法。 你可以使用 Buffer.put()以及Buffer.get()方法达到这个效果。底层其实是将position-limit数据复制到开始的位置，并重置position = limit - position。WHY？这个position是什么意思？其实原因在于这个方法用于：我读了Me，position为2，此时我想开始写数据，但是我以后会在某个时间点回来继续读， 则position就变成4，以后不管你写了多少，都正好不会覆盖未读数据。 3. Buffer.rewind()用于position重置为0，即重新开始写，或者读。 4. Buffer.mark()和Buffer.reset()mark默认为-1。 mark()：将当前position赋值给mark变量。reset()：将mark赋值给position变量。 5. Buffer.equals()和Buffer.compareTo()相等的条件：类型相同、剩余的单位数量相同、剩余的单位类型相同。比较的条件：第一个不相同的元素的大小，如果都相同，则看数量的多少。 3. scatter与gather1. scatter12345ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] byteBuffers = &#123;header, body&#125;;FileChannel channel = new RandomAccessFile("data.txt","rw").getChannel();channel.read(byteBuffers); 不适用与动态消息，第一个Buffer被填充完毕之后才会填充第二个。 2. gather12345ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] buffers = &#123;header, body&#125;;FileChannel channel = new RandomAccessFile("data.txt","rw").getChannel();channel.write(buffers); 只会有position-limit的数据会被写入。 4. Channel之间进行数据传输1234567RandomAccessFile sourceFile = new RandomAccessFile("SourceData.txt", "rw");FileChannel sourceChannel = sourceFile.getChannel();RandomAccessFile targetFile = new RandomAccessFile("TargetData.txt", "rw");FileChannel targetChannel = targetFile.getChannel();long position = 0;long count = sourceChannel.size();targetChannel.transferFrom(sourceChannel, position, count); 还有一个Channel.transferTo()方法，和上面的方法相反的作用。注意：目标文件如果本来大于源文件，目标文件只会被覆盖源文件要传输的数据，剩余的数据还会存在。 如果count传入的时候实际大于size，则被当做count，如果小于size，则会按小于的值覆盖。查看源码即可知。 5. Selector1. 为什么使用Selector？Selector是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。 这样一个单独的线程可以管理多个Channel，从而管理多个网络连接。可以使用一个线程处理所有的通道，而对于操作系统来说，线程之间上下文切换的开销很大，Selector则是 可以处理多个Channel。 2. Selector使用1234567// 创建SeletorSelector selector = Selector.open();// channel注册到selector// 继承自AbstractSelectableChannel的方法ServerSocketChannel channel = ServerSocketChannel.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ); 与Selector一起使用时，Channel必须处于费阻塞模式下，而FileChannel只能是阻塞模式，套接字可以切换。监听的第二个参数是不同类型的事件： Connect：SelectionKey.OP_CONNECT Accept：SelectionKey.OP_ACCEPT Read：SelectionKey.OP_READ Write：SelectionKey.OP_WRITE监听多个事件：第二个参数输入：SelectionKey.OP_CONNECT | SelectionKey.OP_CONNECT 3. SelectionKey1. interset属性其中包含了一些你感兴趣的属性，即注册的事件： 12345int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT;boolean isInterestedInConnect = (interestSet &amp; SelectionKey.OP_CONNECT) == SelectionKey.OP_CONNECT;boolean isInterestedInRead = (interestSet &amp; SelectionKey.OP_READ) == SelectionKey.OP_READ;boolean isInterestedInWrite = (interestSet &amp; SelectionKey.OP_WRITE) == SelectionKey.OP_WRITE; 2. ready属性ready集合是通道已经准备九局的操作的集合，你可以通过int readySet = selectionKey.readyOps()进行分别的访问， 也可以使用： 1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); 3. Selector获得Channel12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 4. 附加的对象（可选）12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 5. 通过Selector选择通道 int select() 该方法会让Selector阻塞，直到至少有一个Channel在你注册的事件上就绪。 int select(long timeout) 设置最长阻塞的毫秒数 int selectNow() 直接返回，无论什么Channel。 返回值表示从上次select()方法调用之后，又有多少符合要求的Channel，不叠加。 6. wakeUp()某个线程调用select()让某个Selector阻塞后，使用该方法可以立马返回，如果没有阻塞，但是提前调用了wakeUp方法， 那么下个调用select方法的线程会立即wake up。 7. 遍历SelectorKeys12345678910111213141516Selector selector = Selector.open();Set selectionKeys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); if (key.isAcceptable()) &#123; &#125; else if (key.isConnectable()) &#123; &#125; else if (key.isReadable()) &#123; &#125; else if (key.isWritable()) &#123; &#125; iterator.remove();&#125; 需要手动将事件给移除。 4. 完整的示例1234567891011121314int port = 9999; ServerSocketChannel channel = ServerSocketChannel.open();channel.configureBlocking(false); channel.socket().bind(new InetSocketAddress(port)); Selector selector = Selector.open(); SelectionKey selKey = channel.register(selector, SelectionKey.OP_ACCEPT); int interestSet = selKey.interestOps(); boolean is_accept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT;System.out.print("isAccept:"+ is_accept); 6. FileChannel文件通道，用于文件的读写，常用，由于FileChannel无法设置非阻塞模式，它总是运行在阻塞模式下。1234567891011 String str = "112中国";RandomAccessFile file = new RandomAccessFile( "D:\\source\\eclipse\\liwen\\src\\main\\java\\liwen\\com\\io\\data.txt", "rw");FileChannel channel = file.getChannel();channel.position(channel.position() + file.length()); //这行代码设置写入文件的最后ByteBuffer buffer = ByteBuffer.allocate(48);buffer.put(str.getBytes());buffer.flip();while (buffer.hasRemaining()) &#123; channel.write(buffer);&#125; 还有用于截取通道的方法：truncate()，以字节为单位。还有一个force()方法，用于强行将数据写入磁盘， 操作系统一般先将数据写入内存，再从内存写入磁盘，设置为True即可。 7. SocketChannel1234567891011121314// 客户端连接，最后使用close关闭。SocketChannel channel = SocketChannel.open();channel.connect(new InetSocketAddress(8989));ByteBuffer buffer = ByteBuffer.allocate(48);channel.read(buffer);// 从buffer中写入数据到channelString data = "what ? ";buffer.clear();buffer.put(data.getBytes());buffer.flip();while (buffer.hasRemaining()) &#123; channel.write(buffer);&#125;channel.close(); 8. ServerSocketChannel12345678910111213// 服务端开启监听：ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.configureBlocking(false);serverSocketChannel.socket().bind(new InetSocketAddress(8777));while (true)&#123; SocketChannel channel = serverSocketChannel.accept(); // 如果设置为非阻塞，则上面的代码会立马返回，需要判空，是否有连接。 if (channel != null)&#123; String ip = serverSocketChannel.socket().getInetAddress().getHostAddress(); System.out.println(ip); // 此时你得到了channel，就可以使用Buffer对数据进行读取操作了。 &#125;&#125; 9. DatagramChannel用于UDP数据的发送和接收 123456// 服务端DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(9999));ByteBuffer buffer = ByteBuffer.allocate(48);channel.configureBlocking(false);channel.receive(buffer); //将得到的UDP数据写入buffer中 12345678// 客户端DatagramChannel channel = DatagramChannel.open();String data = "中国";ByteBuffer buffer = ByteBuffer.allocate(48);buffer.put(data.getBytes());buffer.flip();channel.send(buffer, new InetSocketAddress(9999));channel.close(); 10. Pipe作为两个线程之间的单向数据连接连接（Channel本身是双向，但是通过两个双向的管道一起组合实现成一个单向的，即Sink-&gt;Source）。 12345678910111213// 向管道写数据Pipe pipe = Pipe.open();Pipe.SinkChannel sinkChannel = pipe.sink();ByteBuffer buffer = ByteBuffer.allocate(48);buffer.put("中国人".getBytes());buffer.flip();while (buffer.hasRemaining())&#123; sinkChannel.write(buffer);&#125;// 从管道读数据Pipe.SourceChannel sourceChannel = pipe.source();buffer.clear();sourceChannel.read(buffer); 11. NIO和IO1. 面向流和面向缓冲IO面向流，每次从流中读取一个或多个字节，直至读取所有的字节，没有被缓存再任何地方，另外，也不能移动流中的数据， 如果想移动，需要手动将流中的数据缓存在一个第三方缓冲区变量中。而NIO则本身就将数据放入到缓冲区中，可以在缓冲区 中前后移动，只是加多了对缓冲区的判断以及更多数据进入缓冲区时，不能覆盖原来的数据。 2. 阻塞和非阻塞本质区别，IO在读写直接阻塞。而NIO的读写的操作会直接返回值，进入下一步操作不会阻塞，并通过Selector来实现一个线程 对多个Channel，即多个读写进行管理。 3. 数据的处理 IO的设计逐字节读取数据。例如你正在处理基于行的文本数据流： 1234567891011/**data.txt * Name: xxx * Age: 18 * Email: xxx@gmail.com * Phone: 135xxxxx */BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream("data.txt")));String nameLine = reader.readLine();String ageLine = reader.readLine();String emailLine = reader.readLine();String phoneLine = reader.readLine(); NIO直接读写： 12345678ByteBuffer buffer = ByteBuffer.allocate(48);FileChannel channel = new RandomAccessFile("data.txt", "rw").getChannel();int bytesRead = channel.read(buffer);while (bytesRead != -1) &#123; channel.read(buffer);&#125;channel.close(); 4. 总结 NIO可让您只使用一个（或几个）单线程管理多个通道（网络连接或文件），但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样， 如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，可能是一个优势。 如果你有少量的连接使用非常高的带宽，一次发送大量的数据，也许典型的IO服务器实现可能非常契合。下图说明了一个典型的IO服务器设计：]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一、深入Web请求过程]]></title>
    <url>%2F2017%2F08%2F03%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5Web%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1. DNS域名解析使用浏览器输入网址后，浏览器会检查缓存对应的IP地址，如果没有，浏览器会查找操作系统，即host文件。 所以很多墙外比较慢的网址，可以手动编写host文件对应的IP地址以及对应的网址，可以加快访问速度。 如果实在没有就发送给LDNS，这个LDNS在不同的情况是不一样的，在学校，大部分都是学校的DNS服务器， 家庭的一般都是联通或者电信的DNS服务器，最最最后实在解析不出来，就抛给Root Server域名服务器， 它会返回给本地域名服务器的主域名服务器的地址，即域名空间提供商的域名解析服务器，就像阿里域名解析加速。 2. 清除缓存的域名主要在两个地方缓存：Local DNS Server, 另一个是用户的本机，当然，重启也是更好的方法。 ipconfig /flushdns 在java中，JVM也会缓存DNS的解析结果，分两种，即正确的解析结果，以及错误的解析结果，InetAddress，实际中InetAddress使用必须是单例模式，因为每次创建InetAddress实例都要进行一次完整的域名解析。 3. CDN工作机制CDN也就是内容分布网络(Content Delivery Network)。通过在现有的Internet中增加一层新的网络架构，比镜像更智能。 比喻：CDN=镜像Mirror+缓存Cache+整体负载均衡GSLB。 目前CDN都以缓存网站中的静态数据为主，如CSS、JS、图片和静态页面等，用户在从主站服务器请求到动态内容后，再从CDN上下载这些静态数据。 4. 负载均衡负载均衡(Load Balance)就是对工作任务进行平衡、分摊到多个操作单元上执行，如图片服务器、应用服务器等，提高服务器响应速度，实现地理位置无关性。 通常有三种负载均衡架构：链路负载均衡、集群负载均衡、操作系统负载均衡。 链路：用户最终访问哪个Web Server是由DNS Server来控制的，优点在于用户直接访问目标服务器，不需要经过其它的代理服务器，通常访问速度更快，缺点在于DNS在用户本地和LDNS都有缓存，一旦某台Web Server挂掉，就难及时更新用户的域名解析结构。 集群：硬件负载以及软件负载均衡，前者需要贵的硬件作为中心，而软件则是成本低，但是需要多次代理服务器转发，从而增加了网络延时。 操作系统：如设置多队列网卡。 5. CDN动态加速原理在于CDN的DNS解析中通过动态的链路探测来寻找回源最好的一条路径，通过DNS的调度将所有请求到选定的路径上回源，一个简单的原则就是在每个CDN节点上从源站下载一个一定大小文件，看哪个链路的总耗时最短，这样可以构成一个链路列表，然后绑定到DNS解析上，更新到CDN的Local DNS。以及网络成本等。 6. 总结主要介绍域名的请求，哪些处理，对CDN以及负载均衡有了解。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[二、深入分析Java IO的工作机制]]></title>
    <url>%2F2017%2F08%2F03%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java%20IO%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1. JAVA的I/O类库的基本架构 基于字节操作的I/O接口：InputStream和OutputStream。 基于字符操作的I/O操作：Writer和Reader。 基于磁盘操作的I/O操作：File。 基于网络操作的I/O操作：Socket。 2. 字节字符的转换低级的字节转字符，有InputStreamReader，以及OutputStreamWriter。 而字符转字节一般直接用new String(byte[])。 注意：字符字节的转换在开发中一定要显示指明编码。 在OutputStreamWriter的官方注释中，错误的理解为从字符到字节，其实应该理解成字符与字节之间的桥梁。 3. 访问文件的几种方式前言：读取和写入都是调用操作系统的提供的接口，而操作系统调用就会存在内核空间地址和用户空间地址切换的问题，一般的IO都是数据从 磁盘复制到内核空间，然后再从内核空间复制到用户空间，操作系统为了加速IO访问，在内核空间使用了缓存，即如果是第二次访问同一段 的磁盘地址，直接从内核缓存中取出。 1. 标准访问文件的方式读取：调用操作系统的Read接口，操作系统先检查内核的高速缓存，如果有缓存则直接返回，如果没有则从磁盘中读取，缓存，返回。 写入：调用操作系统的Writer接口，写入到高速缓存中，则通知应用程序完成，什么时候写入磁盘由操作系统决定。当然你可以使用sync强制刷新。 2. 直接I/O的方式即应用程序直接访问磁盘数据，减少一次从内核缓冲区到用户空间的数据复制，例如数据库管理系统，数据库明确的知道哪些数据需要缓存 哪些不需要，以及哪些数据需要先放到内存中预热，但是不好的地方在于，你接管了数据缓存，如果你没有命中，则每次都是IO磁盘，比较 耗时，通常结合直接IO与异步IO。 3. 同步访问文件的方式与标准访问文件不同点在于，写入了磁盘，操作系统才会应用程序返回成功的标志，用于安全性高的场景。 4. 异步访问文件的方式访问文件的请求线程发出后，不会阻塞等待，继续做别的事，完成文件访问后回调某个方法，提高应用程序的效率而不是访问文件的效率。 5. 内存映射的方式操作系统将内存中的某一块区域与磁盘中的文件关联，理解为快捷方式。这样中间加了一层地址映射，空间换时间，在实际开发中，多台业务 服务器对一个统一的路径下进行共享，方便数据的存储。例如A服务器下的data和B服务器下的data进行共享，便于文件的统一上传下载路径管理。 4. 访问磁盘文件前面介绍了操作数据，接着这里介绍数据写向何处，例如持久化到物理磁盘。FileInputStream对象是操作一个文件的接口，创建的同时会创建该文件的描述对象FileDescriptor。操作文件对象的时候可以通过getFD() 方法获取真正与底层操作系统相关联的文件描述。例如调用FileDescriptor.sync()方法将操作系统缓存中的数据强制刷新到物理磁盘中。byte-&gt;char是解码过程，因此读取文件都是需要StreamDecoder类帮助。 1. Java序列化技术将对象转化成一串二进制表示的字符数组，反序列化时需要原始类作为模板，原因在于序列化之后的文件不保存类的完整结构信息。 建议保存为通用的json/xml格式，比较耗的序列化工具：protobuf。序列化以及反序列需要注意一些常见的问题，例如serialVersionUID被修改， 序列化对象中有属性为对象但是该属性对象没有实现Serializable等。 5. 网络I/O工作机制1. TCP状态 三次握手 客户端CLOSED、SYN-SEND、ESTABLISHED。服务端LISTEN、SYN-RCVD、ESTABLISHED。 四次挥手客户端ESTABLISHED、FIN_WAIT_1、FIN_WAIT_2、TIME_WAIT。服务端ESTABLISHED、CLOSE_WAIT、LAST_ACK、CLOSE。 2. 影响网络传输的因素 网络带宽：物理链路在1s内传输的最大比特值，一般都是1.7Mb/s。 传输距离。 TCP拥塞控制：TCP传输是一个“停等停等”的过程，要步调一致则需要通过拥塞控制来调节。TCP在传输时会设定一个“窗口”，窗口大小由带宽和数据 在两端的来回时间，即响应时间决定的。 3. Java Socket的工作机制 客户端开始建立一个Socket实例时，操作系统将为这个Socket实例分配一个没有被使用的本地端口号，并创建一个包含本地地址、 远程地址和端口号的套接字数据结构，这个数据结构一直保存在系统中直到这个连接关闭。在创建Socket实例的构造函数正确返回之前，将进行TCP的三次握手协议， 三次握手，完成之后，Socket实例创建完成。服务端将创建一个ServerSocket实例，只要指定的端口号没有被占用，一般实例都会创建成功，操作系统底层也会为ServerSocket实例创建一个底层 数据结构，这个数据结构中包含指定的端口号和包含监听地址的通配符，通常都是“*”，即监听所有地址。之后调用accept()方法，进入阻塞状态，等待 客户端的请求。当一个新的请求到达时，为这个连接创建一个新的套接字数据结构，该套接字数据的信息包含的地址和端口信息正是请求源地址 和端口，同时这个新创建的数据结构将会关联到ServerSocket实例的一个未完成的连接数据结构列表中。注意，此时服务端的与之对应的Socket实例 并没有完成创建，而是要等待与客户端的3次握手完成后，这个服务端的Socket实例才会返回，并从未连接数据结构列表移到已完成列表。所以与ServerSocket 所关联的列表中每个数据结构都代表与一个客户端建立的TCP连接。 4. 数据传输服务端和客户端都会拥有一个Socket实例，每个Socket实例都有一个InputStream和OutputStream，通过这两个对象来交换数据，同时操作系统会为 这两个对象分配一定大小的缓存区。 写入：数据-&gt;OutputStream对应的SendQ队列，队列填满时，数据将会转移到另一端的InputStream的RecvQ队列中，如果RecvQ已经满了，那么 OuptStream的write方法将会阻塞，直到RecvQ队列可以容纳SendQ队列的数据。因此网络IO还需要一个协调的过程，如果两边同时传输数据则会产生死锁。 6. NIO的工作方式(建议先阅读课外学习：关于NIO)1. BIO的缺点阻塞IO，即BIO，在读取和写入时（InputStream、OutputStream）都有可能堵塞，一旦有堵塞，线程将会失去CPU的使用权，一些方法，例如：一个客户端 一个处理线程、线程池用来减少线程创建和回收的成本。但是，当需要大量的HTTP长连接，例如Web旺旺，虽然并不是每个连接都一直在传输数据，但是如果要 对某个客户端（VIP）提供更高的服务优先，很难通过线程本省的优先级完成，同时访问一些竞争资源时，也会有问题，因此需要同步。因此NIO应运而生。 2. NIO的工作机制通过等待读以及等待写的轮询，在真正进行IO的时候才是使用CPU阻塞，但是由于是memory copy，在带宽足够大的1GB/s基本可以忽略。 3. Buffer的工作方式可以简单理解为操作一组基本数据类型的元素列表：capacity、position、limit、mark。注意，通过Channel获取的IO数据首先经过操作系统的Socket缓冲区，再将数据复制到Buffer中，这个操作系统缓冲区就是底层的TCP所关联的RecvQ或者 SendQ队列。Buffer提供了另一种直接操作操作系统缓冲区的方式，即ByteBuffer.allocateDirector()，这个方法直接返回底层存储空间关联的缓冲区，它通过 Native代码操作非JVM堆的内存空间，每次创建或者释放都要手动调用一次System.gc()。注意：使用该方法直接操作非JVM堆空间会引起JVM内存泄漏问题。适用于数据量比较大，生命周期比较长的情况下，而普通的allocate()方法 适用并发连接少于1000。 4. FileChannel的数据访问1. FileChannel.transferXXX传统的数据访问方式：FileChannel.transferXXX方式： 2. FileChannel.map将文件按照一定大小块映射为内存区域，当程序访问这个内存区域时将直接操作这个文件数据，省去了数据从内核空间向用户空间复制的损耗。 适用于对大文件的只读性操作，如大文件的MD5校验。 7. IO调优1. 磁盘I/O优化1. 性能检测在Linux下的iostat命令，查看I/O wait指标是否正常，即CPU等待I/O指标，如果是4核CPU，那么I、O wait参数不应该超过25%。 2. 提升I/O性能 增加缓存，减少磁盘访问次数。 优化磁盘的管理系统 设计合理的磁盘存储数据块。 2. TCP网络参数调优操作系统的端口号：2^16 = 65535个。 通过查看cat /proc/sys/net/ipv4/ip_local_port_range查看端口范围大量并发，端口号的数量就变成瓶颈，还有TIME_WAIT的数量，如果过多，需要将参数设小，提前释放。 3. 网络I/O优化 减少网络交互的次数SQL在客户端和数据库端设置缓存，请求css、js等可以合并为一个http链接，每个文件通过逗号隔开，服务端一次请求全部返回。 减少网络传输数据量的大小通常Web服务器将请求的Web页面gzip压缩后再传输给浏览器。以及通过简单的协议，读取协议头来获取有用的价值信息。尽量 避免读取整个通信数据，例如4层代理和7层代理，都是精良避免要读取整个通信数据。 尽量减少编码尽量以字节形式发送。 1. 同步与异步 同步一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能完成，这是一种可靠的任务序列，同生同死。 同步能保证程序的可靠性。 异步不需要等待被依赖的任务完成只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行。 异步可以提高程序的性能，需要在同步与异步中保持平衡 2. 阻塞和非阻塞阻塞和非阻塞主要从CPU的消耗上来说。 阻塞CPU停下等待一个慢的操作完成之后，CPU才接着完成其他的工作。 非阻塞这个慢操作执行时，CPU去做其他工作，这个慢操作完成时，CPU收到通知继续完成这个慢操作之后的事。 3. 两种方式的组合 同步阻塞常用，简单，但是IO性能差，CPU大部分处于空闲状态。 同步非阻塞常用于网络IO是长连接同时传输数据不多的情况。提升IO性能的常用手段，会增加CPU消耗，要考虑增加的IO性能能不能补偿CPU的消耗，也就是系统的瓶颈是在IO还是CPU上。 异步阻塞常用于分布式数据库中。例如一个分布式数据库中写一条记录，通常会有一份是同步阻塞的记录，还有2~3份备份记录会写到 其他机器上，这些备份记录通常都采用异步阻塞的方式写IO，异步阻塞对网络IO能够提升效率，尤其像上面这种同时写多份 相同数据的情况。 异步非阻塞比较复杂，只有在非常负载的分布式情况下使用，集群之间的消息同步机制一般使用这种IO组合方式。如Cassandra的Gossip通信机制就采用 异步非阻塞的方式。适用于同时要传多份相同的数据到集群中不同的机器，同时数据的传输量虽然不大但非常频繁的情况。 虽然异步和非阻塞能够提高IO整体性能，但是会增加性能成本，以及程序设计复杂的上升，需要经验丰富的人去设计，如果 设计的不合理反而会导致性能下降。怎样理解阻塞非阻塞与同步异步的区别？ 8. 适配器模式博主做一个Integer转化为String的例子，仿造InputStream转化Reader的简单例子。 123456789101112131415public class InputInteger_ implements Integer_ &#123; private Integer a; public InputInteger_(Integer a)&#123; this.a = a; &#125; public Integer getInteger()&#123; return a; &#125;&#125;public interface Integer_ &#123; public Integer getInteger();&#125; 123456789public class String_ implements InputString_ &#123; public void readString() &#123; &#125;&#125;public interface InputString_ &#123; public void readString();&#125; 1234567891011121314public class InputInteger2String implements InputString_ &#123; Integer_ s; public InputInteger2String(Integer_ s) &#123; this.s = s; &#125; public void readString() &#123; // StreamDecoder Integer r = Integer.valueOf(s.getInteger()); System.out.println(r); &#125;&#125; 123456public class Demo &#123; public static void main(String[] args) &#123; InputInteger2String s = new InputInteger2String(new InputInteger_(4)); s.readString(); &#125;&#125; 9. 装饰器模式赋予被装饰的类更多的功能，就像IO中的BufferedInputStream有缓冲的功能，LineNumberInputStream有提高按行读取数据的功能。 1234567891011121314151617181920public abstract class InputStream_ &#123; public abstract void read();&#125;public class FileInputStream_ extends InputStream_ &#123; public void read() &#123; &#125;&#125;public class FilterInputStream_ extends InputStream_ &#123; protected InputStream_ inputStream_; public FilterInputStream_(InputStream_ inputStream_)&#123; this.inputStream_ = inputStream_; &#125; public void read() &#123; inputStream_.read(); &#125;&#125; 1234567891011121314151617181920public class BufferInputStream_ extends FilterInputStream_ &#123; public BufferInputStream_(InputStream_ inputStream_) &#123; super(inputStream_); &#125; private void bufferFirst()&#123; &#125; private void bufferEnd()&#123; &#125; public void read()&#123; bufferFirst(); super.read(); bufferEnd(); &#125;&#125; 123456789public class Demo &#123; public static void main(String[] args)&#123; InputStream_ inputStream_ = new FileInputStream_(); BufferInputStream_ bufferInputStream_ = new BufferInputStream_(inputStream_); bufferInputStream_.read(); &#125;&#125; 10. 适配器模式与装饰器模式区别它们有个别名，叫包装模式，都起到了包装一个类或对象的作用，但是作用不同。适配器通过改变接口来达到重复使用的目的（如果系统在设计初期，就尽量不要用 适配器模式），而装饰器模式保持原有的接口，增强原有对象的功能。 11. 总结Java中IO的基本库结构，磁盘IO和网络IO的工作方式。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
</search>