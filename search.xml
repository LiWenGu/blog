<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[二、深入分析Java IO的工作机制]]></title>
    <url>%2F2017%2F08%2F05%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java%20IO%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1. JAVA的I/O类库的基本架构 基于字节操作的I/O接口：InputStream和OutputStream。 基于字符操作的I/O操作：Writer和Reader。 基于磁盘操作的I/O操作：File。 基于网络操作的I/O操作：Socket。 2. 字节字符的转换低级的字节转字符，有InputStreamReader，以及OutputStreamWriter。而字符转字节一般直接用new String(byte[])。注意：字符字节的转换在开发中一定要显示指明编码。在OutputStreamWriter的官方注释中，错误的理解为从字符到字节，其实应该理解成字符与字节之间的桥梁。 3. 访问文件的几种方式前言：读取和写入都是调用操作系统的提供的接口，而操作系统调用就会存在内核空间地址和用户空间地址切换的问题，一般的IO都是数据从磁盘复制到内核空间，然后再从内核空间复制到用户空间，操作系统为了加速IO访问，在内核空间使用了缓存，即如果是第二次访问同一段的磁盘地址，直接从内核缓存中取出。 标准访问文件的方式读取：调用操作系统的Read接口，操作系统先检查内核的高速缓存，如果有缓存则直接返回，如果没有则从磁盘中读取，缓存，返回。写入：调用操作系统的Writer接口，写入到高速缓存中，则通知应用程序完成，什么时候写入磁盘由操作系统决定。当然你可以使用sync强制刷新 直接I/O的方式即应用程序直接访问磁盘数据，减少一次从内核缓冲区到用户空间的数据复制，例如数据库管理系统，数据库明确的知道哪些数据需要缓存哪些不需要，以及哪些数据需要先放到内存中预热，但是不好的地方在于，你接管了数据缓存，如果你没有命中，则每次都是IO磁盘，比较耗时，通常结合直接IO与异步IO。 同步访问文件的方式与标准访问文件不同点在于，写入了磁盘，操作系统才会应用程序返回成功的标志，用于安全性高的场景。 异步访问文件的方式访问文件的请求线程发出后，不会阻塞等待，继续做别的事，完成文件访问后回调某个方法，提高应用程序的效率而不是访问文件的效率。 内存映射的方式操作系统将内存中的某一块区域与磁盘中的文件关联，理解为快捷方式。这样中间加了一层地址映射，空间换时间，在实际开发中，多台业务服务器对一个统一的路径下进行共享，方便数据的存储。例如A服务器下的data和B服务器下的data进行共享，便于文件的统一上传下载路径管理。 4. 访问磁盘文件前面介绍了操作数据，接着这里介绍数据写向何处，例如持久化到物理磁盘。FileInputStream对象是操作一个文件的接口，创建的同时会创建该文件的描述对象FileDescriptor。操作文件对象的时候可以通过getFD()方法获取真正与底层操作系统相关联的文件描述。例如调用FileDescriptor.sync()方法将操作系统缓存中的数据强制刷新到物理磁盘中。byte-&gt;char是解码过程，因此读取文件都是需要StreamDecoder类帮助。 1. Java序列化技术将对象转化成一串二进制表示的字符数组，反序列化时需要原始类作为模板，原因在于序列化之后的文件不保存类的完整结构信息。建议保存为通用的json/xml格式，比较耗的序列化工具：protobuf。序列化以及反序列需要注意一些常见的问题，例如serialVersionUID被修改，序列化对象中有属性为对象但是该属性对象没有实现Serializable等。 5. 网络I/O工作机制1. TCP状态： 三次握手客户端CLOSED、SYN-SEND、ESTABLISHED。服务端LISTEN、SYN-RCVD、ESTABLISHED。 四次挥手客户端ESTABLISHED、FIN_WAIT_1、FIN_WAIT_2、TIME_WAIT。服务端ESTABLISHED、CLOSE_WAIT、LAST_ACK、CLOSE。 2. 影响网络传输的因素 网络带宽：物理链路在1s内传输的最大比特值，一般都是1.7Mb/s。 传输距离。 TCP拥塞控制：TCP传输是一个“停等停等”的过程，要步调一致则需要通过拥塞控制来调节。TCP在传输时会设定一个“窗口”，窗口大小由带宽和数据在两端的来回时间，即响应时间决定的。 3. Java Socket的工作机制客户端开始建立一个Socket实例时，操作系统将为这个Socket实例分配一个没有被使用的本地端口号，并创建一个包含本地地址、远程地址和端口号的套接字数据结构，这个数据结构一直保存在系统中直到这个连接关闭。在创建Socket实例的构造函数正确返回之前，将进行TCP的三次握手协议，三次握手，完成之后，Socket实例创建完成。服务端将创建一个ServerSocket实例，只要指定的端口号没有被占用，一般实例都会创建成功，操作系统底层也会为ServerSocket实例创建一个底层数据结构，这个数据结构中包含指定的端口号和包含监听地址的通配符，通常都是“*”，即监听所有地址。之后调用accept()方法，进入阻塞状态，等待客户端的请求。当一个新的请求到达时，为这个连接创建一个新的套接字数据结构，该套接字数据的信息包含的地址和端口信息正是请求源地址和端口，同时这个新创建的数据结构将会关联到ServerSocket实例的一个未完成的连接数据结构列表中。注意，此时服务端的与之对应的Socket实例并没有完成创建，而是要等待与客户端的3次握手完成后，这个服务端的Socket实例才会返回，并从未连接数据结构列表移到已完成列表。所以与ServerSocket所关联的列表中每个数据结构都代表与一个客户端建立的TCP连接。 4. 数据传输服务端和客户端都会拥有一个Socket实例，每个Socket实例都有一个InputStream和OutputStream，通过这两个对象来交换数据，同时操作系统会为这两个对象分配一定大小的缓存区。 写入：数据-&gt;OutputStream对应的SendQ队列，队列填满时，数据将会转移到另一端的InputStream的RecvQ队列中，如果RecvQ已经满了，那么OuptStream的write方法将会阻塞，直到RecvQ队列可以容纳SendQ队列的数据。因此网络IO还需要一个协调的过程，如果两边同时传输数据则会产生死锁。 6. NIO的工作方式1. BIO的缺点阻塞IO，即BIO，在读取和写入时（InputStream、OutputStream）都有可能堵塞，一旦有堵塞，线程将会失去CPU的使用权，一些方法，例如：一个客户端一个处理线程、线程池用来减少线程创建和回收的成本。但是，当需要大量的HTTP长连接，例如Web旺旺，虽然并不是每个连接都一直在传输数据，但是如果要对某个客户端（VIP）提供更高的服务优先，很难通过线程本省的优先级完成，同时访问一些竞争资源时，也会有问题，因此需要同步。因此NIO应运而生。 2. NIO的工作机制]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一、深入Web请求过程]]></title>
    <url>%2F2017%2F08%2F04%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90Java_Web%E6%8A%80%E6%9C%AF%2F%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E6%B7%B1%E5%85%A5Web%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1. DNS域名解析使用浏览器输入网址后，浏览器会检查缓存对应的IP地址，如果没有，浏览器会查找操作系统，即host文件。所以很多墙外比较慢的网址，可以手动编写host文件对应的IP地址以及对应的网址，可以加快访问速度。如果实在没有就发送给LDNS，这个LDNS在不同的情况是不一样的，在学校，大部分都是学校的DNS服务器，家庭的一般都是联通或者电信的DNS服务器，最最最后实在解析不出来，就抛给Root Server域名服务器，它会返回给本地域名服务器的主域名服务器的地址，即域名空间提供商的域名解析服务器，就像阿里域名解析加速。 2. 清除缓存的域名主要在两个地方缓存：Local DNS Server, 另一个是用户的本机，当然，重启也是更好的方法。 ipconfig /flushdns 在java中，JVM也会缓存DNS的解析结果，分两种，即正确的解析结果，以及错误的解析结果，InetAddress，实际中InetAddress使用必须是单例模式，因为每次创建InetAddress实例都要进行一次完整的域名解析。 3. CDN工作机制CDN也就是内容分布网络(Content Delivery Network)。通过在现有的Internet中增加一层新的网络架构，比镜像更智能。比喻：CDN=镜像Mirror+缓存Cache+整体负载均衡GSLB。目前CDN都以缓存网站中的静态数据为主，如CSS、JS、图片和静态页面等，用户在从主站服务器请求到动态内容后，再从CDN上下载这些静态数据。 4. 负载均衡负载均衡(Load Balance)就是对工作任务进行平衡、分摊到多个操作单元上执行，如图片服务器、应用服务器等，提高服务器响应速度，实现地理位置无关性。通常有三种负载均衡架构：链路负载均衡、集群负载均衡、操作系统负载均衡。 链路：用户最终访问哪个Web Server是由DNS Server来控制的，优点在于用户直接访问目标服务器，不需要经过其它的代理服务器，通常访问速度更快，缺点在于DNS在用户本地和LDNS都有缓存，一旦某台Web Server挂掉，就难及时更新用户的域名解析结构。 集群：硬件负载以及软件负载均衡，前者需要贵的硬件作为中心，而软件则是成本低，但是需要多次代理服务器转发，从而增加了网络延时。 操作系统：如设置多队列网卡。 5. CDN动态加速原理在于CDN的DNS解析中通过动态的链路探测来寻找回源最好的一条路径，通过DNS的调度将所有请求到选定的路径上回源，一个简单的原则就是在每个CDN节点上从源站下载一个一定大小文件，看哪个链路的总耗时最短，这样可以构成一个链路列表，然后绑定到DNS解析上，更新到CDN的Local DNS。以及网络成本等。 6. 总结主要介绍域名的请求，哪些处理，对CDN以及负载均衡有了解。]]></content>
      <categories>
        <category>读书笔记</category>
        <category>深入分析Java_Web技术</category>
      </categories>
  </entry>
</search>